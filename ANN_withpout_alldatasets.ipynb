{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrft-tiCqd5l"
      },
      "source": [
        "# Preprocessing with PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z4ksi0JwVuCe",
        "outputId": "0e3c76f8-b00d-4eb1-ae04-814fc7cb0517"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "    0.00000000e+00  0.00000000e+00]\n",
            "  [-9.20134055e-01  1.54299476e+00  9.92465949e-01 ...  1.04262548e+00\n",
            "   -1.16618377e-01 -8.14811298e-01]\n",
            "  [-1.08665533e+00  7.17241111e-01  9.47674862e-01 ...  8.52689363e-01\n",
            "   -2.36686568e-01  2.01748830e-02]\n",
            "  ...\n",
            "  [-3.53772246e-01  7.95436161e-01 -1.61740288e-01 ...  9.24008551e-02\n",
            "    1.21146544e+00  4.63188316e-01]\n",
            "  [-4.69610410e-01  4.54619336e-01 -6.29329877e-03 ...  9.69387890e-03\n",
            "    1.09755247e+00  4.43589090e-01]\n",
            "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "    0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            " [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "    0.00000000e+00  0.00000000e+00]\n",
            "  [-1.04797403e+00  8.84788664e-01  1.01703462e+00 ...  3.77104807e-01\n",
            "   -7.01367197e-01 -2.98649864e+00]\n",
            "  [-1.39119007e+00 -3.08386795e-01  8.11145100e-01 ... -3.76835027e-01\n",
            "   -3.51969563e-01  5.25179263e-01]\n",
            "  ...\n",
            "  [-3.43257059e-01  8.30357908e-01  2.15075592e-01 ... -4.13058102e-01\n",
            "    4.41568616e-01  5.19537014e-01]\n",
            "  [-5.09345962e-01  4.23611807e-01  3.15038878e-02 ... -1.93399096e+00\n",
            "    7.55146042e-02 -3.90762525e-01]\n",
            "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "    0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            " [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "    0.00000000e+00  0.00000000e+00]\n",
            "  [-1.16036032e+00  3.91216202e-01  9.57308975e-01 ... -2.47796139e-01\n",
            "   -2.99543487e-01 -1.32775161e+00]\n",
            "  [-1.52581005e+00 -8.16145615e-01  5.99452545e-01 ...  1.26658886e-01\n",
            "    7.40909596e-01 -1.81930332e-01]\n",
            "  ...\n",
            "  [-1.95273307e-01  7.48658579e-01 -1.61778074e-01 ...  8.31960705e-01\n",
            "    3.46063063e-01  1.93967349e+00]\n",
            "  [-3.28934626e-01  6.68780626e-01 -1.35754641e-03 ... -3.47563983e-01\n",
            "    2.31768449e-01 -1.57199950e-01]\n",
            "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "    0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "    0.00000000e+00  0.00000000e+00]\n",
            "  [ 7.97180453e-03 -6.57329432e-02 -8.10748902e-01 ... -2.59334723e-01\n",
            "   -9.18509119e-01 -3.37333495e-01]\n",
            "  [ 1.07868433e-02 -3.87417612e-01 -4.23295025e-01 ...  1.53839996e+00\n",
            "    1.15339653e+00 -4.71474029e-01]\n",
            "  ...\n",
            "  [-8.76112913e-01  4.58634577e-01  2.14303418e-01 ... -8.62633498e-01\n",
            "   -1.50390459e+00  1.84262486e+00]\n",
            "  [-8.01543349e-01  5.92028759e-01  3.87946689e-01 ...  1.49202475e+00\n",
            "    1.86666082e+00 -3.95229968e-01]\n",
            "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "    0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            " [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "    0.00000000e+00  0.00000000e+00]\n",
            "  [-2.03533729e-01 -7.43168673e-02 -5.71765987e-01 ...  7.42201382e-01\n",
            "   -1.29727515e-01  3.95053807e-01]\n",
            "  [ 1.34164826e-01 -1.58896802e-01 -8.23171884e-01 ... -4.38567299e-01\n",
            "   -4.92738019e-02  2.40947015e-01]\n",
            "  ...\n",
            "  [-7.34629076e-01  4.84680464e-01  3.30450860e-01 ... -1.35523882e-01\n",
            "    7.99223330e-01 -9.83523158e-02]\n",
            "  [-8.01651606e-01  5.30808112e-01  3.26764271e-01 ...  1.28547441e-01\n",
            "   -3.71419198e-01 -1.78025954e-01]\n",
            "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "    0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            " [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "    0.00000000e+00  0.00000000e+00]\n",
            "  [-1.94482544e-01 -2.06930733e-01 -4.31755598e-01 ... -2.43715554e-01\n",
            "    3.45752910e-01  9.91889355e-01]\n",
            "  [ 9.32427186e-02 -1.08254958e-01 -8.41135948e-01 ...  1.12778784e+00\n",
            "    2.10943714e-01  4.63630477e-02]\n",
            "  ...\n",
            "  [-7.22258829e-01  2.79648967e-01  3.23811867e-01 ... -7.22662336e-01\n",
            "   -4.12735315e-01  1.92502187e+00]\n",
            "  [-7.30115645e-01  4.95177717e-01  2.94648973e-01 ... -3.95950444e-02\n",
            "   -7.32681374e-01 -6.08784453e-01]\n",
            "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
            "    0.00000000e+00  0.00000000e+00]]]\n",
            "(208620, 15)\n",
            "(207400,)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import  keras\n",
        "from tensorflow.keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam # - Works\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "#from tensorflow.keras.utils import utils #np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "\n",
        "from operator import truediv\n",
        "\n",
        "from plotly.offline import init_notebook_mode\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "init_notebook_mode(connected=True)\n",
        "%matplotlib inline\n",
        "\n",
        "def loadData(name):\n",
        "    #data_path = os.path.join(os.getcwd(),'data')\n",
        "    #data_path='/content/drive/MyDrive/data_indian'\n",
        "    if name == 'IP':\n",
        "        data_path='/content/drive/MyDrive/data_hyper'\n",
        "        data = sio.loadmat(os.path.join(data_path, 'Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
        "    elif name == 'SA':\n",
        "        data_path='/content/drive/MyDrive/data_hyper'\n",
        "        data = sio.loadmat(os.path.join(data_path, 'Salinas_corrected.mat'))['salinas_corrected']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'Salinas_gt.mat'))['salinas_gt']\n",
        "    elif name == 'PU':\n",
        "        data_path='/content/drive/MyDrive/data_hyper'\n",
        "        data = sio.loadmat(os.path.join(data_path, 'PaviaU.mat'))['paviaU']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU_gt.mat'))['paviaU_gt']\n",
        "    \n",
        "    return data, labels\n",
        "\n",
        "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
        "                                                        stratify=y)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def applyPCA(X, numComponents=75):\n",
        "    newX = np.reshape(X, (-1, X.shape[2]))\n",
        "    pca = PCA(n_components=numComponents, whiten=True)\n",
        "    newX = pca.fit_transform(newX)\n",
        "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
        "    return newX, pca\n",
        "\n",
        "## GLOBAL VARIABLES\n",
        "dataset = 'PU'\n",
        "test_ratio = 0.2 # VALIDATION SPLIT\n",
        "\n",
        "X, y = loadData(dataset)\n",
        "\n",
        "X.shape, y.shape\n",
        "\n",
        "K = 30 if dataset == 'IP' else 15\n",
        "#K=120\n",
        "X,pca = applyPCA(X,numComponents=K)\n",
        "\n",
        "X.shape\n",
        "\n",
        "zeros=np.zeros((y.shape[0],y.shape[1]+2,K)) # zeros from left and right\n",
        "zeros[0:y.shape[0],1:y.shape[1]+1,:]=X # [1,y.shape[1]+1)\n",
        "X_padded=zeros\n",
        "print(X_padded)\n",
        "input_flatten=X_padded.reshape(-1,K) #check how it is reshaped\n",
        "label=y.reshape(y.shape[0]*y.shape[1])\n",
        "#print(input_flatten)\n",
        "print(input_flatten.shape)\n",
        "print(label.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqu_uw3L72YC",
        "outputId": "863eb5fd-1646-4d50-e7c6-94dee7ed8c9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5eKXEAdZ8kl",
        "outputId": "192a8046-dee9-49c3-c5b2-e196ed3e056f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed time : 3.076359987258911\n"
          ]
        }
      ],
      "source": [
        "import time \n",
        "start=time.time()\n",
        "input_big=np.zeros([y.shape[0]*y.shape[1],K*3])\n",
        "list1=[]\n",
        "count=0\n",
        "ind1=0\n",
        "ind2=1\n",
        "\n",
        "for i in range(0,input_flatten.shape[0]) :\n",
        "  if input_flatten[i,:].all() != np.zeros([1,K]).all(): ##\n",
        "    list1.append(i)\n",
        "    l=input_flatten[i-1,:]\n",
        "    m=input_flatten[i,:]\n",
        "    r=input_flatten[i+1,:]\n",
        "    row=np.concatenate((l, m,r), axis=0)\n",
        "    row.reshape([1,row.shape[0]])\n",
        "    input_big[count,:]=row\n",
        "    count=count+1\n",
        "\n",
        "end=time.time()\n",
        "print(f\"elapsed time : {end - start}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL2Nc1fK7Ycu",
        "outputId": "493a3725-209b-4b1b-afe1-bc743e7497da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " elapsed time : 4.4021241664886475 \n"
          ]
        }
      ],
      "source": [
        "#try dot product method to reduce the input to 32\n",
        "start=time.time()\n",
        "import numpy as np\n",
        "\n",
        "input_big=np.zeros([y.shape[0]*y.shape[1],K + 2])\n",
        "list1=[]\n",
        "count=0\n",
        "ind1=0\n",
        "ind2=1\n",
        "\n",
        "for i in range(0,input_flatten.shape[0]) :\n",
        "  if input_flatten[i,:].all() != np.zeros([1,K]).all(): ##\n",
        "    list1.append(i)\n",
        "    l=input_flatten[i-1,:]\n",
        "    m=input_flatten[i,:]\n",
        "    r=input_flatten[i+1,:]\n",
        "    row=np.concatenate(  (   [abs( np.dot(m, l) )] , m , [abs( np.dot(m, r) )]    ), axis=0 )\n",
        "    row.reshape([1,row.shape[0]])\n",
        "    input_big[count,:]=row\n",
        "    count=count+1\n",
        "end=time.time()\n",
        "print(f\" elapsed time : {end - start} \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbYTs7X6aYoj",
        "outputId": "a39030b8-86ef-469e-ba96-a078fee73bf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "207400\n",
            "(207400, 45)\n",
            "(207400,)\n",
            "(207400, 45)\n",
            "(array([     0,      1,      2, ..., 207397, 207398, 207399]),)\n",
            "(164624,)\n",
            "(42776, 45)\n",
            "(42776, 45)\n",
            "(85552, 45)\n",
            "(207400,)\n",
            "(42776,)\n",
            "(85552,)\n"
          ]
        }
      ],
      "source": [
        "print(len(list1))\n",
        "#print(list1)\n",
        "print(input_big.shape)\n",
        "#print(input_big)\n",
        "print(label.shape)\n",
        "#normalize \n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1)) #make sure you did normalization in a correct way\n",
        "scaled_samples = scaler.fit_transform(input_big.reshape(-1,3*K)) ##### old .reshape(-1,3*K) not needed\n",
        "#scaled_samples = scaler.fit_transform(input_big.reshape(-1,K+2))\n",
        "print(scaled_samples.shape)\n",
        "# get the indices of blank pixels \n",
        "# they are found in the label \n",
        "result = np. where(label == 0)\n",
        "print(result)\n",
        "print(result[0].shape)\n",
        "#for index in result[0]:\n",
        "  #print(index)\n",
        "scaled_samples_withoutzero=np.delete(scaled_samples, result[0], axis=0)\n",
        "print(scaled_samples_withoutzero.shape)\n",
        "\n",
        "# add more data\n",
        "#old\n",
        "a=scaled_samples_withoutzero[:,0:K]\n",
        "m=scaled_samples_withoutzero[:,K:2*K] #should we add 1?\n",
        "b=scaled_samples_withoutzero[:,2*K:3*K] #should we add 1?\n",
        "#a=scaled_samples_withoutzero[:,0:1]\n",
        "#m=scaled_samples_withoutzero[:,1:K+1]\n",
        "#b=scaled_samples_withoutzero[:,K+1:K+2]\n",
        "\n",
        "scaled_samples2=np.concatenate((b, m,a), axis=1)\n",
        "\n",
        "print(scaled_samples2.shape)\n",
        "#duplicate\n",
        "scaled_samples_duplicate=np.concatenate((scaled_samples_withoutzero,scaled_samples2), axis=0)\n",
        "print(scaled_samples_duplicate.shape)\n",
        "print(label.shape)\n",
        "label_withoutzero=np.delete(label, result[0], axis=0)\n",
        "print(label_withoutzero.shape)\n",
        "label_duplicate=np.concatenate( ( label_withoutzero , label_withoutzero ) , axis=0 )\n",
        "print(label_duplicate.shape)\n",
        "\n",
        "#subtract one\n",
        "label_duplicate=label_duplicate - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Vq-fjTUnTfp"
      },
      "source": [
        "I need to remove rows that correspond to blank pixel from scaled samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkRa47fgiXJ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77834d15-a762-4f1a-fbb5-f068b7b37b9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.14981061 0.26210349 0.42856506 ... 0.27877577 0.48531029 0.35759125]\n",
            " [0.14536897 0.41136936 0.43371367 ... 0.27385269 0.48933966 0.35313988]\n",
            " [0.14421738 0.41094607 0.4374574  ... 0.27637756 0.48613922 0.36339411]\n",
            " ...\n",
            " [0.13064548 0.40007608 0.44973635 ... 0.27304639 0.49273097 0.35641058]\n",
            " [0.11303287 0.21711226 0.45518463 ... 0.27387358 0.48234331 0.35866548]\n",
            " [0.18446771 0.26261939 0.4369453  ... 0.2829602  0.4916563  0.35952726]]\n",
            "[6 1 1 ... 1 0 2]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils import shuffle\n",
        "X_shuff=scaled_samples_duplicate\n",
        "y_shuff = label_duplicate\n",
        "X_shuff, y_shuff = shuffle(X_shuff, y_shuff, random_state=0)\n",
        "print(X_shuff)\n",
        "print(y_shuff)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_shuff.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w71MZDWY_2wP",
        "outputId": "6a7afc04-f14a-44a8-f3fd-d2634f0aad5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(85552,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.shape)\n",
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWSGsVxK3noo",
        "outputId": "5f93b192-d9a7-4456-8cb3-57eb67b49f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(610, 340)\n",
            "(610, 340, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split into test and training set \n",
        "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
        "                                                        stratify=y)\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "Qzhrr6LR4RBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test=splitTrainTestSet(X_shuff,y_shuff, testRatio=0.1, randomState=345)"
      ],
      "metadata": {
        "id": "Ur7fum382ddT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGfa4p5Y5ZSQ"
      },
      "source": [
        "# Preprocess without PCA "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "VpF6rpi95pAs",
        "outputId": "7221dd00-45fe-457f-f84e-bf4610c3fb7b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow import  keras\n",
        "from tensorflow.keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam # - Works\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "#from tensorflow.keras.utils import utils #np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "\n",
        "from operator import truediv\n",
        "\n",
        "from plotly.offline import init_notebook_mode\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "init_notebook_mode(connected=True)\n",
        "%matplotlib inline\n",
        "\n",
        "def loadData(name):\n",
        "    #data_path = os.path.join(os.getcwd(),'data')\n",
        "    #data_path='/content/drive/MyDrive/data_indian'\n",
        "    if name == 'IP':\n",
        "        data_path='/content/drive/MyDrive/data_hyper'\n",
        "        data = sio.loadmat(os.path.join(data_path, 'Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
        "    elif name == 'SA':\n",
        "        data_path='/content/drive/MyDrive/data_hyper'\n",
        "        data = sio.loadmat(os.path.join(data_path, 'Salinas_corrected.mat'))['salinas_corrected']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'Salinas_gt.mat'))['salinas_gt']\n",
        "    elif name == 'PU':\n",
        "        data_path='/content/drive/MyDrive/data_hyper'\n",
        "        data = sio.loadmat(os.path.join(data_path, 'PaviaU.mat'))['paviaU']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU_gt.mat'))['paviaU_gt']\n",
        "    \n",
        "    return data, labels\n",
        "\n",
        "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
        "                                                        stratify=y)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TykfJPXI5q9b",
        "outputId": "72cec70a-83fc-40b5-df35-fc589c1da9c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((610, 340, 103), (610, 340))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "## GLOBAL VARIABLES\n",
        "dataset = 'PU'\n",
        "test_ratio = 0.2 # VALIDATION SPLIT\n",
        "#load data\n",
        "X, y = loadData(dataset)\n",
        "X.shape, y.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KCCrzjm7cTs"
      },
      "outputs": [],
      "source": [
        "\n",
        "#preprocessing\n",
        "K=X.shape[2]\n",
        "zeros=np.zeros((y.shape[0],y.shape[1]+2,K)) # zeros from left and right\n",
        "zeros[0:y.shape[0],1:y.shape[1]+1,:]=X # [1,y.shape[1]+1)\n",
        "X_padded=zeros\n",
        "input_flatten=X_padded.reshape(-1,K) #check how it is reshaped\n",
        "label=y.reshape(y.shape[0]*y.shape[1])\n",
        "input_big=np.zeros([y.shape[0]*y.shape[1],K*3])\n",
        "list1=[]\n",
        "count=0\n",
        "ind1=0\n",
        "ind2=1\n",
        "\n",
        "for i in range(0,input_flatten.shape[0]) :\n",
        "  if input_flatten[i,:].all() != np.zeros([1,K]).all(): ##\n",
        "    list1.append(i)\n",
        "    l=input_flatten[i-1,:]\n",
        "    m=input_flatten[i,:]\n",
        "    r=input_flatten[i+1,:]\n",
        "    row=np.concatenate((l, m,r), axis=0)\n",
        "    row.reshape([1,row.shape[0]])\n",
        "    input_big[count,:]=row\n",
        "    count=count+1\n",
        "\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1))  # make sure you did normalization in a correct way\n",
        "scaled_samples = scaler.fit_transform(input_big.reshape(-1,3*K)) ##### was 30\n",
        "\n",
        "# get the indices of blank pixels \n",
        "# they are found in the label \n",
        "result = np. where(label == 0) # in real scenerio this is not found \n",
        "scaled_samples_withoutzero=np.delete(scaled_samples, result[0], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4zMfbVl7eyY",
        "outputId": "f8ef9f89-a3a8-4ca1-83b3-04a17ad654b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(85552, 309)\n",
            "(207400,)\n",
            "(42776,)\n",
            "(85552,)\n"
          ]
        }
      ],
      "source": [
        "# add more data\n",
        "#old\n",
        "a=scaled_samples_withoutzero[:,0:K]\n",
        "m=scaled_samples_withoutzero[:,K:2*K] #should we add 1?\n",
        "b=scaled_samples_withoutzero[:,2*K:3*K] #should we add 1?\n",
        "#a=scaled_samples_withoutzero[:,0:1]\n",
        "#m=scaled_samples_withoutzero[:,1:K+1]\n",
        "#b=scaled_samples_withoutzero[:,K+1:K+2]\n",
        "\n",
        "scaled_samples2=np.concatenate((b, m,a), axis=1)\n",
        "\n",
        "#duplicate\n",
        "scaled_samples_duplicate=np.concatenate((scaled_samples_withoutzero,scaled_samples2), axis=0)\n",
        "print(scaled_samples_duplicate.shape)\n",
        "\n",
        "print(label.shape)\n",
        "label_withoutzero=np.delete(label, result[0], axis=0)\n",
        "print(label_withoutzero.shape)\n",
        "label_duplicate=np.concatenate( ( label_withoutzero , label_withoutzero ) , axis=0 )\n",
        "print(label_duplicate.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7Tf5UTm8AH8"
      },
      "outputs": [],
      "source": [
        "#subtract one\n",
        "label_duplicate=label_duplicate - 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX1mOYDo5enm"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC0ubg0WEfUf"
      },
      "source": [
        "# Preprocess with modified PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Clx-x9ILEePD",
        "outputId": "eaffb23b-e54c-4de9-ae27-05b9a8ffc4f8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tensorflow import  keras\n",
        "from tensorflow.keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam # - Works\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "#from tensorflow.keras.utils import utils #np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "\n",
        "from operator import truediv\n",
        "\n",
        "from plotly.offline import init_notebook_mode\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "init_notebook_mode(connected=True)\n",
        "%matplotlib inline\n",
        "\n",
        "def loadData(name):\n",
        "    #data_path = os.path.join(os.getcwd(),'data')\n",
        "    #data_path='/content/drive/MyDrive/data_indian'\n",
        "    if name == 'IP':\n",
        "        data_path='/content/drive/MyDrive/data_hyper'\n",
        "        data = sio.loadmat(os.path.join(data_path, 'Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
        "    elif name == 'SA':\n",
        "        data_path='/content/drive/MyDrive/data_hyper'\n",
        "        data = sio.loadmat(os.path.join(data_path, 'Salinas_corrected.mat'))['salinas_corrected']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'Salinas_gt.mat'))['salinas_gt']\n",
        "    elif name == 'PU':\n",
        "        data_path='/content/drive/MyDrive/data_hyper'\n",
        "        data = sio.loadmat(os.path.join(data_path, 'PaviaU.mat'))['paviaU']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU_gt.mat'))['paviaU_gt']\n",
        "    \n",
        "    return data, labels\n",
        "\n",
        "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
        "                                                        stratify=y)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def my_applyPCA(X, numComponents=75):\n",
        "    start_learn=time.time()\n",
        "    newX_reshaped = np.reshape(X, (-1, X.shape[2]))\n",
        "    pca = PCA(n_components=numComponents, whiten=True)\n",
        "    pca.fit_transform(newX_reshaped)\n",
        "    end_learn=time.time()\n",
        "    components=pca.components_\n",
        "    #print(f' components shape {components.shape}')\n",
        "    #print(f' components  {components[:,0]}')\n",
        "    start_project=time.time()\n",
        "    newX=np.dot(components,newX_reshaped.T - pca.mean_.reshape(-1,1))\n",
        "    #print(newX.shape)\n",
        "    #print(newX[:,0])\n",
        "    newX=newX.T\n",
        "    #print(newX.shape)\n",
        "    newX=np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
        "    end_project=time.time()\n",
        "    print(f\"time taken to learn {end_learn-start_learn}\")\n",
        "    print(f\"time taken to project {end_project-start_project}\")\n",
        "    print(f\"total time taken  {end_project-start_learn}\")\n",
        "    return newX, pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlH0OpyBGY2g",
        "outputId": "03f45b87-f027-4130-d816-1d155257e318"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time taken to learn 2.81906795501709\n",
            "time taken to project 0.1065683364868164\n",
            "total time taken  2.9256420135498047\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(610, 340, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "## GLOBAL VARIABLES\n",
        "dataset = 'PU'\n",
        "test_ratio = 0.2 # VALIDATION SPLIT\n",
        "X, y = loadData(dataset)\n",
        "\n",
        "X.shape, y.shape\n",
        "\n",
        "K = 30 if dataset == 'IP' else 15\n",
        "#K=120\n",
        "X,pca = my_applyPCA(X,numComponents=K)\n",
        "\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhkyRwpLHzFw",
        "outputId": "6d8b4fed-7283-4fe6-8535-a7ed9ccb720c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-5150.19004357  6795.05276995  1532.35146075   410.03013362\n",
            "  -259.85615715  -832.89897019   293.23977612   278.3852123\n",
            "  -285.60996876   251.20856963  -283.85345611    11.78175473\n",
            "    92.30653989    -9.5491515    -59.46923742]\n"
          ]
        }
      ],
      "source": [
        "print(X[0,0,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJSoiA-4ItEX"
      },
      "outputs": [],
      "source": [
        "zeros=np.zeros((y.shape[0],y.shape[1]+2,K)) # zeros from left and right\n",
        "zeros[0:y.shape[0],1:y.shape[1]+1,:]=X # [1,y.shape[1]+1)\n",
        "X_padded=zeros\n",
        "print(X_padded)\n",
        "input_flatten=X_padded.reshape(-1,K) #check how it is reshaped\n",
        "label=y.reshape(y.shape[0]*y.shape[1])\n",
        "#print(input_flatten)\n",
        "print(input_flatten.shape)\n",
        "print(label.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylrPQxYqJAkm",
        "outputId": "c1ebf1ad-ae38-4df6-e686-c04183b5c485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed time : 2.4401004314422607\n"
          ]
        }
      ],
      "source": [
        "import time \n",
        "start=time.time()\n",
        "input_big=np.zeros([y.shape[0]*y.shape[1],K*3])\n",
        "list1=[]\n",
        "count=0\n",
        "ind1=0\n",
        "ind2=1\n",
        "\n",
        "for i in range(0,input_flatten.shape[0]) :\n",
        "  if input_flatten[i,:].all() != np.zeros([1,K]).all(): ##\n",
        "    #list1.append(i)\n",
        "    l,m,r=input_flatten[i-1,:],input_flatten[i,:],input_flatten[i+1,:]\n",
        "    #m=input_flatten[i,:]\n",
        "    #r=input_flatten[i+1,:]\n",
        "    row=np.concatenate((l, m,r), axis=0)\n",
        "    #row.reshape([1,row.shape[0]])\n",
        "  \n",
        "    input_big[count,:]=row\n",
        "    count=count+1\n",
        "\n",
        "end=time.time()\n",
        "print(f\"elapsed time : {end - start}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time \n",
        "start=time.time()\n",
        "input_big=np.zeros([y.shape[0]*y.shape[1],K*3])\n",
        "list1=[]\n",
        "count=0\n",
        "ind1=0\n",
        "ind2=1\n",
        "\n",
        "for i in range(0,input_flatten.shape[0]) :\n",
        "  if input_flatten[i,:].all() != np.zeros([1,K]).all(): ##\n",
        "\n",
        "    input_big[count,:]=np.concatenate((input_flatten[i-1,:], input_flatten[i,:],input_flatten[i+1,:]), axis=0)\n",
        "    count=count+1\n",
        "\n",
        "end=time.time()\n",
        "print(f\"elapsed time : {end - start}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrPhR7t0Yn-3",
        "outputId": "6e1bd5d9-e1bb-4c28-d15c-aca29f51fbf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "elapsed time : 2.472507953643799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WLNJrY4JpEI",
        "outputId": "32b0ccfe-efc3-404d-eb5f-c5506393aafe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "207400\n",
            "(207400, 45)\n",
            "(207400,)\n",
            "(207400, 45)\n",
            "(array([     0,      1,      2, ..., 207397, 207398, 207399]),)\n",
            "(164624,)\n",
            "(42776, 45)\n"
          ]
        }
      ],
      "source": [
        "print(len(list1))\n",
        "#print(list1)\n",
        "print(input_big.shape)\n",
        "#print(input_big)\n",
        "print(label.shape)\n",
        "#normalize \n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1)) #make sure you did normalization in a correct way\n",
        "scaled_samples = scaler.fit_transform(input_big.reshape(-1,3*K)) ##### old .reshape(-1,3*K) not needed\n",
        "#scaled_samples = scaler.fit_transform(input_big.reshape(-1,K+2))\n",
        "print(scaled_samples.shape)\n",
        "# get the indices of blank pixels \n",
        "# they are found in the label \n",
        "result = np. where(label == 0)\n",
        "print(result)\n",
        "print(result[0].shape)\n",
        "#for index in result[0]:\n",
        "  #print(index)\n",
        "scaled_samples_withoutzero=np.delete(scaled_samples, result[0], axis=0)\n",
        "print(scaled_samples_withoutzero.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJSbSPQoJrEw",
        "outputId": "40ee4a0d-f311-4974-93ab-18ee19eff157"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(42776, 45)\n",
            "(85552, 45)\n",
            "(207400,)\n",
            "(42776,)\n",
            "(85552,)\n"
          ]
        }
      ],
      "source": [
        "# add more data\n",
        "#old\n",
        "a=scaled_samples_withoutzero[:,0:K]\n",
        "m=scaled_samples_withoutzero[:,K:2*K] #should we add 1?\n",
        "b=scaled_samples_withoutzero[:,2*K:3*K] #should we add 1?\n",
        "#a=scaled_samples_withoutzero[:,0:1]\n",
        "#m=scaled_samples_withoutzero[:,1:K+1]\n",
        "#b=scaled_samples_withoutzero[:,K+1:K+2]\n",
        "\n",
        "scaled_samples2=np.concatenate((b, m,a), axis=1)\n",
        "\n",
        "print(scaled_samples2.shape)\n",
        "#duplicate\n",
        "scaled_samples_duplicate=np.concatenate((scaled_samples_withoutzero,scaled_samples2), axis=0)\n",
        "print(scaled_samples_duplicate.shape)\n",
        "print(label.shape)\n",
        "label_withoutzero=np.delete(label, result[0], axis=0)\n",
        "print(label_withoutzero.shape)\n",
        "label_duplicate=np.concatenate( ( label_withoutzero , label_withoutzero ) , axis=0 )\n",
        "print(label_duplicate.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWOECriVKDM_"
      },
      "outputs": [],
      "source": [
        "#subtract one\n",
        "label_duplicate=label_duplicate - 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess spectral only"
      ],
      "metadata": {
        "id": "ML9lLzbIqceO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import  keras\n",
        "from tensorflow.keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adam # - Works\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "#from tensorflow.keras.utils import utils #np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "\n",
        "from operator import truediv\n",
        "\n",
        "from plotly.offline import init_notebook_mode\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "init_notebook_mode(connected=True)\n",
        "%matplotlib inline\n",
        "\n",
        "def loadData(name):\n",
        "    #data_path = os.path.join(os.getcwd(),'data')\n",
        "    #data_path='/content/drive/MyDrive/data_indian'\n",
        "    if name == 'IP':\n",
        "        data_path='/content/drive/MyDrive/data_hyper'\n",
        "        data = sio.loadmat(os.path.join(data_path, 'Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'Indian_pines_gt.mat'))['indian_pines_gt']\n",
        "    elif name == 'SA':\n",
        "        data_path='/content/drive/MyDrive/data_hyper'\n",
        "        data = sio.loadmat(os.path.join(data_path, 'Salinas_corrected.mat'))['salinas_corrected']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'Salinas_gt.mat'))['salinas_gt']\n",
        "    elif name == 'PU':\n",
        "        data_path='/content/drive/MyDrive/data_hyper'\n",
        "        data = sio.loadmat(os.path.join(data_path, 'PaviaU.mat'))['paviaU']\n",
        "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU_gt.mat'))['paviaU_gt']\n",
        "    \n",
        "    return data, labels\n",
        "\n",
        "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
        "                                                        stratify=y)\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def applyPCA(X, numComponents=75):\n",
        "    newX = np.reshape(X, (-1, X.shape[2]))\n",
        "    pca = PCA(n_components=numComponents, whiten=True)\n",
        "    newX = pca.fit_transform(newX)\n",
        "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
        "    return newX, pca\n",
        "\n",
        "## GLOBAL VARIABLES\n",
        "dataset = 'PU'\n",
        "test_ratio = 0.2\n",
        "\n",
        "X, y = loadData(dataset)\n",
        "\n",
        "X.shape, y.shape\n",
        "\n",
        "K = 30 if dataset == 'IP' else 15\n",
        "#K=120\n",
        "X,pca = applyPCA(X,numComponents=K)\n",
        "\n",
        "X.shape\n",
        "\n",
        "label=y.reshape(-1)\n",
        "\n",
        "#normalize \n",
        "input=X.reshape(-1,K)\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "scaled_samples = scaler.fit_transform(input) ##### was 30\n",
        "\n",
        "print(scaled_samples.shape)\n",
        "\n",
        "# get the indices of blank pixels \n",
        "# they are found in the label \n",
        "result = np. where(label == 0)\n",
        "print(result)\n",
        "print(result[0].shape)\n",
        "#for index in result[0]:\n",
        "  #print(index)\n",
        "scaled_samples_withoutzero=np.delete(scaled_samples, result[0], axis=0)\n",
        "print(scaled_samples_withoutzero.shape)\n",
        "\n",
        "label_withoutzero=np.delete(label, result[0], axis=0)\n",
        "label_withoutzero=label_withoutzero-1\n",
        "print(label_withoutzero.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "wJ-s0uZdqgG5",
        "outputId": "d9d42932-9513-4aef-bfd4-1295c36f30fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(207400, 15)\n",
            "(array([     0,      1,      2, ..., 207397, 207398, 207399]),)\n",
            "(164624,)\n",
            "(42776, 15)\n",
            "(42776,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMO9p1vSqjcg"
      },
      "source": [
        "# Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rk9rBcVqihn"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense,Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHobN1ixqt7B"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Dense(units=512, input_shape=(3*K,), activation='relu'), #was 30\n",
        "    Dense(units=256, activation='relu',bias_regularizer=l2(0.01)),\n",
        "    Dense(units=128, activation='relu',bias_regularizer=l2(0.01)),\n",
        "    Dense(units=64, activation='relu',bias_regularizer=l2(0.01)),\n",
        "    Dense(units=32, activation='relu',bias_regularizer=l2(0.01)),\n",
        "    Dense(units=256, activation='relu',bias_regularizer=l2(0.01)),\n",
        "    Dense(units=128, activation='relu',bias_regularizer=l2(0.01)),\n",
        "    Dense(units=64, activation='relu',bias_regularizer=l2(0.01)),\n",
        "    Dense(units=32, activation='relu',bias_regularizer=l2(0.01)),\n",
        "    Dropout(0.5),    \n",
        "    Dense(units=9, activation='softmax') # [0,16) ## this is specific to each dataset\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eq3EB0GoWeJP"
      },
      "outputs": [],
      "source": [
        "#train a smaller model test \n",
        "model = Sequential([\n",
        "    Dense(units=256, input_shape=(3*K,), activation='relu'), #was 30\n",
        "    Dense(units=128, activation='relu',bias_regularizer=l2(0.01)),\n",
        "    Dense(units=64, activation='relu',bias_regularizer=l2(0.01)),\n",
        "    Dropout(0.5),    \n",
        "    Dense(units=9, activation='softmax') # [0,16) ## this is specific to each dataset\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFciG4aVjgTQ"
      },
      "outputs": [],
      "source": [
        "#train a smaller model test \n",
        "model = Sequential([\n",
        "    Dense(units=128, input_shape=(3*K,), activation='relu'), #was 30\n",
        "    Dense(units=64, activation='relu',bias_regularizer=l2(0.01)),\n",
        "    Dropout(0.5),    \n",
        "    Dense(units=9, activation='softmax') # [0,16) ## this is specific to each dataset\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcnfFDbADOgH"
      },
      "outputs": [],
      "source": [
        "#train a smaller model test  - two dot plus middle \n",
        "model = Sequential([\n",
        "    Dense(units=128, input_shape=(K+2,), activation='relu'), #was 30\n",
        "    Dense(units=64, activation='relu',bias_regularizer=l2(0.01)),\n",
        "    Dropout(0.5),    \n",
        "    Dense(units=9, activation='softmax') # [0,16) ## this is specific to each dataset\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-p1gUXOXJku"
      },
      "outputs": [],
      "source": [
        "#train a smaller model test spectral-spatial\n",
        "model = Sequential([\n",
        "    Dense(units=64, input_shape=(3*K,), activation='relu'), #was 30\n",
        "    Dense(units=32, activation='relu',bias_regularizer=l2(0.01)),\n",
        "    Dense(units=16, activation='relu',bias_regularizer=l2(0.01)),\n",
        "    #Dropout(0.2),    \n",
        "    Dense(units=9, activation='softmax') # [0,16) ## this is specific to each dataset\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train a smaller model for spectral only \n",
        "model = Sequential([\n",
        "    Dense(units=64, input_shape=(K,), activation='relu'), #was 30\n",
        "    Dense(units=32, activation='relu',bias_regularizer=l2(0.01)),\n",
        "    Dense(units=16, activation='relu',bias_regularizer=l2(0.01)),\n",
        "    #Dropout(0.2),    \n",
        "    Dense(units=9, activation='softmax') # [0,16) ## this is specific to each dataset\n",
        "])\n"
      ],
      "metadata": {
        "id": "Y0ZZ_yaJrAzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZXfTjiYsQZA"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy']) #reviw  0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg8kHb1msTAU",
        "outputId": "0eaa76ab-c0e5-45e1-e322-935f3a8bd808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                2944      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 9)                 153       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,705\n",
            "Trainable params: 5,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for spatial duplicate \n",
        "model.fit(\n",
        "      x=X\n",
        "    , y=y\n",
        "    , validation_split=0.1\n",
        "    , batch_size=10\n",
        "    , epochs=800\n",
        "    , verbose=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCZUZyQhBdoS",
        "outputId": "7fed1964-481b-42ed-94c9-e454a09d63e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "7700/7700 - 33s - loss: 1.0316 - accuracy: 0.6028 - val_loss: 0.6330 - val_accuracy: 0.7196 - 33s/epoch - 4ms/step\n",
            "Epoch 2/200\n",
            "7700/7700 - 33s - loss: 0.7537 - accuracy: 0.6808 - val_loss: 0.5953 - val_accuracy: 0.7262 - 33s/epoch - 4ms/step\n",
            "Epoch 3/200\n",
            "7700/7700 - 35s - loss: 0.6694 - accuracy: 0.7184 - val_loss: 0.5610 - val_accuracy: 0.7592 - 35s/epoch - 5ms/step\n",
            "Epoch 4/200\n",
            "7700/7700 - 31s - loss: 0.6101 - accuracy: 0.7488 - val_loss: 0.4776 - val_accuracy: 0.7830 - 31s/epoch - 4ms/step\n",
            "Epoch 5/200\n",
            "7700/7700 - 31s - loss: 0.5767 - accuracy: 0.7606 - val_loss: 0.4831 - val_accuracy: 0.7911 - 31s/epoch - 4ms/step\n",
            "Epoch 6/200\n",
            "7700/7700 - 31s - loss: 0.5535 - accuracy: 0.7703 - val_loss: 0.4671 - val_accuracy: 0.7931 - 31s/epoch - 4ms/step\n",
            "Epoch 7/200\n",
            "7700/7700 - 31s - loss: 0.5292 - accuracy: 0.7786 - val_loss: 0.4102 - val_accuracy: 0.8049 - 31s/epoch - 4ms/step\n",
            "Epoch 8/200\n",
            "7700/7700 - 31s - loss: 0.4941 - accuracy: 0.7929 - val_loss: 0.3692 - val_accuracy: 0.8467 - 31s/epoch - 4ms/step\n",
            "Epoch 9/200\n",
            "7700/7700 - 31s - loss: 0.4513 - accuracy: 0.8140 - val_loss: 0.3351 - val_accuracy: 0.8588 - 31s/epoch - 4ms/step\n",
            "Epoch 10/200\n",
            "7700/7700 - 31s - loss: 0.4275 - accuracy: 0.8280 - val_loss: 0.3681 - val_accuracy: 0.8498 - 31s/epoch - 4ms/step\n",
            "Epoch 11/200\n",
            "7700/7700 - 31s - loss: 0.4070 - accuracy: 0.8335 - val_loss: 0.3387 - val_accuracy: 0.8543 - 31s/epoch - 4ms/step\n",
            "Epoch 12/200\n",
            "7700/7700 - 30s - loss: 0.3883 - accuracy: 0.8415 - val_loss: 0.2766 - val_accuracy: 0.8693 - 30s/epoch - 4ms/step\n",
            "Epoch 13/200\n",
            "7700/7700 - 29s - loss: 0.3821 - accuracy: 0.8430 - val_loss: 0.3957 - val_accuracy: 0.8373 - 29s/epoch - 4ms/step\n",
            "Epoch 14/200\n",
            "7700/7700 - 29s - loss: 0.3581 - accuracy: 0.8528 - val_loss: 0.2507 - val_accuracy: 0.8921 - 29s/epoch - 4ms/step\n",
            "Epoch 15/200\n",
            "7700/7700 - 30s - loss: 0.3472 - accuracy: 0.8590 - val_loss: 0.2523 - val_accuracy: 0.8877 - 30s/epoch - 4ms/step\n",
            "Epoch 16/200\n",
            "7700/7700 - 30s - loss: 0.3346 - accuracy: 0.8667 - val_loss: 0.2610 - val_accuracy: 0.8816 - 30s/epoch - 4ms/step\n",
            "Epoch 17/200\n",
            "7700/7700 - 30s - loss: 0.3287 - accuracy: 0.8689 - val_loss: 0.2031 - val_accuracy: 0.9258 - 30s/epoch - 4ms/step\n",
            "Epoch 18/200\n",
            "7700/7700 - 30s - loss: 0.3180 - accuracy: 0.8719 - val_loss: 0.2516 - val_accuracy: 0.8910 - 30s/epoch - 4ms/step\n",
            "Epoch 19/200\n",
            "7700/7700 - 31s - loss: 0.3008 - accuracy: 0.8817 - val_loss: 0.2022 - val_accuracy: 0.9125 - 31s/epoch - 4ms/step\n",
            "Epoch 20/200\n",
            "7700/7700 - 30s - loss: 0.2935 - accuracy: 0.8860 - val_loss: 0.2147 - val_accuracy: 0.9135 - 30s/epoch - 4ms/step\n",
            "Epoch 21/200\n",
            "7700/7700 - 29s - loss: 0.2847 - accuracy: 0.8911 - val_loss: 0.1715 - val_accuracy: 0.9309 - 29s/epoch - 4ms/step\n",
            "Epoch 22/200\n",
            "7700/7700 - 30s - loss: 0.2736 - accuracy: 0.8960 - val_loss: 0.1605 - val_accuracy: 0.9492 - 30s/epoch - 4ms/step\n",
            "Epoch 23/200\n",
            "7700/7700 - 30s - loss: 0.2603 - accuracy: 0.9030 - val_loss: 0.3033 - val_accuracy: 0.8927 - 30s/epoch - 4ms/step\n",
            "Epoch 24/200\n",
            "7700/7700 - 30s - loss: 0.2470 - accuracy: 0.9068 - val_loss: 0.1769 - val_accuracy: 0.9275 - 30s/epoch - 4ms/step\n",
            "Epoch 25/200\n",
            "7700/7700 - 29s - loss: 0.2440 - accuracy: 0.9124 - val_loss: 0.2283 - val_accuracy: 0.9122 - 29s/epoch - 4ms/step\n",
            "Epoch 26/200\n",
            "7700/7700 - 29s - loss: 0.2366 - accuracy: 0.9158 - val_loss: 0.2287 - val_accuracy: 0.9097 - 29s/epoch - 4ms/step\n",
            "Epoch 27/200\n",
            "7700/7700 - 29s - loss: 0.2259 - accuracy: 0.9209 - val_loss: 0.2890 - val_accuracy: 0.9143 - 29s/epoch - 4ms/step\n",
            "Epoch 28/200\n",
            "7700/7700 - 29s - loss: 0.2209 - accuracy: 0.9227 - val_loss: 0.1295 - val_accuracy: 0.9566 - 29s/epoch - 4ms/step\n",
            "Epoch 29/200\n",
            "7700/7700 - 29s - loss: 0.2148 - accuracy: 0.9247 - val_loss: 0.1686 - val_accuracy: 0.9286 - 29s/epoch - 4ms/step\n",
            "Epoch 30/200\n",
            "7700/7700 - 29s - loss: 0.2146 - accuracy: 0.9250 - val_loss: 0.1404 - val_accuracy: 0.9427 - 29s/epoch - 4ms/step\n",
            "Epoch 31/200\n",
            "7700/7700 - 29s - loss: 0.2027 - accuracy: 0.9275 - val_loss: 0.1841 - val_accuracy: 0.9306 - 29s/epoch - 4ms/step\n",
            "Epoch 32/200\n",
            "7700/7700 - 29s - loss: 0.2064 - accuracy: 0.9281 - val_loss: 0.1808 - val_accuracy: 0.9261 - 29s/epoch - 4ms/step\n",
            "Epoch 33/200\n",
            "7700/7700 - 29s - loss: 0.1985 - accuracy: 0.9297 - val_loss: 0.3199 - val_accuracy: 0.8824 - 29s/epoch - 4ms/step\n",
            "Epoch 34/200\n",
            "7700/7700 - 29s - loss: 0.1973 - accuracy: 0.9316 - val_loss: 0.1340 - val_accuracy: 0.9442 - 29s/epoch - 4ms/step\n",
            "Epoch 35/200\n",
            "7700/7700 - 29s - loss: 0.1929 - accuracy: 0.9331 - val_loss: 0.1241 - val_accuracy: 0.9508 - 29s/epoch - 4ms/step\n",
            "Epoch 36/200\n",
            "7700/7700 - 29s - loss: 0.1930 - accuracy: 0.9333 - val_loss: 0.1477 - val_accuracy: 0.9452 - 29s/epoch - 4ms/step\n",
            "Epoch 37/200\n",
            "7700/7700 - 29s - loss: 0.1875 - accuracy: 0.9357 - val_loss: 0.1029 - val_accuracy: 0.9654 - 29s/epoch - 4ms/step\n",
            "Epoch 38/200\n",
            "7700/7700 - 29s - loss: 0.1946 - accuracy: 0.9332 - val_loss: 0.1213 - val_accuracy: 0.9543 - 29s/epoch - 4ms/step\n",
            "Epoch 39/200\n",
            "7700/7700 - 29s - loss: 0.1840 - accuracy: 0.9356 - val_loss: 0.1032 - val_accuracy: 0.9637 - 29s/epoch - 4ms/step\n",
            "Epoch 40/200\n",
            "7700/7700 - 28s - loss: 0.1911 - accuracy: 0.9335 - val_loss: 0.1122 - val_accuracy: 0.9606 - 28s/epoch - 4ms/step\n",
            "Epoch 41/200\n",
            "7700/7700 - 29s - loss: 0.1826 - accuracy: 0.9365 - val_loss: 0.1493 - val_accuracy: 0.9398 - 29s/epoch - 4ms/step\n",
            "Epoch 42/200\n",
            "7700/7700 - 28s - loss: 0.1835 - accuracy: 0.9374 - val_loss: 0.1655 - val_accuracy: 0.9410 - 28s/epoch - 4ms/step\n",
            "Epoch 43/200\n",
            "7700/7700 - 28s - loss: 0.1747 - accuracy: 0.9378 - val_loss: 0.1733 - val_accuracy: 0.9320 - 28s/epoch - 4ms/step\n",
            "Epoch 44/200\n",
            "7700/7700 - 29s - loss: 0.1776 - accuracy: 0.9385 - val_loss: 0.1384 - val_accuracy: 0.9503 - 29s/epoch - 4ms/step\n",
            "Epoch 45/200\n",
            "7700/7700 - 28s - loss: 0.1740 - accuracy: 0.9393 - val_loss: 0.1066 - val_accuracy: 0.9628 - 28s/epoch - 4ms/step\n",
            "Epoch 46/200\n",
            "7700/7700 - 28s - loss: 0.1746 - accuracy: 0.9396 - val_loss: 0.1220 - val_accuracy: 0.9542 - 28s/epoch - 4ms/step\n",
            "Epoch 47/200\n",
            "7700/7700 - 28s - loss: 0.1728 - accuracy: 0.9402 - val_loss: 0.1389 - val_accuracy: 0.9457 - 28s/epoch - 4ms/step\n",
            "Epoch 48/200\n",
            "7700/7700 - 28s - loss: 0.1678 - accuracy: 0.9420 - val_loss: 0.1857 - val_accuracy: 0.9285 - 28s/epoch - 4ms/step\n",
            "Epoch 49/200\n",
            "7700/7700 - 28s - loss: 0.1717 - accuracy: 0.9401 - val_loss: 0.0907 - val_accuracy: 0.9686 - 28s/epoch - 4ms/step\n",
            "Epoch 50/200\n",
            "7700/7700 - 29s - loss: 0.1625 - accuracy: 0.9437 - val_loss: 0.1630 - val_accuracy: 0.9379 - 29s/epoch - 4ms/step\n",
            "Epoch 51/200\n",
            "7700/7700 - 28s - loss: 0.1699 - accuracy: 0.9418 - val_loss: 0.0970 - val_accuracy: 0.9681 - 28s/epoch - 4ms/step\n",
            "Epoch 52/200\n",
            "7700/7700 - 28s - loss: 0.1640 - accuracy: 0.9433 - val_loss: 0.0857 - val_accuracy: 0.9690 - 28s/epoch - 4ms/step\n",
            "Epoch 53/200\n",
            "7700/7700 - 28s - loss: 0.1585 - accuracy: 0.9441 - val_loss: 0.1608 - val_accuracy: 0.9434 - 28s/epoch - 4ms/step\n",
            "Epoch 54/200\n",
            "7700/7700 - 28s - loss: 0.1610 - accuracy: 0.9447 - val_loss: 0.1645 - val_accuracy: 0.9357 - 28s/epoch - 4ms/step\n",
            "Epoch 55/200\n",
            "7700/7700 - 28s - loss: 0.1623 - accuracy: 0.9449 - val_loss: 0.0929 - val_accuracy: 0.9703 - 28s/epoch - 4ms/step\n",
            "Epoch 56/200\n",
            "7700/7700 - 29s - loss: 0.1673 - accuracy: 0.9416 - val_loss: 0.1144 - val_accuracy: 0.9592 - 29s/epoch - 4ms/step\n",
            "Epoch 57/200\n",
            "7700/7700 - 29s - loss: 0.1540 - accuracy: 0.9460 - val_loss: 0.1088 - val_accuracy: 0.9577 - 29s/epoch - 4ms/step\n",
            "Epoch 58/200\n",
            "7700/7700 - 28s - loss: 0.1575 - accuracy: 0.9461 - val_loss: 0.2661 - val_accuracy: 0.9079 - 28s/epoch - 4ms/step\n",
            "Epoch 59/200\n",
            "7700/7700 - 28s - loss: 0.1537 - accuracy: 0.9466 - val_loss: 0.0976 - val_accuracy: 0.9613 - 28s/epoch - 4ms/step\n",
            "Epoch 60/200\n",
            "7700/7700 - 28s - loss: 0.1541 - accuracy: 0.9460 - val_loss: 0.0844 - val_accuracy: 0.9684 - 28s/epoch - 4ms/step\n",
            "Epoch 61/200\n",
            "7700/7700 - 29s - loss: 0.1886 - accuracy: 0.9370 - val_loss: 0.1339 - val_accuracy: 0.9486 - 29s/epoch - 4ms/step\n",
            "Epoch 62/200\n",
            "7700/7700 - 29s - loss: 0.1473 - accuracy: 0.9491 - val_loss: 0.2193 - val_accuracy: 0.9197 - 29s/epoch - 4ms/step\n",
            "Epoch 63/200\n",
            "7700/7700 - 28s - loss: 0.1437 - accuracy: 0.9501 - val_loss: 0.0896 - val_accuracy: 0.9638 - 28s/epoch - 4ms/step\n",
            "Epoch 64/200\n",
            "7700/7700 - 28s - loss: 0.1479 - accuracy: 0.9489 - val_loss: 0.0915 - val_accuracy: 0.9661 - 28s/epoch - 4ms/step\n",
            "Epoch 65/200\n",
            "7700/7700 - 29s - loss: 0.1497 - accuracy: 0.9493 - val_loss: 0.1064 - val_accuracy: 0.9577 - 29s/epoch - 4ms/step\n",
            "Epoch 66/200\n",
            "7700/7700 - 29s - loss: 0.1362 - accuracy: 0.9509 - val_loss: 0.0817 - val_accuracy: 0.9702 - 29s/epoch - 4ms/step\n",
            "Epoch 67/200\n",
            "7700/7700 - 29s - loss: 0.1407 - accuracy: 0.9496 - val_loss: 0.0906 - val_accuracy: 0.9652 - 29s/epoch - 4ms/step\n",
            "Epoch 68/200\n",
            "7700/7700 - 29s - loss: 0.1392 - accuracy: 0.9515 - val_loss: 0.1166 - val_accuracy: 0.9552 - 29s/epoch - 4ms/step\n",
            "Epoch 69/200\n",
            "7700/7700 - 29s - loss: 0.1359 - accuracy: 0.9522 - val_loss: 0.0846 - val_accuracy: 0.9684 - 29s/epoch - 4ms/step\n",
            "Epoch 70/200\n",
            "7700/7700 - 29s - loss: 0.1467 - accuracy: 0.9495 - val_loss: 0.2633 - val_accuracy: 0.9017 - 29s/epoch - 4ms/step\n",
            "Epoch 71/200\n",
            "7700/7700 - 29s - loss: 0.1427 - accuracy: 0.9503 - val_loss: 0.0849 - val_accuracy: 0.9690 - 29s/epoch - 4ms/step\n",
            "Epoch 72/200\n",
            "7700/7700 - 29s - loss: 0.1432 - accuracy: 0.9510 - val_loss: 0.1381 - val_accuracy: 0.9481 - 29s/epoch - 4ms/step\n",
            "Epoch 73/200\n",
            "7700/7700 - 30s - loss: 0.1455 - accuracy: 0.9493 - val_loss: 0.1837 - val_accuracy: 0.9289 - 30s/epoch - 4ms/step\n",
            "Epoch 74/200\n",
            "7700/7700 - 29s - loss: 0.1341 - accuracy: 0.9528 - val_loss: 0.1408 - val_accuracy: 0.9427 - 29s/epoch - 4ms/step\n",
            "Epoch 75/200\n",
            "7700/7700 - 29s - loss: 0.1308 - accuracy: 0.9537 - val_loss: 0.0839 - val_accuracy: 0.9694 - 29s/epoch - 4ms/step\n",
            "Epoch 76/200\n",
            "7700/7700 - 29s - loss: 0.1282 - accuracy: 0.9547 - val_loss: 0.0777 - val_accuracy: 0.9681 - 29s/epoch - 4ms/step\n",
            "Epoch 77/200\n",
            "7700/7700 - 29s - loss: 0.1322 - accuracy: 0.9539 - val_loss: 0.1169 - val_accuracy: 0.9549 - 29s/epoch - 4ms/step\n",
            "Epoch 78/200\n",
            "7700/7700 - 29s - loss: 0.1416 - accuracy: 0.9527 - val_loss: 0.0811 - val_accuracy: 0.9669 - 29s/epoch - 4ms/step\n",
            "Epoch 79/200\n",
            "7700/7700 - 29s - loss: 0.1500 - accuracy: 0.9506 - val_loss: 0.0705 - val_accuracy: 0.9727 - 29s/epoch - 4ms/step\n",
            "Epoch 80/200\n",
            "7700/7700 - 29s - loss: 0.1263 - accuracy: 0.9545 - val_loss: 0.0842 - val_accuracy: 0.9707 - 29s/epoch - 4ms/step\n",
            "Epoch 81/200\n",
            "7700/7700 - 29s - loss: 0.1309 - accuracy: 0.9546 - val_loss: 0.1111 - val_accuracy: 0.9587 - 29s/epoch - 4ms/step\n",
            "Epoch 82/200\n",
            "7700/7700 - 29s - loss: 0.1342 - accuracy: 0.9539 - val_loss: 0.0724 - val_accuracy: 0.9729 - 29s/epoch - 4ms/step\n",
            "Epoch 83/200\n",
            "7700/7700 - 29s - loss: 0.1365 - accuracy: 0.9523 - val_loss: 0.1439 - val_accuracy: 0.9418 - 29s/epoch - 4ms/step\n",
            "Epoch 84/200\n",
            "7700/7700 - 29s - loss: 0.1304 - accuracy: 0.9540 - val_loss: 0.0705 - val_accuracy: 0.9725 - 29s/epoch - 4ms/step\n",
            "Epoch 85/200\n",
            "7700/7700 - 29s - loss: 0.1295 - accuracy: 0.9549 - val_loss: 0.1666 - val_accuracy: 0.9378 - 29s/epoch - 4ms/step\n",
            "Epoch 86/200\n",
            "7700/7700 - 29s - loss: 0.1298 - accuracy: 0.9546 - val_loss: 0.0644 - val_accuracy: 0.9765 - 29s/epoch - 4ms/step\n",
            "Epoch 87/200\n",
            "7700/7700 - 29s - loss: 0.1428 - accuracy: 0.9516 - val_loss: 0.0861 - val_accuracy: 0.9679 - 29s/epoch - 4ms/step\n",
            "Epoch 88/200\n",
            "7700/7700 - 32s - loss: 0.1296 - accuracy: 0.9553 - val_loss: 0.0712 - val_accuracy: 0.9719 - 32s/epoch - 4ms/step\n",
            "Epoch 89/200\n",
            "7700/7700 - 30s - loss: 0.1399 - accuracy: 0.9515 - val_loss: 0.0706 - val_accuracy: 0.9725 - 30s/epoch - 4ms/step\n",
            "Epoch 90/200\n",
            "7700/7700 - 29s - loss: 0.1244 - accuracy: 0.9557 - val_loss: 0.1171 - val_accuracy: 0.9493 - 29s/epoch - 4ms/step\n",
            "Epoch 91/200\n",
            "7700/7700 - 29s - loss: 0.1269 - accuracy: 0.9565 - val_loss: 0.1331 - val_accuracy: 0.9447 - 29s/epoch - 4ms/step\n",
            "Epoch 92/200\n",
            "7700/7700 - 29s - loss: 0.1240 - accuracy: 0.9564 - val_loss: 0.1013 - val_accuracy: 0.9631 - 29s/epoch - 4ms/step\n",
            "Epoch 93/200\n",
            "7700/7700 - 29s - loss: 0.1355 - accuracy: 0.9547 - val_loss: 0.0802 - val_accuracy: 0.9721 - 29s/epoch - 4ms/step\n",
            "Epoch 94/200\n",
            "7700/7700 - 29s - loss: 0.1246 - accuracy: 0.9563 - val_loss: 0.0795 - val_accuracy: 0.9670 - 29s/epoch - 4ms/step\n",
            "Epoch 95/200\n",
            "7700/7700 - 29s - loss: 0.1240 - accuracy: 0.9572 - val_loss: 0.0707 - val_accuracy: 0.9704 - 29s/epoch - 4ms/step\n",
            "Epoch 96/200\n",
            "7700/7700 - 30s - loss: 0.1197 - accuracy: 0.9575 - val_loss: 0.1077 - val_accuracy: 0.9550 - 30s/epoch - 4ms/step\n",
            "Epoch 97/200\n",
            "7700/7700 - 32s - loss: 0.1322 - accuracy: 0.9547 - val_loss: 0.0762 - val_accuracy: 0.9702 - 32s/epoch - 4ms/step\n",
            "Epoch 98/200\n",
            "7700/7700 - 29s - loss: 0.1367 - accuracy: 0.9541 - val_loss: 0.1484 - val_accuracy: 0.9530 - 29s/epoch - 4ms/step\n",
            "Epoch 99/200\n",
            "7700/7700 - 29s - loss: 0.1225 - accuracy: 0.9577 - val_loss: 0.1141 - val_accuracy: 0.9549 - 29s/epoch - 4ms/step\n",
            "Epoch 100/200\n",
            "7700/7700 - 29s - loss: 0.1312 - accuracy: 0.9553 - val_loss: 0.0653 - val_accuracy: 0.9744 - 29s/epoch - 4ms/step\n",
            "Epoch 101/200\n",
            "7700/7700 - 29s - loss: 0.1187 - accuracy: 0.9588 - val_loss: 0.1081 - val_accuracy: 0.9620 - 29s/epoch - 4ms/step\n",
            "Epoch 102/200\n",
            "7700/7700 - 29s - loss: 0.1192 - accuracy: 0.9572 - val_loss: 0.0782 - val_accuracy: 0.9683 - 29s/epoch - 4ms/step\n",
            "Epoch 103/200\n",
            "7700/7700 - 29s - loss: 0.1263 - accuracy: 0.9570 - val_loss: 0.0943 - val_accuracy: 0.9632 - 29s/epoch - 4ms/step\n",
            "Epoch 104/200\n",
            "7700/7700 - 29s - loss: 0.1213 - accuracy: 0.9577 - val_loss: 0.1351 - val_accuracy: 0.9400 - 29s/epoch - 4ms/step\n",
            "Epoch 105/200\n",
            "7700/7700 - 29s - loss: 0.1206 - accuracy: 0.9573 - val_loss: 0.0837 - val_accuracy: 0.9667 - 29s/epoch - 4ms/step\n",
            "Epoch 106/200\n",
            "7700/7700 - 29s - loss: 0.1200 - accuracy: 0.9568 - val_loss: 0.1341 - val_accuracy: 0.9435 - 29s/epoch - 4ms/step\n",
            "Epoch 107/200\n",
            "7700/7700 - 29s - loss: 0.1239 - accuracy: 0.9573 - val_loss: 0.0828 - val_accuracy: 0.9688 - 29s/epoch - 4ms/step\n",
            "Epoch 108/200\n",
            "7700/7700 - 30s - loss: 0.1280 - accuracy: 0.9557 - val_loss: 0.0809 - val_accuracy: 0.9718 - 30s/epoch - 4ms/step\n",
            "Epoch 109/200\n",
            "7700/7700 - 31s - loss: 0.1489 - accuracy: 0.9476 - val_loss: 0.0786 - val_accuracy: 0.9711 - 31s/epoch - 4ms/step\n",
            "Epoch 110/200\n",
            "7700/7700 - 30s - loss: 0.1204 - accuracy: 0.9573 - val_loss: 0.0867 - val_accuracy: 0.9639 - 30s/epoch - 4ms/step\n",
            "Epoch 111/200\n",
            "7700/7700 - 30s - loss: 0.1207 - accuracy: 0.9574 - val_loss: 0.0834 - val_accuracy: 0.9683 - 30s/epoch - 4ms/step\n",
            "Epoch 112/200\n",
            "7700/7700 - 30s - loss: 0.1160 - accuracy: 0.9595 - val_loss: 0.1342 - val_accuracy: 0.9557 - 30s/epoch - 4ms/step\n",
            "Epoch 113/200\n",
            "7700/7700 - 30s - loss: 0.1441 - accuracy: 0.9499 - val_loss: 0.0684 - val_accuracy: 0.9723 - 30s/epoch - 4ms/step\n",
            "Epoch 114/200\n",
            "7700/7700 - 29s - loss: 0.1132 - accuracy: 0.9596 - val_loss: 0.0783 - val_accuracy: 0.9697 - 29s/epoch - 4ms/step\n",
            "Epoch 115/200\n",
            "7700/7700 - 29s - loss: 0.1201 - accuracy: 0.9577 - val_loss: 0.0731 - val_accuracy: 0.9718 - 29s/epoch - 4ms/step\n",
            "Epoch 116/200\n",
            "7700/7700 - 29s - loss: 0.1119 - accuracy: 0.9602 - val_loss: 0.1076 - val_accuracy: 0.9590 - 29s/epoch - 4ms/step\n",
            "Epoch 117/200\n",
            "7700/7700 - 31s - loss: 0.1217 - accuracy: 0.9570 - val_loss: 0.0912 - val_accuracy: 0.9665 - 31s/epoch - 4ms/step\n",
            "Epoch 118/200\n",
            "7700/7700 - 29s - loss: 0.1099 - accuracy: 0.9603 - val_loss: 0.1873 - val_accuracy: 0.9293 - 29s/epoch - 4ms/step\n",
            "Epoch 119/200\n",
            "7700/7700 - 29s - loss: 0.1240 - accuracy: 0.9580 - val_loss: 0.1176 - val_accuracy: 0.9548 - 29s/epoch - 4ms/step\n",
            "Epoch 120/200\n",
            "7700/7700 - 29s - loss: 0.1335 - accuracy: 0.9537 - val_loss: 0.0784 - val_accuracy: 0.9709 - 29s/epoch - 4ms/step\n",
            "Epoch 121/200\n",
            "7700/7700 - 29s - loss: 0.1169 - accuracy: 0.9586 - val_loss: 0.1005 - val_accuracy: 0.9622 - 29s/epoch - 4ms/step\n",
            "Epoch 122/200\n",
            "7700/7700 - 29s - loss: 0.1259 - accuracy: 0.9564 - val_loss: 0.1018 - val_accuracy: 0.9612 - 29s/epoch - 4ms/step\n",
            "Epoch 123/200\n",
            "7700/7700 - 29s - loss: 0.1180 - accuracy: 0.9584 - val_loss: 0.1442 - val_accuracy: 0.9432 - 29s/epoch - 4ms/step\n",
            "Epoch 124/200\n",
            "7700/7700 - 29s - loss: 0.1134 - accuracy: 0.9595 - val_loss: 0.0653 - val_accuracy: 0.9742 - 29s/epoch - 4ms/step\n",
            "Epoch 125/200\n",
            "7700/7700 - 29s - loss: 0.1244 - accuracy: 0.9564 - val_loss: 0.2336 - val_accuracy: 0.9196 - 29s/epoch - 4ms/step\n",
            "Epoch 126/200\n",
            "7700/7700 - 29s - loss: 0.1312 - accuracy: 0.9539 - val_loss: 0.1983 - val_accuracy: 0.9507 - 29s/epoch - 4ms/step\n",
            "Epoch 127/200\n",
            "7700/7700 - 29s - loss: 0.1808 - accuracy: 0.9353 - val_loss: 0.0834 - val_accuracy: 0.9684 - 29s/epoch - 4ms/step\n",
            "Epoch 128/200\n",
            "7700/7700 - 29s - loss: 0.1360 - accuracy: 0.9529 - val_loss: 0.0862 - val_accuracy: 0.9670 - 29s/epoch - 4ms/step\n",
            "Epoch 129/200\n",
            "7700/7700 - 28s - loss: 0.1198 - accuracy: 0.9583 - val_loss: 0.1550 - val_accuracy: 0.9474 - 28s/epoch - 4ms/step\n",
            "Epoch 130/200\n",
            "7700/7700 - 29s - loss: 0.1203 - accuracy: 0.9583 - val_loss: 0.0742 - val_accuracy: 0.9742 - 29s/epoch - 4ms/step\n",
            "Epoch 131/200\n",
            "7700/7700 - 28s - loss: 0.1285 - accuracy: 0.9549 - val_loss: 0.0859 - val_accuracy: 0.9679 - 28s/epoch - 4ms/step\n",
            "Epoch 132/200\n",
            "7700/7700 - 29s - loss: 0.1158 - accuracy: 0.9599 - val_loss: 0.0741 - val_accuracy: 0.9727 - 29s/epoch - 4ms/step\n",
            "Epoch 133/200\n",
            "7700/7700 - 29s - loss: 0.1123 - accuracy: 0.9603 - val_loss: 0.0808 - val_accuracy: 0.9689 - 29s/epoch - 4ms/step\n",
            "Epoch 134/200\n",
            "7700/7700 - 29s - loss: 0.1091 - accuracy: 0.9619 - val_loss: 0.0674 - val_accuracy: 0.9755 - 29s/epoch - 4ms/step\n",
            "Epoch 135/200\n",
            "7700/7700 - 29s - loss: 0.1202 - accuracy: 0.9585 - val_loss: 0.1065 - val_accuracy: 0.9646 - 29s/epoch - 4ms/step\n",
            "Epoch 136/200\n",
            "7700/7700 - 29s - loss: 0.1435 - accuracy: 0.9491 - val_loss: 0.1301 - val_accuracy: 0.9532 - 29s/epoch - 4ms/step\n",
            "Epoch 137/200\n",
            "7700/7700 - 29s - loss: 0.1241 - accuracy: 0.9574 - val_loss: 0.1155 - val_accuracy: 0.9559 - 29s/epoch - 4ms/step\n",
            "Epoch 138/200\n",
            "7700/7700 - 29s - loss: 0.1138 - accuracy: 0.9611 - val_loss: 0.0704 - val_accuracy: 0.9741 - 29s/epoch - 4ms/step\n",
            "Epoch 139/200\n",
            "7700/7700 - 29s - loss: 0.1309 - accuracy: 0.9539 - val_loss: 0.1089 - val_accuracy: 0.9583 - 29s/epoch - 4ms/step\n",
            "Epoch 140/200\n",
            "7700/7700 - 29s - loss: 0.1177 - accuracy: 0.9594 - val_loss: 0.0950 - val_accuracy: 0.9665 - 29s/epoch - 4ms/step\n",
            "Epoch 141/200\n",
            "7700/7700 - 29s - loss: 0.1194 - accuracy: 0.9599 - val_loss: 0.0816 - val_accuracy: 0.9686 - 29s/epoch - 4ms/step\n",
            "Epoch 142/200\n",
            "7700/7700 - 29s - loss: 0.1128 - accuracy: 0.9606 - val_loss: 0.1133 - val_accuracy: 0.9613 - 29s/epoch - 4ms/step\n",
            "Epoch 143/200\n",
            "7700/7700 - 29s - loss: 0.1306 - accuracy: 0.9549 - val_loss: 0.1648 - val_accuracy: 0.9367 - 29s/epoch - 4ms/step\n",
            "Epoch 144/200\n",
            "7700/7700 - 30s - loss: 0.1352 - accuracy: 0.9546 - val_loss: 0.0938 - val_accuracy: 0.9625 - 30s/epoch - 4ms/step\n",
            "Epoch 145/200\n",
            "7700/7700 - 29s - loss: 0.1115 - accuracy: 0.9595 - val_loss: 0.0814 - val_accuracy: 0.9689 - 29s/epoch - 4ms/step\n",
            "Epoch 146/200\n",
            "7700/7700 - 29s - loss: 0.1348 - accuracy: 0.9549 - val_loss: 0.0929 - val_accuracy: 0.9679 - 29s/epoch - 4ms/step\n",
            "Epoch 147/200\n",
            "7700/7700 - 29s - loss: 0.1186 - accuracy: 0.9591 - val_loss: 0.1162 - val_accuracy: 0.9591 - 29s/epoch - 4ms/step\n",
            "Epoch 148/200\n",
            "7700/7700 - 29s - loss: 0.1116 - accuracy: 0.9610 - val_loss: 0.0855 - val_accuracy: 0.9676 - 29s/epoch - 4ms/step\n",
            "Epoch 149/200\n",
            "7700/7700 - 29s - loss: 0.1095 - accuracy: 0.9627 - val_loss: 0.1545 - val_accuracy: 0.9563 - 29s/epoch - 4ms/step\n",
            "Epoch 150/200\n",
            "7700/7700 - 29s - loss: 0.1202 - accuracy: 0.9573 - val_loss: 0.0876 - val_accuracy: 0.9703 - 29s/epoch - 4ms/step\n",
            "Epoch 151/200\n",
            "7700/7700 - 29s - loss: 0.1124 - accuracy: 0.9605 - val_loss: 0.0797 - val_accuracy: 0.9722 - 29s/epoch - 4ms/step\n",
            "Epoch 152/200\n",
            "7700/7700 - 29s - loss: 0.1232 - accuracy: 0.9585 - val_loss: 0.0795 - val_accuracy: 0.9686 - 29s/epoch - 4ms/step\n",
            "Epoch 153/200\n",
            "7700/7700 - 29s - loss: 0.1287 - accuracy: 0.9582 - val_loss: 0.0690 - val_accuracy: 0.9728 - 29s/epoch - 4ms/step\n",
            "Epoch 154/200\n",
            "7700/7700 - 29s - loss: 0.1094 - accuracy: 0.9618 - val_loss: 0.0684 - val_accuracy: 0.9722 - 29s/epoch - 4ms/step\n",
            "Epoch 155/200\n",
            "7700/7700 - 29s - loss: 0.1318 - accuracy: 0.9550 - val_loss: 0.0750 - val_accuracy: 0.9715 - 29s/epoch - 4ms/step\n",
            "Epoch 156/200\n",
            "7700/7700 - 29s - loss: 0.1105 - accuracy: 0.9622 - val_loss: 0.2008 - val_accuracy: 0.9289 - 29s/epoch - 4ms/step\n",
            "Epoch 157/200\n",
            "7700/7700 - 29s - loss: 0.1095 - accuracy: 0.9619 - val_loss: 0.0795 - val_accuracy: 0.9716 - 29s/epoch - 4ms/step\n",
            "Epoch 158/200\n",
            "7700/7700 - 29s - loss: 0.1231 - accuracy: 0.9580 - val_loss: 0.0747 - val_accuracy: 0.9744 - 29s/epoch - 4ms/step\n",
            "Epoch 159/200\n",
            "7700/7700 - 29s - loss: 0.1451 - accuracy: 0.9513 - val_loss: 0.0691 - val_accuracy: 0.9760 - 29s/epoch - 4ms/step\n",
            "Epoch 160/200\n",
            "7700/7700 - 30s - loss: 0.1158 - accuracy: 0.9602 - val_loss: 0.0553 - val_accuracy: 0.9794 - 30s/epoch - 4ms/step\n",
            "Epoch 161/200\n",
            "7700/7700 - 29s - loss: 0.1210 - accuracy: 0.9588 - val_loss: 0.1281 - val_accuracy: 0.9527 - 29s/epoch - 4ms/step\n",
            "Epoch 162/200\n",
            "7700/7700 - 29s - loss: 0.1118 - accuracy: 0.9632 - val_loss: 0.0653 - val_accuracy: 0.9771 - 29s/epoch - 4ms/step\n",
            "Epoch 163/200\n",
            "7700/7700 - 30s - loss: 0.1455 - accuracy: 0.9508 - val_loss: 0.0578 - val_accuracy: 0.9773 - 30s/epoch - 4ms/step\n",
            "Epoch 164/200\n",
            "7700/7700 - 30s - loss: 0.1096 - accuracy: 0.9621 - val_loss: 0.1086 - val_accuracy: 0.9614 - 30s/epoch - 4ms/step\n",
            "Epoch 165/200\n",
            "7700/7700 - 32s - loss: 0.1429 - accuracy: 0.9520 - val_loss: 0.0844 - val_accuracy: 0.9697 - 32s/epoch - 4ms/step\n",
            "Epoch 166/200\n",
            "7700/7700 - 29s - loss: 0.1171 - accuracy: 0.9596 - val_loss: 0.0983 - val_accuracy: 0.9665 - 29s/epoch - 4ms/step\n",
            "Epoch 167/200\n",
            "7700/7700 - 29s - loss: 0.1107 - accuracy: 0.9622 - val_loss: 0.0741 - val_accuracy: 0.9675 - 29s/epoch - 4ms/step\n",
            "Epoch 168/200\n",
            "7700/7700 - 29s - loss: 0.1281 - accuracy: 0.9580 - val_loss: 0.0628 - val_accuracy: 0.9776 - 29s/epoch - 4ms/step\n",
            "Epoch 169/200\n",
            "7700/7700 - 29s - loss: 0.1220 - accuracy: 0.9593 - val_loss: 0.0627 - val_accuracy: 0.9760 - 29s/epoch - 4ms/step\n",
            "Epoch 170/200\n",
            "7700/7700 - 29s - loss: 0.1157 - accuracy: 0.9608 - val_loss: 0.0763 - val_accuracy: 0.9721 - 29s/epoch - 4ms/step\n",
            "Epoch 171/200\n",
            "7700/7700 - 30s - loss: 0.1112 - accuracy: 0.9615 - val_loss: 0.0611 - val_accuracy: 0.9772 - 30s/epoch - 4ms/step\n",
            "Epoch 172/200\n",
            "7700/7700 - 29s - loss: 0.1290 - accuracy: 0.9580 - val_loss: 0.0741 - val_accuracy: 0.9738 - 29s/epoch - 4ms/step\n",
            "Epoch 173/200\n",
            "7700/7700 - 29s - loss: 0.2587 - accuracy: 0.9068 - val_loss: 0.0944 - val_accuracy: 0.9676 - 29s/epoch - 4ms/step\n",
            "Epoch 174/200\n",
            "7700/7700 - 29s - loss: 0.1244 - accuracy: 0.9575 - val_loss: 0.6351 - val_accuracy: 0.8891 - 29s/epoch - 4ms/step\n",
            "Epoch 175/200\n",
            "7700/7700 - 29s - loss: 0.1175 - accuracy: 0.9597 - val_loss: 0.0739 - val_accuracy: 0.9717 - 29s/epoch - 4ms/step\n",
            "Epoch 176/200\n",
            "7700/7700 - 29s - loss: 0.1416 - accuracy: 0.9506 - val_loss: 0.1420 - val_accuracy: 0.9557 - 29s/epoch - 4ms/step\n",
            "Epoch 177/200\n",
            "7700/7700 - 29s - loss: 0.1485 - accuracy: 0.9507 - val_loss: 0.0741 - val_accuracy: 0.9730 - 29s/epoch - 4ms/step\n",
            "Epoch 178/200\n",
            "7700/7700 - 29s - loss: 0.1142 - accuracy: 0.9606 - val_loss: 0.0611 - val_accuracy: 0.9795 - 29s/epoch - 4ms/step\n",
            "Epoch 179/200\n",
            "7700/7700 - 29s - loss: 0.1689 - accuracy: 0.9414 - val_loss: 0.1214 - val_accuracy: 0.9573 - 29s/epoch - 4ms/step\n",
            "Epoch 180/200\n",
            "7700/7700 - 29s - loss: 0.1533 - accuracy: 0.9488 - val_loss: 0.1743 - val_accuracy: 0.9340 - 29s/epoch - 4ms/step\n",
            "Epoch 181/200\n",
            "7700/7700 - 29s - loss: 0.1184 - accuracy: 0.9602 - val_loss: 0.0760 - val_accuracy: 0.9721 - 29s/epoch - 4ms/step\n",
            "Epoch 182/200\n",
            "7700/7700 - 29s - loss: 0.1262 - accuracy: 0.9583 - val_loss: 0.0952 - val_accuracy: 0.9683 - 29s/epoch - 4ms/step\n",
            "Epoch 183/200\n",
            "7700/7700 - 29s - loss: 0.1072 - accuracy: 0.9626 - val_loss: 0.0889 - val_accuracy: 0.9653 - 29s/epoch - 4ms/step\n",
            "Epoch 184/200\n",
            "7700/7700 - 29s - loss: 0.2069 - accuracy: 0.9315 - val_loss: 0.1321 - val_accuracy: 0.9522 - 29s/epoch - 4ms/step\n",
            "Epoch 185/200\n",
            "7700/7700 - 29s - loss: 0.1594 - accuracy: 0.9482 - val_loss: 0.1692 - val_accuracy: 0.9413 - 29s/epoch - 4ms/step\n",
            "Epoch 186/200\n",
            "7700/7700 - 29s - loss: 0.1353 - accuracy: 0.9540 - val_loss: 0.0988 - val_accuracy: 0.9612 - 29s/epoch - 4ms/step\n",
            "Epoch 187/200\n",
            "7700/7700 - 29s - loss: 0.1413 - accuracy: 0.9521 - val_loss: 0.0898 - val_accuracy: 0.9674 - 29s/epoch - 4ms/step\n",
            "Epoch 188/200\n",
            "7700/7700 - 29s - loss: 0.1391 - accuracy: 0.9539 - val_loss: 0.0845 - val_accuracy: 0.9709 - 29s/epoch - 4ms/step\n",
            "Epoch 189/200\n",
            "7700/7700 - 29s - loss: 0.1340 - accuracy: 0.9545 - val_loss: 0.0962 - val_accuracy: 0.9684 - 29s/epoch - 4ms/step\n",
            "Epoch 190/200\n",
            "7700/7700 - 29s - loss: 0.1492 - accuracy: 0.9524 - val_loss: 0.0701 - val_accuracy: 0.9752 - 29s/epoch - 4ms/step\n",
            "Epoch 191/200\n",
            "7700/7700 - 29s - loss: 0.1160 - accuracy: 0.9601 - val_loss: 0.1293 - val_accuracy: 0.9440 - 29s/epoch - 4ms/step\n",
            "Epoch 192/200\n",
            "7700/7700 - 29s - loss: 0.1233 - accuracy: 0.9588 - val_loss: 0.0698 - val_accuracy: 0.9752 - 29s/epoch - 4ms/step\n",
            "Epoch 193/200\n",
            "7700/7700 - 29s - loss: 0.1251 - accuracy: 0.9571 - val_loss: 0.1584 - val_accuracy: 0.9459 - 29s/epoch - 4ms/step\n",
            "Epoch 194/200\n",
            "7700/7700 - 29s - loss: 0.1286 - accuracy: 0.9564 - val_loss: 0.0835 - val_accuracy: 0.9708 - 29s/epoch - 4ms/step\n",
            "Epoch 195/200\n",
            "7700/7700 - 29s - loss: 0.1207 - accuracy: 0.9598 - val_loss: 0.0865 - val_accuracy: 0.9680 - 29s/epoch - 4ms/step\n",
            "Epoch 196/200\n",
            "7700/7700 - 29s - loss: 0.1359 - accuracy: 0.9556 - val_loss: 0.0922 - val_accuracy: 0.9656 - 29s/epoch - 4ms/step\n",
            "Epoch 197/200\n",
            "7700/7700 - 29s - loss: 0.2460 - accuracy: 0.9156 - val_loss: 0.1465 - val_accuracy: 0.9563 - 29s/epoch - 4ms/step\n",
            "Epoch 198/200\n",
            "7700/7700 - 29s - loss: 0.1718 - accuracy: 0.9436 - val_loss: 0.0971 - val_accuracy: 0.9644 - 29s/epoch - 4ms/step\n",
            "Epoch 199/200\n",
            "7700/7700 - 29s - loss: 0.1644 - accuracy: 0.9470 - val_loss: 0.0793 - val_accuracy: 0.9727 - 29s/epoch - 4ms/step\n",
            "Epoch 200/200\n",
            "7700/7700 - 29s - loss: 0.1319 - accuracy: 0.9554 - val_loss: 0.0941 - val_accuracy: 0.9659 - 29s/epoch - 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4cfa0d35d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "summary of the previous results \n",
        "max ac 96 at 200\n",
        "after 200 barely there is an improvement "
      ],
      "metadata": {
        "id": "OXB7BRxwS6Aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train a smaller model test spectral-spatial winth independent test split  \n",
        "\n",
        "model.fit(\n",
        "    \n",
        "      x=X_train\n",
        "    , y=y_train\n",
        "    , validation_split=0.1\n",
        "    , batch_size=10\n",
        "    , epochs=800\n",
        "    , verbose=2\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nT9uY_W5AHv",
        "outputId": "93afa84a-cad4-44e1-b22a-2e4ae64286c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "6930/6930 - 13s - loss: 1.3244 - accuracy: 0.5400 - val_loss: 0.9531 - val_accuracy: 0.6196 - 13s/epoch - 2ms/step\n",
            "Epoch 2/800\n",
            "6930/6930 - 12s - loss: 0.8478 - accuracy: 0.6414 - val_loss: 0.7714 - val_accuracy: 0.6736 - 12s/epoch - 2ms/step\n",
            "Epoch 3/800\n",
            "6930/6930 - 12s - loss: 0.7167 - accuracy: 0.7011 - val_loss: 0.6706 - val_accuracy: 0.7009 - 12s/epoch - 2ms/step\n",
            "Epoch 4/800\n",
            "6930/6930 - 12s - loss: 0.6360 - accuracy: 0.7331 - val_loss: 0.6066 - val_accuracy: 0.7342 - 12s/epoch - 2ms/step\n",
            "Epoch 5/800\n",
            "6930/6930 - 12s - loss: 0.5986 - accuracy: 0.7434 - val_loss: 0.5850 - val_accuracy: 0.7400 - 12s/epoch - 2ms/step\n",
            "Epoch 6/800\n",
            "6930/6930 - 12s - loss: 0.5800 - accuracy: 0.7480 - val_loss: 0.5697 - val_accuracy: 0.7448 - 12s/epoch - 2ms/step\n",
            "Epoch 7/800\n",
            "6930/6930 - 12s - loss: 0.5666 - accuracy: 0.7532 - val_loss: 0.5644 - val_accuracy: 0.7445 - 12s/epoch - 2ms/step\n",
            "Epoch 8/800\n",
            "6930/6930 - 12s - loss: 0.5555 - accuracy: 0.7562 - val_loss: 0.5476 - val_accuracy: 0.7590 - 12s/epoch - 2ms/step\n",
            "Epoch 9/800\n",
            "6930/6930 - 12s - loss: 0.5461 - accuracy: 0.7608 - val_loss: 0.5383 - val_accuracy: 0.7622 - 12s/epoch - 2ms/step\n",
            "Epoch 10/800\n",
            "6930/6930 - 12s - loss: 0.5378 - accuracy: 0.7634 - val_loss: 0.5314 - val_accuracy: 0.7709 - 12s/epoch - 2ms/step\n",
            "Epoch 11/800\n",
            "6930/6930 - 12s - loss: 0.5301 - accuracy: 0.7681 - val_loss: 0.5261 - val_accuracy: 0.7719 - 12s/epoch - 2ms/step\n",
            "Epoch 12/800\n",
            "6930/6930 - 12s - loss: 0.5234 - accuracy: 0.7715 - val_loss: 0.5197 - val_accuracy: 0.7730 - 12s/epoch - 2ms/step\n",
            "Epoch 13/800\n",
            "6930/6930 - 12s - loss: 0.5167 - accuracy: 0.7745 - val_loss: 0.5121 - val_accuracy: 0.7806 - 12s/epoch - 2ms/step\n",
            "Epoch 14/800\n",
            "6930/6930 - 12s - loss: 0.5104 - accuracy: 0.7780 - val_loss: 0.5048 - val_accuracy: 0.7806 - 12s/epoch - 2ms/step\n",
            "Epoch 15/800\n",
            "6930/6930 - 12s - loss: 0.5042 - accuracy: 0.7817 - val_loss: 0.5001 - val_accuracy: 0.7881 - 12s/epoch - 2ms/step\n",
            "Epoch 16/800\n",
            "6930/6930 - 12s - loss: 0.4981 - accuracy: 0.7838 - val_loss: 0.4947 - val_accuracy: 0.7826 - 12s/epoch - 2ms/step\n",
            "Epoch 17/800\n",
            "6930/6930 - 12s - loss: 0.4914 - accuracy: 0.7871 - val_loss: 0.4892 - val_accuracy: 0.7887 - 12s/epoch - 2ms/step\n",
            "Epoch 18/800\n",
            "6930/6930 - 12s - loss: 0.4865 - accuracy: 0.7900 - val_loss: 0.4811 - val_accuracy: 0.7971 - 12s/epoch - 2ms/step\n",
            "Epoch 19/800\n",
            "6930/6930 - 12s - loss: 0.4804 - accuracy: 0.7924 - val_loss: 0.4752 - val_accuracy: 0.7969 - 12s/epoch - 2ms/step\n",
            "Epoch 20/800\n",
            "6930/6930 - 12s - loss: 0.4748 - accuracy: 0.7961 - val_loss: 0.4704 - val_accuracy: 0.7947 - 12s/epoch - 2ms/step\n",
            "Epoch 21/800\n",
            "6930/6930 - 12s - loss: 0.4677 - accuracy: 0.7989 - val_loss: 0.4760 - val_accuracy: 0.8008 - 12s/epoch - 2ms/step\n",
            "Epoch 22/800\n",
            "6930/6930 - 12s - loss: 0.4610 - accuracy: 0.8020 - val_loss: 0.4552 - val_accuracy: 0.8019 - 12s/epoch - 2ms/step\n",
            "Epoch 23/800\n",
            "6930/6930 - 12s - loss: 0.4542 - accuracy: 0.8065 - val_loss: 0.4496 - val_accuracy: 0.8051 - 12s/epoch - 2ms/step\n",
            "Epoch 24/800\n",
            "6930/6930 - 12s - loss: 0.4466 - accuracy: 0.8119 - val_loss: 0.4434 - val_accuracy: 0.8273 - 12s/epoch - 2ms/step\n",
            "Epoch 25/800\n",
            "6930/6930 - 12s - loss: 0.4386 - accuracy: 0.8166 - val_loss: 0.4352 - val_accuracy: 0.8223 - 12s/epoch - 2ms/step\n",
            "Epoch 26/800\n",
            "6930/6930 - 12s - loss: 0.4288 - accuracy: 0.8234 - val_loss: 0.4206 - val_accuracy: 0.8290 - 12s/epoch - 2ms/step\n",
            "Epoch 27/800\n",
            "6930/6930 - 12s - loss: 0.4170 - accuracy: 0.8318 - val_loss: 0.4072 - val_accuracy: 0.8399 - 12s/epoch - 2ms/step\n",
            "Epoch 28/800\n",
            "6930/6930 - 12s - loss: 0.4070 - accuracy: 0.8367 - val_loss: 0.3970 - val_accuracy: 0.8449 - 12s/epoch - 2ms/step\n",
            "Epoch 29/800\n",
            "6930/6930 - 12s - loss: 0.3979 - accuracy: 0.8407 - val_loss: 0.4011 - val_accuracy: 0.8343 - 12s/epoch - 2ms/step\n",
            "Epoch 30/800\n",
            "6930/6930 - 12s - loss: 0.3891 - accuracy: 0.8455 - val_loss: 0.3894 - val_accuracy: 0.8501 - 12s/epoch - 2ms/step\n",
            "Epoch 31/800\n",
            "6930/6930 - 12s - loss: 0.3802 - accuracy: 0.8493 - val_loss: 0.3751 - val_accuracy: 0.8522 - 12s/epoch - 2ms/step\n",
            "Epoch 32/800\n",
            "6930/6930 - 12s - loss: 0.3721 - accuracy: 0.8527 - val_loss: 0.3651 - val_accuracy: 0.8538 - 12s/epoch - 2ms/step\n",
            "Epoch 33/800\n",
            "6930/6930 - 12s - loss: 0.3650 - accuracy: 0.8560 - val_loss: 0.3646 - val_accuracy: 0.8530 - 12s/epoch - 2ms/step\n",
            "Epoch 34/800\n",
            "6930/6930 - 12s - loss: 0.3581 - accuracy: 0.8586 - val_loss: 0.3475 - val_accuracy: 0.8632 - 12s/epoch - 2ms/step\n",
            "Epoch 35/800\n",
            "6930/6930 - 12s - loss: 0.3509 - accuracy: 0.8624 - val_loss: 0.3451 - val_accuracy: 0.8634 - 12s/epoch - 2ms/step\n",
            "Epoch 36/800\n",
            "6930/6930 - 12s - loss: 0.3458 - accuracy: 0.8635 - val_loss: 0.3631 - val_accuracy: 0.8429 - 12s/epoch - 2ms/step\n",
            "Epoch 37/800\n",
            "6930/6930 - 12s - loss: 0.3389 - accuracy: 0.8659 - val_loss: 0.3377 - val_accuracy: 0.8692 - 12s/epoch - 2ms/step\n",
            "Epoch 38/800\n",
            "6930/6930 - 12s - loss: 0.3332 - accuracy: 0.8685 - val_loss: 0.3288 - val_accuracy: 0.8697 - 12s/epoch - 2ms/step\n",
            "Epoch 39/800\n",
            "6930/6930 - 12s - loss: 0.3283 - accuracy: 0.8709 - val_loss: 0.3272 - val_accuracy: 0.8677 - 12s/epoch - 2ms/step\n",
            "Epoch 40/800\n",
            "6930/6930 - 12s - loss: 0.3225 - accuracy: 0.8715 - val_loss: 0.3150 - val_accuracy: 0.8773 - 12s/epoch - 2ms/step\n",
            "Epoch 41/800\n",
            "6930/6930 - 12s - loss: 0.3180 - accuracy: 0.8737 - val_loss: 0.3112 - val_accuracy: 0.8819 - 12s/epoch - 2ms/step\n",
            "Epoch 42/800\n",
            "6930/6930 - 12s - loss: 0.3132 - accuracy: 0.8765 - val_loss: 0.3256 - val_accuracy: 0.8673 - 12s/epoch - 2ms/step\n",
            "Epoch 43/800\n",
            "6930/6930 - 12s - loss: 0.3088 - accuracy: 0.8783 - val_loss: 0.3162 - val_accuracy: 0.8765 - 12s/epoch - 2ms/step\n",
            "Epoch 44/800\n",
            "6930/6930 - 12s - loss: 0.3053 - accuracy: 0.8790 - val_loss: 0.3257 - val_accuracy: 0.8684 - 12s/epoch - 2ms/step\n",
            "Epoch 45/800\n",
            "6930/6930 - 12s - loss: 0.3005 - accuracy: 0.8821 - val_loss: 0.2984 - val_accuracy: 0.8857 - 12s/epoch - 2ms/step\n",
            "Epoch 46/800\n",
            "6930/6930 - 12s - loss: 0.2963 - accuracy: 0.8832 - val_loss: 0.2861 - val_accuracy: 0.8905 - 12s/epoch - 2ms/step\n",
            "Epoch 47/800\n",
            "6930/6930 - 12s - loss: 0.2931 - accuracy: 0.8830 - val_loss: 0.2826 - val_accuracy: 0.8932 - 12s/epoch - 2ms/step\n",
            "Epoch 48/800\n",
            "6930/6930 - 12s - loss: 0.2908 - accuracy: 0.8858 - val_loss: 0.2837 - val_accuracy: 0.8882 - 12s/epoch - 2ms/step\n",
            "Epoch 49/800\n",
            "6930/6930 - 12s - loss: 0.2873 - accuracy: 0.8864 - val_loss: 0.2793 - val_accuracy: 0.8939 - 12s/epoch - 2ms/step\n",
            "Epoch 50/800\n",
            "6930/6930 - 12s - loss: 0.2840 - accuracy: 0.8871 - val_loss: 0.2816 - val_accuracy: 0.8938 - 12s/epoch - 2ms/step\n",
            "Epoch 51/800\n",
            "6930/6930 - 12s - loss: 0.2811 - accuracy: 0.8897 - val_loss: 0.2880 - val_accuracy: 0.8877 - 12s/epoch - 2ms/step\n",
            "Epoch 52/800\n",
            "6930/6930 - 12s - loss: 0.2775 - accuracy: 0.8910 - val_loss: 0.2703 - val_accuracy: 0.8970 - 12s/epoch - 2ms/step\n",
            "Epoch 53/800\n",
            "6930/6930 - 12s - loss: 0.2758 - accuracy: 0.8908 - val_loss: 0.2694 - val_accuracy: 0.8975 - 12s/epoch - 2ms/step\n",
            "Epoch 54/800\n",
            "6930/6930 - 12s - loss: 0.2740 - accuracy: 0.8921 - val_loss: 0.2716 - val_accuracy: 0.8951 - 12s/epoch - 2ms/step\n",
            "Epoch 55/800\n",
            "6930/6930 - 12s - loss: 0.2710 - accuracy: 0.8933 - val_loss: 0.2776 - val_accuracy: 0.8899 - 12s/epoch - 2ms/step\n",
            "Epoch 56/800\n",
            "6930/6930 - 12s - loss: 0.2687 - accuracy: 0.8935 - val_loss: 0.2676 - val_accuracy: 0.8932 - 12s/epoch - 2ms/step\n",
            "Epoch 57/800\n",
            "6930/6930 - 12s - loss: 0.2668 - accuracy: 0.8944 - val_loss: 0.2604 - val_accuracy: 0.9003 - 12s/epoch - 2ms/step\n",
            "Epoch 58/800\n",
            "6930/6930 - 12s - loss: 0.2644 - accuracy: 0.8966 - val_loss: 0.2626 - val_accuracy: 0.8999 - 12s/epoch - 2ms/step\n",
            "Epoch 59/800\n",
            "6930/6930 - 12s - loss: 0.2627 - accuracy: 0.8966 - val_loss: 0.2544 - val_accuracy: 0.9021 - 12s/epoch - 2ms/step\n",
            "Epoch 60/800\n",
            "6930/6930 - 12s - loss: 0.2613 - accuracy: 0.8974 - val_loss: 0.2632 - val_accuracy: 0.9009 - 12s/epoch - 2ms/step\n",
            "Epoch 61/800\n",
            "6930/6930 - 12s - loss: 0.2594 - accuracy: 0.8988 - val_loss: 0.2511 - val_accuracy: 0.9047 - 12s/epoch - 2ms/step\n",
            "Epoch 62/800\n",
            "6930/6930 - 12s - loss: 0.2569 - accuracy: 0.8994 - val_loss: 0.2643 - val_accuracy: 0.8979 - 12s/epoch - 2ms/step\n",
            "Epoch 63/800\n",
            "6930/6930 - 12s - loss: 0.2559 - accuracy: 0.8994 - val_loss: 0.2616 - val_accuracy: 0.9000 - 12s/epoch - 2ms/step\n",
            "Epoch 64/800\n",
            "6930/6930 - 12s - loss: 0.2543 - accuracy: 0.9011 - val_loss: 0.2515 - val_accuracy: 0.9068 - 12s/epoch - 2ms/step\n",
            "Epoch 65/800\n",
            "6930/6930 - 12s - loss: 0.2542 - accuracy: 0.9007 - val_loss: 0.2462 - val_accuracy: 0.9096 - 12s/epoch - 2ms/step\n",
            "Epoch 66/800\n",
            "6930/6930 - 12s - loss: 0.2519 - accuracy: 0.9024 - val_loss: 0.2445 - val_accuracy: 0.9099 - 12s/epoch - 2ms/step\n",
            "Epoch 67/800\n",
            "6930/6930 - 12s - loss: 0.2508 - accuracy: 0.9025 - val_loss: 0.2514 - val_accuracy: 0.9032 - 12s/epoch - 2ms/step\n",
            "Epoch 68/800\n",
            "6930/6930 - 12s - loss: 0.2492 - accuracy: 0.9032 - val_loss: 0.2413 - val_accuracy: 0.9101 - 12s/epoch - 2ms/step\n",
            "Epoch 69/800\n",
            "6930/6930 - 12s - loss: 0.2479 - accuracy: 0.9026 - val_loss: 0.2580 - val_accuracy: 0.8994 - 12s/epoch - 2ms/step\n",
            "Epoch 70/800\n",
            "6930/6930 - 12s - loss: 0.2472 - accuracy: 0.9037 - val_loss: 0.2436 - val_accuracy: 0.9084 - 12s/epoch - 2ms/step\n",
            "Epoch 71/800\n",
            "6930/6930 - 12s - loss: 0.2462 - accuracy: 0.9043 - val_loss: 0.2414 - val_accuracy: 0.9103 - 12s/epoch - 2ms/step\n",
            "Epoch 72/800\n",
            "6930/6930 - 12s - loss: 0.2445 - accuracy: 0.9048 - val_loss: 0.2418 - val_accuracy: 0.9088 - 12s/epoch - 2ms/step\n",
            "Epoch 73/800\n",
            "6930/6930 - 12s - loss: 0.2423 - accuracy: 0.9057 - val_loss: 0.2528 - val_accuracy: 0.8994 - 12s/epoch - 2ms/step\n",
            "Epoch 74/800\n",
            "6930/6930 - 12s - loss: 0.2421 - accuracy: 0.9061 - val_loss: 0.2841 - val_accuracy: 0.8888 - 12s/epoch - 2ms/step\n",
            "Epoch 75/800\n",
            "6930/6930 - 12s - loss: 0.2411 - accuracy: 0.9066 - val_loss: 0.2333 - val_accuracy: 0.9129 - 12s/epoch - 2ms/step\n",
            "Epoch 76/800\n",
            "6930/6930 - 12s - loss: 0.2397 - accuracy: 0.9067 - val_loss: 0.2339 - val_accuracy: 0.9119 - 12s/epoch - 2ms/step\n",
            "Epoch 77/800\n",
            "6930/6930 - 12s - loss: 0.2385 - accuracy: 0.9074 - val_loss: 0.2555 - val_accuracy: 0.9031 - 12s/epoch - 2ms/step\n",
            "Epoch 78/800\n",
            "6930/6930 - 12s - loss: 0.2378 - accuracy: 0.9079 - val_loss: 0.2452 - val_accuracy: 0.9081 - 12s/epoch - 2ms/step\n",
            "Epoch 79/800\n",
            "6930/6930 - 12s - loss: 0.2381 - accuracy: 0.9077 - val_loss: 0.2602 - val_accuracy: 0.9013 - 12s/epoch - 2ms/step\n",
            "Epoch 80/800\n",
            "6930/6930 - 12s - loss: 0.2366 - accuracy: 0.9083 - val_loss: 0.2347 - val_accuracy: 0.9117 - 12s/epoch - 2ms/step\n",
            "Epoch 81/800\n",
            "6930/6930 - 12s - loss: 0.2348 - accuracy: 0.9092 - val_loss: 0.2280 - val_accuracy: 0.9162 - 12s/epoch - 2ms/step\n",
            "Epoch 82/800\n",
            "6930/6930 - 12s - loss: 0.2345 - accuracy: 0.9101 - val_loss: 0.2329 - val_accuracy: 0.9117 - 12s/epoch - 2ms/step\n",
            "Epoch 83/800\n",
            "6930/6930 - 12s - loss: 0.2326 - accuracy: 0.9105 - val_loss: 0.2293 - val_accuracy: 0.9130 - 12s/epoch - 2ms/step\n",
            "Epoch 84/800\n",
            "6930/6930 - 12s - loss: 0.2320 - accuracy: 0.9101 - val_loss: 0.2350 - val_accuracy: 0.9130 - 12s/epoch - 2ms/step\n",
            "Epoch 85/800\n",
            "6930/6930 - 12s - loss: 0.2303 - accuracy: 0.9114 - val_loss: 0.2371 - val_accuracy: 0.9108 - 12s/epoch - 2ms/step\n",
            "Epoch 86/800\n",
            "6930/6930 - 11s - loss: 0.2299 - accuracy: 0.9114 - val_loss: 0.2209 - val_accuracy: 0.9182 - 11s/epoch - 2ms/step\n",
            "Epoch 87/800\n",
            "6930/6930 - 12s - loss: 0.2294 - accuracy: 0.9102 - val_loss: 0.2224 - val_accuracy: 0.9162 - 12s/epoch - 2ms/step\n",
            "Epoch 88/800\n",
            "6930/6930 - 12s - loss: 0.2275 - accuracy: 0.9122 - val_loss: 0.2579 - val_accuracy: 0.9031 - 12s/epoch - 2ms/step\n",
            "Epoch 89/800\n",
            "6930/6930 - 12s - loss: 0.2268 - accuracy: 0.9125 - val_loss: 0.2234 - val_accuracy: 0.9152 - 12s/epoch - 2ms/step\n",
            "Epoch 90/800\n",
            "6930/6930 - 12s - loss: 0.2265 - accuracy: 0.9117 - val_loss: 0.2231 - val_accuracy: 0.9142 - 12s/epoch - 2ms/step\n",
            "Epoch 91/800\n",
            "6930/6930 - 12s - loss: 0.2245 - accuracy: 0.9137 - val_loss: 0.2178 - val_accuracy: 0.9171 - 12s/epoch - 2ms/step\n",
            "Epoch 92/800\n",
            "6930/6930 - 11s - loss: 0.2244 - accuracy: 0.9133 - val_loss: 0.2237 - val_accuracy: 0.9177 - 11s/epoch - 2ms/step\n",
            "Epoch 93/800\n",
            "6930/6930 - 12s - loss: 0.2239 - accuracy: 0.9132 - val_loss: 0.2201 - val_accuracy: 0.9162 - 12s/epoch - 2ms/step\n",
            "Epoch 94/800\n",
            "6930/6930 - 11s - loss: 0.2217 - accuracy: 0.9155 - val_loss: 0.2203 - val_accuracy: 0.9140 - 11s/epoch - 2ms/step\n",
            "Epoch 95/800\n",
            "6930/6930 - 12s - loss: 0.2210 - accuracy: 0.9146 - val_loss: 0.2536 - val_accuracy: 0.9030 - 12s/epoch - 2ms/step\n",
            "Epoch 96/800\n",
            "6930/6930 - 12s - loss: 0.2207 - accuracy: 0.9152 - val_loss: 0.2215 - val_accuracy: 0.9152 - 12s/epoch - 2ms/step\n",
            "Epoch 97/800\n",
            "6930/6930 - 11s - loss: 0.2201 - accuracy: 0.9142 - val_loss: 0.2145 - val_accuracy: 0.9208 - 11s/epoch - 2ms/step\n",
            "Epoch 98/800\n",
            "6930/6930 - 12s - loss: 0.2191 - accuracy: 0.9159 - val_loss: 0.2129 - val_accuracy: 0.9197 - 12s/epoch - 2ms/step\n",
            "Epoch 99/800\n",
            "6930/6930 - 12s - loss: 0.2179 - accuracy: 0.9163 - val_loss: 0.2216 - val_accuracy: 0.9127 - 12s/epoch - 2ms/step\n",
            "Epoch 100/800\n",
            "6930/6930 - 12s - loss: 0.2170 - accuracy: 0.9163 - val_loss: 0.2079 - val_accuracy: 0.9201 - 12s/epoch - 2ms/step\n",
            "Epoch 101/800\n",
            "6930/6930 - 12s - loss: 0.2163 - accuracy: 0.9174 - val_loss: 0.2302 - val_accuracy: 0.9081 - 12s/epoch - 2ms/step\n",
            "Epoch 102/800\n",
            "6930/6930 - 12s - loss: 0.2169 - accuracy: 0.9160 - val_loss: 0.2204 - val_accuracy: 0.9144 - 12s/epoch - 2ms/step\n",
            "Epoch 103/800\n",
            "6930/6930 - 12s - loss: 0.2146 - accuracy: 0.9179 - val_loss: 0.2250 - val_accuracy: 0.9084 - 12s/epoch - 2ms/step\n",
            "Epoch 104/800\n",
            "6930/6930 - 12s - loss: 0.2135 - accuracy: 0.9177 - val_loss: 0.2655 - val_accuracy: 0.8914 - 12s/epoch - 2ms/step\n",
            "Epoch 105/800\n",
            "6930/6930 - 12s - loss: 0.2136 - accuracy: 0.9171 - val_loss: 0.2221 - val_accuracy: 0.9147 - 12s/epoch - 2ms/step\n",
            "Epoch 106/800\n",
            "6930/6930 - 11s - loss: 0.2120 - accuracy: 0.9183 - val_loss: 0.2279 - val_accuracy: 0.9118 - 11s/epoch - 2ms/step\n",
            "Epoch 107/800\n",
            "6930/6930 - 12s - loss: 0.2106 - accuracy: 0.9196 - val_loss: 0.2062 - val_accuracy: 0.9203 - 12s/epoch - 2ms/step\n",
            "Epoch 108/800\n",
            "6930/6930 - 12s - loss: 0.2103 - accuracy: 0.9183 - val_loss: 0.2905 - val_accuracy: 0.8836 - 12s/epoch - 2ms/step\n",
            "Epoch 109/800\n",
            "6930/6930 - 11s - loss: 0.2103 - accuracy: 0.9189 - val_loss: 0.1994 - val_accuracy: 0.9239 - 11s/epoch - 2ms/step\n",
            "Epoch 110/800\n",
            "6930/6930 - 12s - loss: 0.2076 - accuracy: 0.9193 - val_loss: 0.2014 - val_accuracy: 0.9208 - 12s/epoch - 2ms/step\n",
            "Epoch 111/800\n",
            "6930/6930 - 12s - loss: 0.2077 - accuracy: 0.9204 - val_loss: 0.2010 - val_accuracy: 0.9243 - 12s/epoch - 2ms/step\n",
            "Epoch 112/800\n",
            "6930/6930 - 12s - loss: 0.2064 - accuracy: 0.9211 - val_loss: 0.2263 - val_accuracy: 0.9112 - 12s/epoch - 2ms/step\n",
            "Epoch 113/800\n",
            "6930/6930 - 12s - loss: 0.2052 - accuracy: 0.9211 - val_loss: 0.2053 - val_accuracy: 0.9243 - 12s/epoch - 2ms/step\n",
            "Epoch 114/800\n",
            "6930/6930 - 12s - loss: 0.2047 - accuracy: 0.9213 - val_loss: 0.2012 - val_accuracy: 0.9219 - 12s/epoch - 2ms/step\n",
            "Epoch 115/800\n",
            "6930/6930 - 12s - loss: 0.2030 - accuracy: 0.9221 - val_loss: 0.2538 - val_accuracy: 0.9014 - 12s/epoch - 2ms/step\n",
            "Epoch 116/800\n",
            "6930/6930 - 12s - loss: 0.2027 - accuracy: 0.9205 - val_loss: 0.2045 - val_accuracy: 0.9190 - 12s/epoch - 2ms/step\n",
            "Epoch 117/800\n",
            "6930/6930 - 12s - loss: 0.2016 - accuracy: 0.9222 - val_loss: 0.1989 - val_accuracy: 0.9244 - 12s/epoch - 2ms/step\n",
            "Epoch 118/800\n",
            "6930/6930 - 12s - loss: 0.2012 - accuracy: 0.9230 - val_loss: 0.2010 - val_accuracy: 0.9210 - 12s/epoch - 2ms/step\n",
            "Epoch 119/800\n",
            "6930/6930 - 12s - loss: 0.2000 - accuracy: 0.9231 - val_loss: 0.2218 - val_accuracy: 0.9101 - 12s/epoch - 2ms/step\n",
            "Epoch 120/800\n",
            "6930/6930 - 12s - loss: 0.1987 - accuracy: 0.9236 - val_loss: 0.2259 - val_accuracy: 0.9099 - 12s/epoch - 2ms/step\n",
            "Epoch 121/800\n",
            "6930/6930 - 11s - loss: 0.1983 - accuracy: 0.9235 - val_loss: 0.1932 - val_accuracy: 0.9252 - 11s/epoch - 2ms/step\n",
            "Epoch 122/800\n",
            "6930/6930 - 12s - loss: 0.1974 - accuracy: 0.9241 - val_loss: 0.1963 - val_accuracy: 0.9227 - 12s/epoch - 2ms/step\n",
            "Epoch 123/800\n",
            "6930/6930 - 12s - loss: 0.1985 - accuracy: 0.9233 - val_loss: 0.2102 - val_accuracy: 0.9213 - 12s/epoch - 2ms/step\n",
            "Epoch 124/800\n",
            "6930/6930 - 12s - loss: 0.1956 - accuracy: 0.9245 - val_loss: 0.2724 - val_accuracy: 0.8953 - 12s/epoch - 2ms/step\n",
            "Epoch 125/800\n",
            "6930/6930 - 12s - loss: 0.1944 - accuracy: 0.9249 - val_loss: 0.1989 - val_accuracy: 0.9248 - 12s/epoch - 2ms/step\n",
            "Epoch 126/800\n",
            "6930/6930 - 12s - loss: 0.1942 - accuracy: 0.9253 - val_loss: 0.2004 - val_accuracy: 0.9230 - 12s/epoch - 2ms/step\n",
            "Epoch 127/800\n",
            "6930/6930 - 11s - loss: 0.1936 - accuracy: 0.9260 - val_loss: 0.1881 - val_accuracy: 0.9299 - 11s/epoch - 2ms/step\n",
            "Epoch 128/800\n",
            "6930/6930 - 12s - loss: 0.1926 - accuracy: 0.9265 - val_loss: 0.1916 - val_accuracy: 0.9273 - 12s/epoch - 2ms/step\n",
            "Epoch 129/800\n",
            "6930/6930 - 12s - loss: 0.1921 - accuracy: 0.9257 - val_loss: 0.2005 - val_accuracy: 0.9210 - 12s/epoch - 2ms/step\n",
            "Epoch 130/800\n",
            "6930/6930 - 12s - loss: 0.1912 - accuracy: 0.9261 - val_loss: 0.1837 - val_accuracy: 0.9303 - 12s/epoch - 2ms/step\n",
            "Epoch 131/800\n",
            "6930/6930 - 12s - loss: 0.1895 - accuracy: 0.9271 - val_loss: 0.2054 - val_accuracy: 0.9205 - 12s/epoch - 2ms/step\n",
            "Epoch 132/800\n",
            "6930/6930 - 11s - loss: 0.1890 - accuracy: 0.9277 - val_loss: 0.1786 - val_accuracy: 0.9318 - 11s/epoch - 2ms/step\n",
            "Epoch 133/800\n",
            "6930/6930 - 12s - loss: 0.1887 - accuracy: 0.9280 - val_loss: 0.1782 - val_accuracy: 0.9331 - 12s/epoch - 2ms/step\n",
            "Epoch 134/800\n",
            "6930/6930 - 12s - loss: 0.1878 - accuracy: 0.9285 - val_loss: 0.1980 - val_accuracy: 0.9242 - 12s/epoch - 2ms/step\n",
            "Epoch 135/800\n",
            "6930/6930 - 12s - loss: 0.1873 - accuracy: 0.9285 - val_loss: 0.1961 - val_accuracy: 0.9242 - 12s/epoch - 2ms/step\n",
            "Epoch 136/800\n",
            "6930/6930 - 12s - loss: 0.1854 - accuracy: 0.9287 - val_loss: 0.2075 - val_accuracy: 0.9210 - 12s/epoch - 2ms/step\n",
            "Epoch 137/800\n",
            "6930/6930 - 12s - loss: 0.1847 - accuracy: 0.9290 - val_loss: 0.1811 - val_accuracy: 0.9304 - 12s/epoch - 2ms/step\n",
            "Epoch 138/800\n",
            "6930/6930 - 11s - loss: 0.1836 - accuracy: 0.9302 - val_loss: 0.1913 - val_accuracy: 0.9284 - 11s/epoch - 2ms/step\n",
            "Epoch 139/800\n",
            "6930/6930 - 12s - loss: 0.1829 - accuracy: 0.9298 - val_loss: 0.1933 - val_accuracy: 0.9271 - 12s/epoch - 2ms/step\n",
            "Epoch 140/800\n",
            "6930/6930 - 12s - loss: 0.1820 - accuracy: 0.9311 - val_loss: 0.1822 - val_accuracy: 0.9295 - 12s/epoch - 2ms/step\n",
            "Epoch 141/800\n",
            "6930/6930 - 12s - loss: 0.1810 - accuracy: 0.9315 - val_loss: 0.1742 - val_accuracy: 0.9348 - 12s/epoch - 2ms/step\n",
            "Epoch 142/800\n",
            "6930/6930 - 12s - loss: 0.1804 - accuracy: 0.9320 - val_loss: 0.1770 - val_accuracy: 0.9329 - 12s/epoch - 2ms/step\n",
            "Epoch 143/800\n",
            "6930/6930 - 12s - loss: 0.1803 - accuracy: 0.9305 - val_loss: 0.1782 - val_accuracy: 0.9332 - 12s/epoch - 2ms/step\n",
            "Epoch 144/800\n",
            "6930/6930 - 12s - loss: 0.1791 - accuracy: 0.9323 - val_loss: 0.1831 - val_accuracy: 0.9310 - 12s/epoch - 2ms/step\n",
            "Epoch 145/800\n",
            "6930/6930 - 12s - loss: 0.1781 - accuracy: 0.9321 - val_loss: 0.1708 - val_accuracy: 0.9358 - 12s/epoch - 2ms/step\n",
            "Epoch 146/800\n",
            "6930/6930 - 12s - loss: 0.1772 - accuracy: 0.9329 - val_loss: 0.2038 - val_accuracy: 0.9175 - 12s/epoch - 2ms/step\n",
            "Epoch 147/800\n",
            "6930/6930 - 12s - loss: 0.1766 - accuracy: 0.9328 - val_loss: 0.1807 - val_accuracy: 0.9327 - 12s/epoch - 2ms/step\n",
            "Epoch 148/800\n",
            "6930/6930 - 11s - loss: 0.1756 - accuracy: 0.9332 - val_loss: 0.1768 - val_accuracy: 0.9347 - 11s/epoch - 2ms/step\n",
            "Epoch 149/800\n",
            "6930/6930 - 12s - loss: 0.1750 - accuracy: 0.9339 - val_loss: 0.1808 - val_accuracy: 0.9323 - 12s/epoch - 2ms/step\n",
            "Epoch 150/800\n",
            "6930/6930 - 12s - loss: 0.1752 - accuracy: 0.9336 - val_loss: 0.1841 - val_accuracy: 0.9310 - 12s/epoch - 2ms/step\n",
            "Epoch 151/800\n",
            "6930/6930 - 12s - loss: 0.1725 - accuracy: 0.9345 - val_loss: 0.1891 - val_accuracy: 0.9238 - 12s/epoch - 2ms/step\n",
            "Epoch 152/800\n",
            "6930/6930 - 12s - loss: 0.1722 - accuracy: 0.9356 - val_loss: 0.1717 - val_accuracy: 0.9340 - 12s/epoch - 2ms/step\n",
            "Epoch 153/800\n",
            "6930/6930 - 12s - loss: 0.1724 - accuracy: 0.9345 - val_loss: 0.1955 - val_accuracy: 0.9249 - 12s/epoch - 2ms/step\n",
            "Epoch 154/800\n",
            "6930/6930 - 12s - loss: 0.1708 - accuracy: 0.9355 - val_loss: 0.1694 - val_accuracy: 0.9349 - 12s/epoch - 2ms/step\n",
            "Epoch 155/800\n",
            "6930/6930 - 12s - loss: 0.1705 - accuracy: 0.9354 - val_loss: 0.1896 - val_accuracy: 0.9304 - 12s/epoch - 2ms/step\n",
            "Epoch 156/800\n",
            "6930/6930 - 12s - loss: 0.1700 - accuracy: 0.9359 - val_loss: 0.1695 - val_accuracy: 0.9355 - 12s/epoch - 2ms/step\n",
            "Epoch 157/800\n",
            "6930/6930 - 12s - loss: 0.1687 - accuracy: 0.9365 - val_loss: 0.1953 - val_accuracy: 0.9212 - 12s/epoch - 2ms/step\n",
            "Epoch 158/800\n",
            "6930/6930 - 12s - loss: 0.1675 - accuracy: 0.9362 - val_loss: 0.1666 - val_accuracy: 0.9397 - 12s/epoch - 2ms/step\n",
            "Epoch 159/800\n",
            "6930/6930 - 12s - loss: 0.1675 - accuracy: 0.9360 - val_loss: 0.1815 - val_accuracy: 0.9279 - 12s/epoch - 2ms/step\n",
            "Epoch 160/800\n",
            "6930/6930 - 12s - loss: 0.1670 - accuracy: 0.9368 - val_loss: 0.1621 - val_accuracy: 0.9400 - 12s/epoch - 2ms/step\n",
            "Epoch 161/800\n",
            "6930/6930 - 12s - loss: 0.1663 - accuracy: 0.9376 - val_loss: 0.1709 - val_accuracy: 0.9358 - 12s/epoch - 2ms/step\n",
            "Epoch 162/800\n",
            "6930/6930 - 12s - loss: 0.1651 - accuracy: 0.9374 - val_loss: 0.1704 - val_accuracy: 0.9356 - 12s/epoch - 2ms/step\n",
            "Epoch 163/800\n",
            "6930/6930 - 12s - loss: 0.1654 - accuracy: 0.9377 - val_loss: 0.1584 - val_accuracy: 0.9409 - 12s/epoch - 2ms/step\n",
            "Epoch 164/800\n",
            "6930/6930 - 12s - loss: 0.1657 - accuracy: 0.9378 - val_loss: 0.1806 - val_accuracy: 0.9301 - 12s/epoch - 2ms/step\n",
            "Epoch 165/800\n",
            "6930/6930 - 12s - loss: 0.1633 - accuracy: 0.9378 - val_loss: 0.1532 - val_accuracy: 0.9451 - 12s/epoch - 2ms/step\n",
            "Epoch 166/800\n",
            "6930/6930 - 12s - loss: 0.1624 - accuracy: 0.9394 - val_loss: 0.1603 - val_accuracy: 0.9416 - 12s/epoch - 2ms/step\n",
            "Epoch 167/800\n",
            "6930/6930 - 12s - loss: 0.1628 - accuracy: 0.9388 - val_loss: 0.1799 - val_accuracy: 0.9278 - 12s/epoch - 2ms/step\n",
            "Epoch 168/800\n",
            "6930/6930 - 12s - loss: 0.1619 - accuracy: 0.9393 - val_loss: 0.1700 - val_accuracy: 0.9370 - 12s/epoch - 2ms/step\n",
            "Epoch 169/800\n",
            "6930/6930 - 12s - loss: 0.1613 - accuracy: 0.9392 - val_loss: 0.1740 - val_accuracy: 0.9352 - 12s/epoch - 2ms/step\n",
            "Epoch 170/800\n",
            "6930/6930 - 12s - loss: 0.1610 - accuracy: 0.9399 - val_loss: 0.1833 - val_accuracy: 0.9294 - 12s/epoch - 2ms/step\n",
            "Epoch 171/800\n",
            "6930/6930 - 11s - loss: 0.1608 - accuracy: 0.9395 - val_loss: 0.1518 - val_accuracy: 0.9449 - 11s/epoch - 2ms/step\n",
            "Epoch 172/800\n",
            "6930/6930 - 11s - loss: 0.1593 - accuracy: 0.9403 - val_loss: 0.1615 - val_accuracy: 0.9391 - 11s/epoch - 2ms/step\n",
            "Epoch 173/800\n",
            "6930/6930 - 12s - loss: 0.1588 - accuracy: 0.9410 - val_loss: 0.1578 - val_accuracy: 0.9418 - 12s/epoch - 2ms/step\n",
            "Epoch 174/800\n",
            "6930/6930 - 12s - loss: 0.1582 - accuracy: 0.9408 - val_loss: 0.1605 - val_accuracy: 0.9404 - 12s/epoch - 2ms/step\n",
            "Epoch 175/800\n",
            "6930/6930 - 12s - loss: 0.1582 - accuracy: 0.9409 - val_loss: 0.1666 - val_accuracy: 0.9382 - 12s/epoch - 2ms/step\n",
            "Epoch 176/800\n",
            "6930/6930 - 12s - loss: 0.1564 - accuracy: 0.9408 - val_loss: 0.1617 - val_accuracy: 0.9401 - 12s/epoch - 2ms/step\n",
            "Epoch 177/800\n",
            "6930/6930 - 12s - loss: 0.1570 - accuracy: 0.9417 - val_loss: 0.1664 - val_accuracy: 0.9375 - 12s/epoch - 2ms/step\n",
            "Epoch 178/800\n",
            "6930/6930 - 12s - loss: 0.1564 - accuracy: 0.9413 - val_loss: 0.1496 - val_accuracy: 0.9453 - 12s/epoch - 2ms/step\n",
            "Epoch 179/800\n",
            "6930/6930 - 12s - loss: 0.1554 - accuracy: 0.9413 - val_loss: 0.1487 - val_accuracy: 0.9474 - 12s/epoch - 2ms/step\n",
            "Epoch 180/800\n",
            "6930/6930 - 11s - loss: 0.1542 - accuracy: 0.9425 - val_loss: 0.1575 - val_accuracy: 0.9403 - 11s/epoch - 2ms/step\n",
            "Epoch 181/800\n",
            "6930/6930 - 12s - loss: 0.1534 - accuracy: 0.9426 - val_loss: 0.1581 - val_accuracy: 0.9414 - 12s/epoch - 2ms/step\n",
            "Epoch 182/800\n",
            "6930/6930 - 11s - loss: 0.1535 - accuracy: 0.9421 - val_loss: 0.1455 - val_accuracy: 0.9464 - 11s/epoch - 2ms/step\n",
            "Epoch 183/800\n",
            "6930/6930 - 11s - loss: 0.1529 - accuracy: 0.9425 - val_loss: 0.1580 - val_accuracy: 0.9412 - 11s/epoch - 2ms/step\n",
            "Epoch 184/800\n",
            "6930/6930 - 12s - loss: 0.1518 - accuracy: 0.9431 - val_loss: 0.1654 - val_accuracy: 0.9361 - 12s/epoch - 2ms/step\n",
            "Epoch 185/800\n",
            "6930/6930 - 12s - loss: 0.1519 - accuracy: 0.9436 - val_loss: 0.1552 - val_accuracy: 0.9427 - 12s/epoch - 2ms/step\n",
            "Epoch 186/800\n",
            "6930/6930 - 12s - loss: 0.1506 - accuracy: 0.9437 - val_loss: 0.1455 - val_accuracy: 0.9461 - 12s/epoch - 2ms/step\n",
            "Epoch 187/800\n",
            "6930/6930 - 12s - loss: 0.1498 - accuracy: 0.9443 - val_loss: 0.1467 - val_accuracy: 0.9457 - 12s/epoch - 2ms/step\n",
            "Epoch 188/800\n",
            "6930/6930 - 12s - loss: 0.1500 - accuracy: 0.9450 - val_loss: 0.1407 - val_accuracy: 0.9497 - 12s/epoch - 2ms/step\n",
            "Epoch 189/800\n",
            "6930/6930 - 12s - loss: 0.1492 - accuracy: 0.9451 - val_loss: 0.1430 - val_accuracy: 0.9458 - 12s/epoch - 2ms/step\n",
            "Epoch 190/800\n",
            "6930/6930 - 12s - loss: 0.1486 - accuracy: 0.9441 - val_loss: 0.1567 - val_accuracy: 0.9438 - 12s/epoch - 2ms/step\n",
            "Epoch 191/800\n",
            "6930/6930 - 12s - loss: 0.1484 - accuracy: 0.9441 - val_loss: 0.1676 - val_accuracy: 0.9369 - 12s/epoch - 2ms/step\n",
            "Epoch 192/800\n",
            "6930/6930 - 12s - loss: 0.1476 - accuracy: 0.9449 - val_loss: 0.1463 - val_accuracy: 0.9466 - 12s/epoch - 2ms/step\n",
            "Epoch 193/800\n",
            "6930/6930 - 12s - loss: 0.1471 - accuracy: 0.9454 - val_loss: 0.1559 - val_accuracy: 0.9406 - 12s/epoch - 2ms/step\n",
            "Epoch 194/800\n",
            "6930/6930 - 12s - loss: 0.1474 - accuracy: 0.9449 - val_loss: 0.1389 - val_accuracy: 0.9497 - 12s/epoch - 2ms/step\n",
            "Epoch 195/800\n",
            "6930/6930 - 12s - loss: 0.1456 - accuracy: 0.9451 - val_loss: 0.1495 - val_accuracy: 0.9453 - 12s/epoch - 2ms/step\n",
            "Epoch 196/800\n",
            "6930/6930 - 12s - loss: 0.1460 - accuracy: 0.9460 - val_loss: 0.1356 - val_accuracy: 0.9505 - 12s/epoch - 2ms/step\n",
            "Epoch 197/800\n",
            "6930/6930 - 12s - loss: 0.1454 - accuracy: 0.9455 - val_loss: 0.1472 - val_accuracy: 0.9469 - 12s/epoch - 2ms/step\n",
            "Epoch 198/800\n",
            "6930/6930 - 12s - loss: 0.1443 - accuracy: 0.9464 - val_loss: 0.1424 - val_accuracy: 0.9483 - 12s/epoch - 2ms/step\n",
            "Epoch 199/800\n",
            "6930/6930 - 12s - loss: 0.1443 - accuracy: 0.9472 - val_loss: 0.1453 - val_accuracy: 0.9462 - 12s/epoch - 2ms/step\n",
            "Epoch 200/800\n",
            "6930/6930 - 12s - loss: 0.1445 - accuracy: 0.9463 - val_loss: 0.1932 - val_accuracy: 0.9284 - 12s/epoch - 2ms/step\n",
            "Epoch 201/800\n",
            "6930/6930 - 12s - loss: 0.1442 - accuracy: 0.9464 - val_loss: 0.1394 - val_accuracy: 0.9501 - 12s/epoch - 2ms/step\n",
            "Epoch 202/800\n",
            "6930/6930 - 12s - loss: 0.1424 - accuracy: 0.9475 - val_loss: 0.1533 - val_accuracy: 0.9425 - 12s/epoch - 2ms/step\n",
            "Epoch 203/800\n",
            "6930/6930 - 12s - loss: 0.1426 - accuracy: 0.9471 - val_loss: 0.1499 - val_accuracy: 0.9429 - 12s/epoch - 2ms/step\n",
            "Epoch 204/800\n",
            "6930/6930 - 12s - loss: 0.1423 - accuracy: 0.9469 - val_loss: 0.1483 - val_accuracy: 0.9442 - 12s/epoch - 2ms/step\n",
            "Epoch 205/800\n",
            "6930/6930 - 12s - loss: 0.1426 - accuracy: 0.9468 - val_loss: 0.1581 - val_accuracy: 0.9404 - 12s/epoch - 2ms/step\n",
            "Epoch 206/800\n",
            "6930/6930 - 12s - loss: 0.1408 - accuracy: 0.9476 - val_loss: 0.1406 - val_accuracy: 0.9499 - 12s/epoch - 2ms/step\n",
            "Epoch 207/800\n",
            "6930/6930 - 12s - loss: 0.1418 - accuracy: 0.9474 - val_loss: 0.1578 - val_accuracy: 0.9404 - 12s/epoch - 2ms/step\n",
            "Epoch 208/800\n",
            "6930/6930 - 12s - loss: 0.1419 - accuracy: 0.9467 - val_loss: 0.1405 - val_accuracy: 0.9473 - 12s/epoch - 2ms/step\n",
            "Epoch 209/800\n",
            "6930/6930 - 12s - loss: 0.1407 - accuracy: 0.9474 - val_loss: 0.1474 - val_accuracy: 0.9447 - 12s/epoch - 2ms/step\n",
            "Epoch 210/800\n",
            "6930/6930 - 11s - loss: 0.1402 - accuracy: 0.9481 - val_loss: 0.1327 - val_accuracy: 0.9540 - 11s/epoch - 2ms/step\n",
            "Epoch 211/800\n",
            "6930/6930 - 12s - loss: 0.1399 - accuracy: 0.9478 - val_loss: 0.1436 - val_accuracy: 0.9469 - 12s/epoch - 2ms/step\n",
            "Epoch 212/800\n",
            "6930/6930 - 12s - loss: 0.1395 - accuracy: 0.9480 - val_loss: 0.1390 - val_accuracy: 0.9523 - 12s/epoch - 2ms/step\n",
            "Epoch 213/800\n",
            "6930/6930 - 11s - loss: 0.1387 - accuracy: 0.9483 - val_loss: 0.1487 - val_accuracy: 0.9448 - 11s/epoch - 2ms/step\n",
            "Epoch 214/800\n",
            "6930/6930 - 12s - loss: 0.1385 - accuracy: 0.9485 - val_loss: 0.1350 - val_accuracy: 0.9509 - 12s/epoch - 2ms/step\n",
            "Epoch 215/800\n",
            "6930/6930 - 12s - loss: 0.1364 - accuracy: 0.9495 - val_loss: 0.1377 - val_accuracy: 0.9499 - 12s/epoch - 2ms/step\n",
            "Epoch 216/800\n",
            "6930/6930 - 12s - loss: 0.1367 - accuracy: 0.9493 - val_loss: 0.1858 - val_accuracy: 0.9279 - 12s/epoch - 2ms/step\n",
            "Epoch 217/800\n",
            "6930/6930 - 12s - loss: 0.1366 - accuracy: 0.9494 - val_loss: 0.1365 - val_accuracy: 0.9521 - 12s/epoch - 2ms/step\n",
            "Epoch 218/800\n",
            "6930/6930 - 12s - loss: 0.1362 - accuracy: 0.9491 - val_loss: 0.1426 - val_accuracy: 0.9484 - 12s/epoch - 2ms/step\n",
            "Epoch 219/800\n",
            "6930/6930 - 12s - loss: 0.1363 - accuracy: 0.9500 - val_loss: 0.1336 - val_accuracy: 0.9525 - 12s/epoch - 2ms/step\n",
            "Epoch 220/800\n",
            "6930/6930 - 12s - loss: 0.1350 - accuracy: 0.9493 - val_loss: 0.1488 - val_accuracy: 0.9438 - 12s/epoch - 2ms/step\n",
            "Epoch 221/800\n",
            "6930/6930 - 12s - loss: 0.1361 - accuracy: 0.9497 - val_loss: 0.1911 - val_accuracy: 0.9266 - 12s/epoch - 2ms/step\n",
            "Epoch 222/800\n",
            "6930/6930 - 12s - loss: 0.1353 - accuracy: 0.9506 - val_loss: 0.1417 - val_accuracy: 0.9483 - 12s/epoch - 2ms/step\n",
            "Epoch 223/800\n",
            "6930/6930 - 12s - loss: 0.1344 - accuracy: 0.9508 - val_loss: 0.1329 - val_accuracy: 0.9535 - 12s/epoch - 2ms/step\n",
            "Epoch 224/800\n",
            "6930/6930 - 12s - loss: 0.1342 - accuracy: 0.9496 - val_loss: 0.1364 - val_accuracy: 0.9499 - 12s/epoch - 2ms/step\n",
            "Epoch 225/800\n",
            "6930/6930 - 12s - loss: 0.1336 - accuracy: 0.9505 - val_loss: 0.1297 - val_accuracy: 0.9532 - 12s/epoch - 2ms/step\n",
            "Epoch 226/800\n",
            "6930/6930 - 12s - loss: 0.1334 - accuracy: 0.9504 - val_loss: 0.1319 - val_accuracy: 0.9529 - 12s/epoch - 2ms/step\n",
            "Epoch 227/800\n",
            "6930/6930 - 12s - loss: 0.1324 - accuracy: 0.9517 - val_loss: 0.1303 - val_accuracy: 0.9536 - 12s/epoch - 2ms/step\n",
            "Epoch 228/800\n",
            "6930/6930 - 12s - loss: 0.1320 - accuracy: 0.9512 - val_loss: 0.1388 - val_accuracy: 0.9495 - 12s/epoch - 2ms/step\n",
            "Epoch 229/800\n",
            "6930/6930 - 11s - loss: 0.1341 - accuracy: 0.9501 - val_loss: 0.1733 - val_accuracy: 0.9330 - 11s/epoch - 2ms/step\n",
            "Epoch 230/800\n",
            "6930/6930 - 11s - loss: 0.1313 - accuracy: 0.9517 - val_loss: 0.1273 - val_accuracy: 0.9562 - 11s/epoch - 2ms/step\n",
            "Epoch 231/800\n",
            "6930/6930 - 12s - loss: 0.1310 - accuracy: 0.9514 - val_loss: 0.1413 - val_accuracy: 0.9466 - 12s/epoch - 2ms/step\n",
            "Epoch 232/800\n",
            "6930/6930 - 12s - loss: 0.1309 - accuracy: 0.9512 - val_loss: 0.1346 - val_accuracy: 0.9510 - 12s/epoch - 2ms/step\n",
            "Epoch 233/800\n",
            "6930/6930 - 12s - loss: 0.1304 - accuracy: 0.9519 - val_loss: 0.1454 - val_accuracy: 0.9453 - 12s/epoch - 2ms/step\n",
            "Epoch 234/800\n",
            "6930/6930 - 12s - loss: 0.1303 - accuracy: 0.9515 - val_loss: 0.1328 - val_accuracy: 0.9506 - 12s/epoch - 2ms/step\n",
            "Epoch 235/800\n",
            "6930/6930 - 12s - loss: 0.1301 - accuracy: 0.9513 - val_loss: 0.1350 - val_accuracy: 0.9505 - 12s/epoch - 2ms/step\n",
            "Epoch 236/800\n",
            "6930/6930 - 12s - loss: 0.1308 - accuracy: 0.9512 - val_loss: 0.1347 - val_accuracy: 0.9525 - 12s/epoch - 2ms/step\n",
            "Epoch 237/800\n",
            "6930/6930 - 12s - loss: 0.1292 - accuracy: 0.9513 - val_loss: 0.1264 - val_accuracy: 0.9557 - 12s/epoch - 2ms/step\n",
            "Epoch 238/800\n",
            "6930/6930 - 11s - loss: 0.1296 - accuracy: 0.9513 - val_loss: 0.1572 - val_accuracy: 0.9416 - 11s/epoch - 2ms/step\n",
            "Epoch 239/800\n",
            "6930/6930 - 12s - loss: 0.1288 - accuracy: 0.9521 - val_loss: 0.1249 - val_accuracy: 0.9562 - 12s/epoch - 2ms/step\n",
            "Epoch 240/800\n",
            "6930/6930 - 12s - loss: 0.1277 - accuracy: 0.9528 - val_loss: 0.1219 - val_accuracy: 0.9578 - 12s/epoch - 2ms/step\n",
            "Epoch 241/800\n",
            "6930/6930 - 12s - loss: 0.1279 - accuracy: 0.9522 - val_loss: 0.1399 - val_accuracy: 0.9487 - 12s/epoch - 2ms/step\n",
            "Epoch 242/800\n",
            "6930/6930 - 12s - loss: 0.1286 - accuracy: 0.9524 - val_loss: 0.1525 - val_accuracy: 0.9439 - 12s/epoch - 2ms/step\n",
            "Epoch 243/800\n",
            "6930/6930 - 12s - loss: 0.1271 - accuracy: 0.9530 - val_loss: 0.1348 - val_accuracy: 0.9506 - 12s/epoch - 2ms/step\n",
            "Epoch 244/800\n",
            "6930/6930 - 12s - loss: 0.1278 - accuracy: 0.9521 - val_loss: 0.1359 - val_accuracy: 0.9529 - 12s/epoch - 2ms/step\n",
            "Epoch 245/800\n",
            "6930/6930 - 12s - loss: 0.1274 - accuracy: 0.9529 - val_loss: 0.1256 - val_accuracy: 0.9564 - 12s/epoch - 2ms/step\n",
            "Epoch 246/800\n",
            "6930/6930 - 12s - loss: 0.1258 - accuracy: 0.9532 - val_loss: 0.1337 - val_accuracy: 0.9526 - 12s/epoch - 2ms/step\n",
            "Epoch 247/800\n",
            "6930/6930 - 12s - loss: 0.1252 - accuracy: 0.9533 - val_loss: 0.1476 - val_accuracy: 0.9422 - 12s/epoch - 2ms/step\n",
            "Epoch 248/800\n",
            "6930/6930 - 12s - loss: 0.1259 - accuracy: 0.9523 - val_loss: 0.1290 - val_accuracy: 0.9544 - 12s/epoch - 2ms/step\n",
            "Epoch 249/800\n",
            "6930/6930 - 12s - loss: 0.1252 - accuracy: 0.9532 - val_loss: 0.1334 - val_accuracy: 0.9508 - 12s/epoch - 2ms/step\n",
            "Epoch 250/800\n",
            "6930/6930 - 12s - loss: 0.1249 - accuracy: 0.9537 - val_loss: 0.1250 - val_accuracy: 0.9555 - 12s/epoch - 2ms/step\n",
            "Epoch 251/800\n",
            "6930/6930 - 12s - loss: 0.1243 - accuracy: 0.9544 - val_loss: 0.1282 - val_accuracy: 0.9553 - 12s/epoch - 2ms/step\n",
            "Epoch 252/800\n",
            "6930/6930 - 12s - loss: 0.1237 - accuracy: 0.9544 - val_loss: 0.1233 - val_accuracy: 0.9566 - 12s/epoch - 2ms/step\n",
            "Epoch 253/800\n",
            "6930/6930 - 12s - loss: 0.1232 - accuracy: 0.9543 - val_loss: 0.1196 - val_accuracy: 0.9578 - 12s/epoch - 2ms/step\n",
            "Epoch 254/800\n",
            "6930/6930 - 12s - loss: 0.1234 - accuracy: 0.9545 - val_loss: 0.1324 - val_accuracy: 0.9531 - 12s/epoch - 2ms/step\n",
            "Epoch 255/800\n",
            "6930/6930 - 12s - loss: 0.1228 - accuracy: 0.9550 - val_loss: 0.1498 - val_accuracy: 0.9460 - 12s/epoch - 2ms/step\n",
            "Epoch 256/800\n",
            "6930/6930 - 12s - loss: 0.1235 - accuracy: 0.9542 - val_loss: 0.1355 - val_accuracy: 0.9517 - 12s/epoch - 2ms/step\n",
            "Epoch 257/800\n",
            "6930/6930 - 12s - loss: 0.1223 - accuracy: 0.9546 - val_loss: 0.1341 - val_accuracy: 0.9519 - 12s/epoch - 2ms/step\n",
            "Epoch 258/800\n",
            "6930/6930 - 12s - loss: 0.1215 - accuracy: 0.9554 - val_loss: 0.1189 - val_accuracy: 0.9574 - 12s/epoch - 2ms/step\n",
            "Epoch 259/800\n",
            "6930/6930 - 12s - loss: 0.1219 - accuracy: 0.9549 - val_loss: 0.1276 - val_accuracy: 0.9555 - 12s/epoch - 2ms/step\n",
            "Epoch 260/800\n",
            "6930/6930 - 11s - loss: 0.1214 - accuracy: 0.9541 - val_loss: 0.1319 - val_accuracy: 0.9525 - 11s/epoch - 2ms/step\n",
            "Epoch 261/800\n",
            "6930/6930 - 12s - loss: 0.1210 - accuracy: 0.9552 - val_loss: 0.1412 - val_accuracy: 0.9492 - 12s/epoch - 2ms/step\n",
            "Epoch 262/800\n",
            "6930/6930 - 11s - loss: 0.1208 - accuracy: 0.9548 - val_loss: 0.1179 - val_accuracy: 0.9591 - 11s/epoch - 2ms/step\n",
            "Epoch 263/800\n",
            "6930/6930 - 12s - loss: 0.1200 - accuracy: 0.9551 - val_loss: 0.1242 - val_accuracy: 0.9562 - 12s/epoch - 2ms/step\n",
            "Epoch 264/800\n",
            "6930/6930 - 11s - loss: 0.1199 - accuracy: 0.9547 - val_loss: 0.1268 - val_accuracy: 0.9535 - 11s/epoch - 2ms/step\n",
            "Epoch 265/800\n",
            "6930/6930 - 12s - loss: 0.1197 - accuracy: 0.9556 - val_loss: 0.1268 - val_accuracy: 0.9545 - 12s/epoch - 2ms/step\n",
            "Epoch 266/800\n",
            "6930/6930 - 12s - loss: 0.1198 - accuracy: 0.9556 - val_loss: 0.1372 - val_accuracy: 0.9487 - 12s/epoch - 2ms/step\n",
            "Epoch 267/800\n",
            "6930/6930 - 12s - loss: 0.1198 - accuracy: 0.9552 - val_loss: 0.1381 - val_accuracy: 0.9504 - 12s/epoch - 2ms/step\n",
            "Epoch 268/800\n",
            "6930/6930 - 12s - loss: 0.1199 - accuracy: 0.9560 - val_loss: 0.1235 - val_accuracy: 0.9551 - 12s/epoch - 2ms/step\n",
            "Epoch 269/800\n",
            "6930/6930 - 12s - loss: 0.1187 - accuracy: 0.9567 - val_loss: 0.1159 - val_accuracy: 0.9590 - 12s/epoch - 2ms/step\n",
            "Epoch 270/800\n",
            "6930/6930 - 12s - loss: 0.1169 - accuracy: 0.9571 - val_loss: 0.1237 - val_accuracy: 0.9558 - 12s/epoch - 2ms/step\n",
            "Epoch 271/800\n",
            "6930/6930 - 12s - loss: 0.1181 - accuracy: 0.9560 - val_loss: 0.1165 - val_accuracy: 0.9606 - 12s/epoch - 2ms/step\n",
            "Epoch 272/800\n",
            "6930/6930 - 12s - loss: 0.1172 - accuracy: 0.9568 - val_loss: 0.1362 - val_accuracy: 0.9529 - 12s/epoch - 2ms/step\n",
            "Epoch 273/800\n",
            "6930/6930 - 11s - loss: 0.1171 - accuracy: 0.9571 - val_loss: 0.1129 - val_accuracy: 0.9606 - 11s/epoch - 2ms/step\n",
            "Epoch 274/800\n",
            "6930/6930 - 12s - loss: 0.1167 - accuracy: 0.9564 - val_loss: 0.1138 - val_accuracy: 0.9600 - 12s/epoch - 2ms/step\n",
            "Epoch 275/800\n",
            "6930/6930 - 12s - loss: 0.1169 - accuracy: 0.9565 - val_loss: 0.1247 - val_accuracy: 0.9565 - 12s/epoch - 2ms/step\n",
            "Epoch 276/800\n",
            "6930/6930 - 12s - loss: 0.1173 - accuracy: 0.9571 - val_loss: 0.1173 - val_accuracy: 0.9601 - 12s/epoch - 2ms/step\n",
            "Epoch 277/800\n",
            "6930/6930 - 12s - loss: 0.1155 - accuracy: 0.9574 - val_loss: 0.1353 - val_accuracy: 0.9517 - 12s/epoch - 2ms/step\n",
            "Epoch 278/800\n",
            "6930/6930 - 12s - loss: 0.1163 - accuracy: 0.9570 - val_loss: 0.1130 - val_accuracy: 0.9601 - 12s/epoch - 2ms/step\n",
            "Epoch 279/800\n",
            "6930/6930 - 12s - loss: 0.1170 - accuracy: 0.9565 - val_loss: 0.1496 - val_accuracy: 0.9429 - 12s/epoch - 2ms/step\n",
            "Epoch 280/800\n",
            "6930/6930 - 12s - loss: 0.1161 - accuracy: 0.9565 - val_loss: 0.1160 - val_accuracy: 0.9587 - 12s/epoch - 2ms/step\n",
            "Epoch 281/800\n",
            "6930/6930 - 12s - loss: 0.1153 - accuracy: 0.9582 - val_loss: 0.1208 - val_accuracy: 0.9583 - 12s/epoch - 2ms/step\n",
            "Epoch 282/800\n",
            "6930/6930 - 12s - loss: 0.1157 - accuracy: 0.9573 - val_loss: 0.1173 - val_accuracy: 0.9573 - 12s/epoch - 2ms/step\n",
            "Epoch 283/800\n",
            "6930/6930 - 12s - loss: 0.1139 - accuracy: 0.9576 - val_loss: 0.1126 - val_accuracy: 0.9618 - 12s/epoch - 2ms/step\n",
            "Epoch 284/800\n",
            "6930/6930 - 12s - loss: 0.1138 - accuracy: 0.9579 - val_loss: 0.1135 - val_accuracy: 0.9621 - 12s/epoch - 2ms/step\n",
            "Epoch 285/800\n",
            "6930/6930 - 12s - loss: 0.1141 - accuracy: 0.9582 - val_loss: 0.1176 - val_accuracy: 0.9582 - 12s/epoch - 2ms/step\n",
            "Epoch 286/800\n",
            "6930/6930 - 12s - loss: 0.1144 - accuracy: 0.9577 - val_loss: 0.1204 - val_accuracy: 0.9578 - 12s/epoch - 2ms/step\n",
            "Epoch 287/800\n",
            "6930/6930 - 12s - loss: 0.1133 - accuracy: 0.9580 - val_loss: 0.1187 - val_accuracy: 0.9599 - 12s/epoch - 2ms/step\n",
            "Epoch 288/800\n",
            "6930/6930 - 12s - loss: 0.1130 - accuracy: 0.9580 - val_loss: 0.1100 - val_accuracy: 0.9599 - 12s/epoch - 2ms/step\n",
            "Epoch 289/800\n",
            "6930/6930 - 12s - loss: 0.1129 - accuracy: 0.9585 - val_loss: 0.1145 - val_accuracy: 0.9604 - 12s/epoch - 2ms/step\n",
            "Epoch 290/800\n",
            "6930/6930 - 12s - loss: 0.1125 - accuracy: 0.9582 - val_loss: 0.1135 - val_accuracy: 0.9582 - 12s/epoch - 2ms/step\n",
            "Epoch 291/800\n",
            "6930/6930 - 11s - loss: 0.1131 - accuracy: 0.9577 - val_loss: 0.1135 - val_accuracy: 0.9588 - 11s/epoch - 2ms/step\n",
            "Epoch 292/800\n",
            "6930/6930 - 12s - loss: 0.1121 - accuracy: 0.9583 - val_loss: 0.1157 - val_accuracy: 0.9604 - 12s/epoch - 2ms/step\n",
            "Epoch 293/800\n",
            "6930/6930 - 12s - loss: 0.1121 - accuracy: 0.9585 - val_loss: 0.1368 - val_accuracy: 0.9506 - 12s/epoch - 2ms/step\n",
            "Epoch 294/800\n",
            "6930/6930 - 12s - loss: 0.1126 - accuracy: 0.9590 - val_loss: 0.1113 - val_accuracy: 0.9601 - 12s/epoch - 2ms/step\n",
            "Epoch 295/800\n",
            "6930/6930 - 12s - loss: 0.1114 - accuracy: 0.9584 - val_loss: 0.1201 - val_accuracy: 0.9553 - 12s/epoch - 2ms/step\n",
            "Epoch 296/800\n",
            "6930/6930 - 12s - loss: 0.1113 - accuracy: 0.9588 - val_loss: 0.1425 - val_accuracy: 0.9482 - 12s/epoch - 2ms/step\n",
            "Epoch 297/800\n",
            "6930/6930 - 12s - loss: 0.1113 - accuracy: 0.9585 - val_loss: 0.1339 - val_accuracy: 0.9519 - 12s/epoch - 2ms/step\n",
            "Epoch 298/800\n",
            "6930/6930 - 12s - loss: 0.1103 - accuracy: 0.9587 - val_loss: 0.1078 - val_accuracy: 0.9626 - 12s/epoch - 2ms/step\n",
            "Epoch 299/800\n",
            "6930/6930 - 11s - loss: 0.1107 - accuracy: 0.9588 - val_loss: 0.1194 - val_accuracy: 0.9587 - 11s/epoch - 2ms/step\n",
            "Epoch 300/800\n",
            "6930/6930 - 12s - loss: 0.1107 - accuracy: 0.9588 - val_loss: 0.1156 - val_accuracy: 0.9596 - 12s/epoch - 2ms/step\n",
            "Epoch 301/800\n",
            "6930/6930 - 12s - loss: 0.1100 - accuracy: 0.9592 - val_loss: 0.1208 - val_accuracy: 0.9549 - 12s/epoch - 2ms/step\n",
            "Epoch 302/800\n",
            "6930/6930 - 12s - loss: 0.1097 - accuracy: 0.9592 - val_loss: 0.1121 - val_accuracy: 0.9609 - 12s/epoch - 2ms/step\n",
            "Epoch 303/800\n",
            "6930/6930 - 12s - loss: 0.1095 - accuracy: 0.9594 - val_loss: 0.1120 - val_accuracy: 0.9612 - 12s/epoch - 2ms/step\n",
            "Epoch 304/800\n",
            "6930/6930 - 12s - loss: 0.1100 - accuracy: 0.9590 - val_loss: 0.1131 - val_accuracy: 0.9600 - 12s/epoch - 2ms/step\n",
            "Epoch 305/800\n",
            "6930/6930 - 12s - loss: 0.1102 - accuracy: 0.9594 - val_loss: 0.1088 - val_accuracy: 0.9616 - 12s/epoch - 2ms/step\n",
            "Epoch 306/800\n",
            "6930/6930 - 12s - loss: 0.1092 - accuracy: 0.9589 - val_loss: 0.1189 - val_accuracy: 0.9566 - 12s/epoch - 2ms/step\n",
            "Epoch 307/800\n",
            "6930/6930 - 12s - loss: 0.1086 - accuracy: 0.9597 - val_loss: 0.1127 - val_accuracy: 0.9616 - 12s/epoch - 2ms/step\n",
            "Epoch 308/800\n",
            "6930/6930 - 12s - loss: 0.1083 - accuracy: 0.9601 - val_loss: 0.1404 - val_accuracy: 0.9471 - 12s/epoch - 2ms/step\n",
            "Epoch 309/800\n",
            "6930/6930 - 12s - loss: 0.1080 - accuracy: 0.9605 - val_loss: 0.1160 - val_accuracy: 0.9608 - 12s/epoch - 2ms/step\n",
            "Epoch 310/800\n",
            "6930/6930 - 12s - loss: 0.1089 - accuracy: 0.9594 - val_loss: 0.1064 - val_accuracy: 0.9616 - 12s/epoch - 2ms/step\n",
            "Epoch 311/800\n",
            "6930/6930 - 12s - loss: 0.1089 - accuracy: 0.9599 - val_loss: 0.1192 - val_accuracy: 0.9558 - 12s/epoch - 2ms/step\n",
            "Epoch 312/800\n",
            "6930/6930 - 12s - loss: 0.1078 - accuracy: 0.9602 - val_loss: 0.1168 - val_accuracy: 0.9601 - 12s/epoch - 2ms/step\n",
            "Epoch 313/800\n",
            "6930/6930 - 12s - loss: 0.1070 - accuracy: 0.9604 - val_loss: 0.1262 - val_accuracy: 0.9562 - 12s/epoch - 2ms/step\n",
            "Epoch 314/800\n",
            "6930/6930 - 12s - loss: 0.1071 - accuracy: 0.9604 - val_loss: 0.1137 - val_accuracy: 0.9616 - 12s/epoch - 2ms/step\n",
            "Epoch 315/800\n",
            "6930/6930 - 12s - loss: 0.1091 - accuracy: 0.9594 - val_loss: 0.1097 - val_accuracy: 0.9618 - 12s/epoch - 2ms/step\n",
            "Epoch 316/800\n",
            "6930/6930 - 12s - loss: 0.1064 - accuracy: 0.9607 - val_loss: 0.1663 - val_accuracy: 0.9397 - 12s/epoch - 2ms/step\n",
            "Epoch 317/800\n",
            "6930/6930 - 12s - loss: 0.1066 - accuracy: 0.9602 - val_loss: 0.1253 - val_accuracy: 0.9547 - 12s/epoch - 2ms/step\n",
            "Epoch 318/800\n",
            "6930/6930 - 11s - loss: 0.1064 - accuracy: 0.9607 - val_loss: 0.1092 - val_accuracy: 0.9606 - 11s/epoch - 2ms/step\n",
            "Epoch 319/800\n",
            "6930/6930 - 12s - loss: 0.1066 - accuracy: 0.9600 - val_loss: 0.1193 - val_accuracy: 0.9575 - 12s/epoch - 2ms/step\n",
            "Epoch 320/800\n",
            "6930/6930 - 12s - loss: 0.1062 - accuracy: 0.9604 - val_loss: 0.1123 - val_accuracy: 0.9605 - 12s/epoch - 2ms/step\n",
            "Epoch 321/800\n",
            "6930/6930 - 12s - loss: 0.1064 - accuracy: 0.9603 - val_loss: 0.1052 - val_accuracy: 0.9645 - 12s/epoch - 2ms/step\n",
            "Epoch 322/800\n",
            "6930/6930 - 12s - loss: 0.1059 - accuracy: 0.9606 - val_loss: 0.1145 - val_accuracy: 0.9601 - 12s/epoch - 2ms/step\n",
            "Epoch 323/800\n",
            "6930/6930 - 12s - loss: 0.1069 - accuracy: 0.9605 - val_loss: 0.1109 - val_accuracy: 0.9586 - 12s/epoch - 2ms/step\n",
            "Epoch 324/800\n",
            "6930/6930 - 12s - loss: 0.1050 - accuracy: 0.9613 - val_loss: 0.1097 - val_accuracy: 0.9584 - 12s/epoch - 2ms/step\n",
            "Epoch 325/800\n",
            "6930/6930 - 12s - loss: 0.1048 - accuracy: 0.9616 - val_loss: 0.1246 - val_accuracy: 0.9545 - 12s/epoch - 2ms/step\n",
            "Epoch 326/800\n",
            "6930/6930 - 12s - loss: 0.1044 - accuracy: 0.9612 - val_loss: 0.1455 - val_accuracy: 0.9484 - 12s/epoch - 2ms/step\n",
            "Epoch 327/800\n",
            "6930/6930 - 12s - loss: 0.1053 - accuracy: 0.9613 - val_loss: 0.1069 - val_accuracy: 0.9629 - 12s/epoch - 2ms/step\n",
            "Epoch 328/800\n",
            "6930/6930 - 12s - loss: 0.1045 - accuracy: 0.9614 - val_loss: 0.1062 - val_accuracy: 0.9609 - 12s/epoch - 2ms/step\n",
            "Epoch 329/800\n",
            "6930/6930 - 12s - loss: 0.1046 - accuracy: 0.9614 - val_loss: 0.1279 - val_accuracy: 0.9551 - 12s/epoch - 2ms/step\n",
            "Epoch 330/800\n",
            "6930/6930 - 11s - loss: 0.1047 - accuracy: 0.9617 - val_loss: 0.1633 - val_accuracy: 0.9401 - 11s/epoch - 2ms/step\n",
            "Epoch 331/800\n",
            "6930/6930 - 12s - loss: 0.1048 - accuracy: 0.9612 - val_loss: 0.1017 - val_accuracy: 0.9632 - 12s/epoch - 2ms/step\n",
            "Epoch 332/800\n",
            "6930/6930 - 12s - loss: 0.1048 - accuracy: 0.9611 - val_loss: 0.1039 - val_accuracy: 0.9648 - 12s/epoch - 2ms/step\n",
            "Epoch 333/800\n",
            "6930/6930 - 12s - loss: 0.1040 - accuracy: 0.9614 - val_loss: 0.1458 - val_accuracy: 0.9442 - 12s/epoch - 2ms/step\n",
            "Epoch 334/800\n",
            "6930/6930 - 12s - loss: 0.1034 - accuracy: 0.9616 - val_loss: 0.1049 - val_accuracy: 0.9632 - 12s/epoch - 2ms/step\n",
            "Epoch 335/800\n",
            "6930/6930 - 12s - loss: 0.1034 - accuracy: 0.9620 - val_loss: 0.1056 - val_accuracy: 0.9632 - 12s/epoch - 2ms/step\n",
            "Epoch 336/800\n",
            "6930/6930 - 12s - loss: 0.1035 - accuracy: 0.9617 - val_loss: 0.1023 - val_accuracy: 0.9656 - 12s/epoch - 2ms/step\n",
            "Epoch 337/800\n",
            "6930/6930 - 12s - loss: 0.1034 - accuracy: 0.9619 - val_loss: 0.1016 - val_accuracy: 0.9652 - 12s/epoch - 2ms/step\n",
            "Epoch 338/800\n",
            "6930/6930 - 12s - loss: 0.1032 - accuracy: 0.9616 - val_loss: 0.1257 - val_accuracy: 0.9547 - 12s/epoch - 2ms/step\n",
            "Epoch 339/800\n",
            "6930/6930 - 12s - loss: 0.1024 - accuracy: 0.9622 - val_loss: 0.1099 - val_accuracy: 0.9591 - 12s/epoch - 2ms/step\n",
            "Epoch 340/800\n",
            "6930/6930 - 11s - loss: 0.1030 - accuracy: 0.9622 - val_loss: 0.1161 - val_accuracy: 0.9578 - 11s/epoch - 2ms/step\n",
            "Epoch 341/800\n",
            "6930/6930 - 12s - loss: 0.1022 - accuracy: 0.9617 - val_loss: 0.1031 - val_accuracy: 0.9642 - 12s/epoch - 2ms/step\n",
            "Epoch 342/800\n",
            "6930/6930 - 12s - loss: 0.1025 - accuracy: 0.9619 - val_loss: 0.1438 - val_accuracy: 0.9475 - 12s/epoch - 2ms/step\n",
            "Epoch 343/800\n",
            "6930/6930 - 12s - loss: 0.1023 - accuracy: 0.9624 - val_loss: 0.1032 - val_accuracy: 0.9644 - 12s/epoch - 2ms/step\n",
            "Epoch 344/800\n",
            "6930/6930 - 12s - loss: 0.1014 - accuracy: 0.9622 - val_loss: 0.1045 - val_accuracy: 0.9632 - 12s/epoch - 2ms/step\n",
            "Epoch 345/800\n",
            "6930/6930 - 12s - loss: 0.1026 - accuracy: 0.9617 - val_loss: 0.1177 - val_accuracy: 0.9577 - 12s/epoch - 2ms/step\n",
            "Epoch 346/800\n",
            "6930/6930 - 12s - loss: 0.1008 - accuracy: 0.9629 - val_loss: 0.1133 - val_accuracy: 0.9594 - 12s/epoch - 2ms/step\n",
            "Epoch 347/800\n",
            "6930/6930 - 12s - loss: 0.1026 - accuracy: 0.9613 - val_loss: 0.1027 - val_accuracy: 0.9640 - 12s/epoch - 2ms/step\n",
            "Epoch 348/800\n",
            "6930/6930 - 12s - loss: 0.1017 - accuracy: 0.9623 - val_loss: 0.1270 - val_accuracy: 0.9555 - 12s/epoch - 2ms/step\n",
            "Epoch 349/800\n",
            "6930/6930 - 12s - loss: 0.1011 - accuracy: 0.9625 - val_loss: 0.1119 - val_accuracy: 0.9610 - 12s/epoch - 2ms/step\n",
            "Epoch 350/800\n",
            "6930/6930 - 12s - loss: 0.1009 - accuracy: 0.9627 - val_loss: 0.1014 - val_accuracy: 0.9660 - 12s/epoch - 2ms/step\n",
            "Epoch 351/800\n",
            "6930/6930 - 12s - loss: 0.1003 - accuracy: 0.9628 - val_loss: 0.1088 - val_accuracy: 0.9623 - 12s/epoch - 2ms/step\n",
            "Epoch 352/800\n",
            "6930/6930 - 12s - loss: 0.1002 - accuracy: 0.9628 - val_loss: 0.0986 - val_accuracy: 0.9683 - 12s/epoch - 2ms/step\n",
            "Epoch 353/800\n",
            "6930/6930 - 12s - loss: 0.1019 - accuracy: 0.9617 - val_loss: 0.1041 - val_accuracy: 0.9639 - 12s/epoch - 2ms/step\n",
            "Epoch 354/800\n",
            "6930/6930 - 12s - loss: 0.1012 - accuracy: 0.9622 - val_loss: 0.1076 - val_accuracy: 0.9623 - 12s/epoch - 2ms/step\n",
            "Epoch 355/800\n",
            "6930/6930 - 12s - loss: 0.1012 - accuracy: 0.9627 - val_loss: 0.1006 - val_accuracy: 0.9644 - 12s/epoch - 2ms/step\n",
            "Epoch 356/800\n",
            "6930/6930 - 12s - loss: 0.1001 - accuracy: 0.9631 - val_loss: 0.1056 - val_accuracy: 0.9631 - 12s/epoch - 2ms/step\n",
            "Epoch 357/800\n",
            "6930/6930 - 12s - loss: 0.0994 - accuracy: 0.9627 - val_loss: 0.1003 - val_accuracy: 0.9644 - 12s/epoch - 2ms/step\n",
            "Epoch 358/800\n",
            "6930/6930 - 12s - loss: 0.1004 - accuracy: 0.9627 - val_loss: 0.1072 - val_accuracy: 0.9618 - 12s/epoch - 2ms/step\n",
            "Epoch 359/800\n",
            "6930/6930 - 12s - loss: 0.1011 - accuracy: 0.9627 - val_loss: 0.1106 - val_accuracy: 0.9609 - 12s/epoch - 2ms/step\n",
            "Epoch 360/800\n",
            "6930/6930 - 11s - loss: 0.1001 - accuracy: 0.9633 - val_loss: 0.1050 - val_accuracy: 0.9649 - 11s/epoch - 2ms/step\n",
            "Epoch 361/800\n",
            "6930/6930 - 12s - loss: 0.0998 - accuracy: 0.9628 - val_loss: 0.1013 - val_accuracy: 0.9643 - 12s/epoch - 2ms/step\n",
            "Epoch 362/800\n",
            "6930/6930 - 12s - loss: 0.0998 - accuracy: 0.9633 - val_loss: 0.1271 - val_accuracy: 0.9518 - 12s/epoch - 2ms/step\n",
            "Epoch 363/800\n",
            "6930/6930 - 12s - loss: 0.0988 - accuracy: 0.9631 - val_loss: 0.1146 - val_accuracy: 0.9592 - 12s/epoch - 2ms/step\n",
            "Epoch 364/800\n",
            "6930/6930 - 12s - loss: 0.0998 - accuracy: 0.9630 - val_loss: 0.1025 - val_accuracy: 0.9640 - 12s/epoch - 2ms/step\n",
            "Epoch 365/800\n",
            "6930/6930 - 12s - loss: 0.0984 - accuracy: 0.9635 - val_loss: 0.1122 - val_accuracy: 0.9596 - 12s/epoch - 2ms/step\n",
            "Epoch 366/800\n",
            "6930/6930 - 12s - loss: 0.0994 - accuracy: 0.9639 - val_loss: 0.1006 - val_accuracy: 0.9673 - 12s/epoch - 2ms/step\n",
            "Epoch 367/800\n",
            "6930/6930 - 12s - loss: 0.0994 - accuracy: 0.9634 - val_loss: 0.1121 - val_accuracy: 0.9605 - 12s/epoch - 2ms/step\n",
            "Epoch 368/800\n",
            "6930/6930 - 12s - loss: 0.0989 - accuracy: 0.9634 - val_loss: 0.1033 - val_accuracy: 0.9645 - 12s/epoch - 2ms/step\n",
            "Epoch 369/800\n",
            "6930/6930 - 12s - loss: 0.0982 - accuracy: 0.9640 - val_loss: 0.0944 - val_accuracy: 0.9662 - 12s/epoch - 2ms/step\n",
            "Epoch 370/800\n",
            "6930/6930 - 12s - loss: 0.0980 - accuracy: 0.9644 - val_loss: 0.1004 - val_accuracy: 0.9662 - 12s/epoch - 2ms/step\n",
            "Epoch 371/800\n",
            "6930/6930 - 12s - loss: 0.0978 - accuracy: 0.9634 - val_loss: 0.0996 - val_accuracy: 0.9660 - 12s/epoch - 2ms/step\n",
            "Epoch 372/800\n",
            "6930/6930 - 12s - loss: 0.0979 - accuracy: 0.9637 - val_loss: 0.0974 - val_accuracy: 0.9664 - 12s/epoch - 2ms/step\n",
            "Epoch 373/800\n",
            "6930/6930 - 12s - loss: 0.0972 - accuracy: 0.9641 - val_loss: 0.0955 - val_accuracy: 0.9655 - 12s/epoch - 2ms/step\n",
            "Epoch 374/800\n",
            "6930/6930 - 12s - loss: 0.0985 - accuracy: 0.9636 - val_loss: 0.0964 - val_accuracy: 0.9657 - 12s/epoch - 2ms/step\n",
            "Epoch 375/800\n",
            "6930/6930 - 12s - loss: 0.0984 - accuracy: 0.9637 - val_loss: 0.1079 - val_accuracy: 0.9621 - 12s/epoch - 2ms/step\n",
            "Epoch 376/800\n",
            "6930/6930 - 12s - loss: 0.0980 - accuracy: 0.9633 - val_loss: 0.1192 - val_accuracy: 0.9574 - 12s/epoch - 2ms/step\n",
            "Epoch 377/800\n",
            "6930/6930 - 12s - loss: 0.0972 - accuracy: 0.9639 - val_loss: 0.1178 - val_accuracy: 0.9595 - 12s/epoch - 2ms/step\n",
            "Epoch 378/800\n",
            "6930/6930 - 12s - loss: 0.0985 - accuracy: 0.9637 - val_loss: 0.0957 - val_accuracy: 0.9673 - 12s/epoch - 2ms/step\n",
            "Epoch 379/800\n",
            "6930/6930 - 12s - loss: 0.0980 - accuracy: 0.9634 - val_loss: 0.1053 - val_accuracy: 0.9630 - 12s/epoch - 2ms/step\n",
            "Epoch 380/800\n",
            "6930/6930 - 11s - loss: 0.0969 - accuracy: 0.9642 - val_loss: 0.1042 - val_accuracy: 0.9631 - 11s/epoch - 2ms/step\n",
            "Epoch 381/800\n",
            "6930/6930 - 11s - loss: 0.0972 - accuracy: 0.9642 - val_loss: 0.0988 - val_accuracy: 0.9662 - 11s/epoch - 2ms/step\n",
            "Epoch 382/800\n",
            "6930/6930 - 12s - loss: 0.0975 - accuracy: 0.9637 - val_loss: 0.0952 - val_accuracy: 0.9686 - 12s/epoch - 2ms/step\n",
            "Epoch 383/800\n",
            "6930/6930 - 12s - loss: 0.0973 - accuracy: 0.9639 - val_loss: 0.1028 - val_accuracy: 0.9638 - 12s/epoch - 2ms/step\n",
            "Epoch 384/800\n",
            "6930/6930 - 12s - loss: 0.0964 - accuracy: 0.9640 - val_loss: 0.0964 - val_accuracy: 0.9670 - 12s/epoch - 2ms/step\n",
            "Epoch 385/800\n",
            "6930/6930 - 12s - loss: 0.0965 - accuracy: 0.9641 - val_loss: 0.0923 - val_accuracy: 0.9675 - 12s/epoch - 2ms/step\n",
            "Epoch 386/800\n",
            "6930/6930 - 12s - loss: 0.0956 - accuracy: 0.9646 - val_loss: 0.1020 - val_accuracy: 0.9645 - 12s/epoch - 2ms/step\n",
            "Epoch 387/800\n",
            "6930/6930 - 12s - loss: 0.0958 - accuracy: 0.9642 - val_loss: 0.0955 - val_accuracy: 0.9679 - 12s/epoch - 2ms/step\n",
            "Epoch 388/800\n",
            "6930/6930 - 11s - loss: 0.0957 - accuracy: 0.9657 - val_loss: 0.1004 - val_accuracy: 0.9656 - 11s/epoch - 2ms/step\n",
            "Epoch 389/800\n",
            "6930/6930 - 12s - loss: 0.0955 - accuracy: 0.9644 - val_loss: 0.1107 - val_accuracy: 0.9592 - 12s/epoch - 2ms/step\n",
            "Epoch 390/800\n",
            "6930/6930 - 12s - loss: 0.0956 - accuracy: 0.9643 - val_loss: 0.1007 - val_accuracy: 0.9657 - 12s/epoch - 2ms/step\n",
            "Epoch 391/800\n",
            "6930/6930 - 12s - loss: 0.0949 - accuracy: 0.9648 - val_loss: 0.1001 - val_accuracy: 0.9660 - 12s/epoch - 2ms/step\n",
            "Epoch 392/800\n",
            "6930/6930 - 12s - loss: 0.0948 - accuracy: 0.9648 - val_loss: 0.0954 - val_accuracy: 0.9682 - 12s/epoch - 2ms/step\n",
            "Epoch 393/800\n",
            "6930/6930 - 12s - loss: 0.0954 - accuracy: 0.9647 - val_loss: 0.1533 - val_accuracy: 0.9406 - 12s/epoch - 2ms/step\n",
            "Epoch 394/800\n",
            "6930/6930 - 11s - loss: 0.0952 - accuracy: 0.9644 - val_loss: 0.1069 - val_accuracy: 0.9614 - 11s/epoch - 2ms/step\n",
            "Epoch 395/800\n",
            "6930/6930 - 12s - loss: 0.0949 - accuracy: 0.9652 - val_loss: 0.1029 - val_accuracy: 0.9631 - 12s/epoch - 2ms/step\n",
            "Epoch 396/800\n",
            "6930/6930 - 12s - loss: 0.0952 - accuracy: 0.9644 - val_loss: 0.1000 - val_accuracy: 0.9647 - 12s/epoch - 2ms/step\n",
            "Epoch 397/800\n",
            "6930/6930 - 12s - loss: 0.0949 - accuracy: 0.9648 - val_loss: 0.0960 - val_accuracy: 0.9669 - 12s/epoch - 2ms/step\n",
            "Epoch 398/800\n",
            "6930/6930 - 12s - loss: 0.0948 - accuracy: 0.9646 - val_loss: 0.1012 - val_accuracy: 0.9642 - 12s/epoch - 2ms/step\n",
            "Epoch 399/800\n",
            "6930/6930 - 12s - loss: 0.0947 - accuracy: 0.9648 - val_loss: 0.1164 - val_accuracy: 0.9577 - 12s/epoch - 2ms/step\n",
            "Epoch 400/800\n",
            "6930/6930 - 12s - loss: 0.0942 - accuracy: 0.9646 - val_loss: 0.1089 - val_accuracy: 0.9596 - 12s/epoch - 2ms/step\n",
            "Epoch 401/800\n",
            "6930/6930 - 12s - loss: 0.0943 - accuracy: 0.9649 - val_loss: 0.0978 - val_accuracy: 0.9662 - 12s/epoch - 2ms/step\n",
            "Epoch 402/800\n",
            "6930/6930 - 12s - loss: 0.0950 - accuracy: 0.9646 - val_loss: 0.0936 - val_accuracy: 0.9671 - 12s/epoch - 2ms/step\n",
            "Epoch 403/800\n",
            "6930/6930 - 12s - loss: 0.0937 - accuracy: 0.9649 - val_loss: 0.1200 - val_accuracy: 0.9551 - 12s/epoch - 2ms/step\n",
            "Epoch 404/800\n",
            "6930/6930 - 12s - loss: 0.0950 - accuracy: 0.9650 - val_loss: 0.0937 - val_accuracy: 0.9678 - 12s/epoch - 2ms/step\n",
            "Epoch 405/800\n",
            "6930/6930 - 12s - loss: 0.0944 - accuracy: 0.9651 - val_loss: 0.0987 - val_accuracy: 0.9642 - 12s/epoch - 2ms/step\n",
            "Epoch 406/800\n",
            "6930/6930 - 11s - loss: 0.0938 - accuracy: 0.9651 - val_loss: 0.0957 - val_accuracy: 0.9656 - 11s/epoch - 2ms/step\n",
            "Epoch 407/800\n",
            "6930/6930 - 12s - loss: 0.0940 - accuracy: 0.9660 - val_loss: 0.0975 - val_accuracy: 0.9668 - 12s/epoch - 2ms/step\n",
            "Epoch 408/800\n",
            "6930/6930 - 12s - loss: 0.0939 - accuracy: 0.9650 - val_loss: 0.1047 - val_accuracy: 0.9621 - 12s/epoch - 2ms/step\n",
            "Epoch 409/800\n",
            "6930/6930 - 12s - loss: 0.0944 - accuracy: 0.9647 - val_loss: 0.1012 - val_accuracy: 0.9640 - 12s/epoch - 2ms/step\n",
            "Epoch 410/800\n",
            "6930/6930 - 12s - loss: 0.0928 - accuracy: 0.9661 - val_loss: 0.1286 - val_accuracy: 0.9519 - 12s/epoch - 2ms/step\n",
            "Epoch 411/800\n",
            "6930/6930 - 11s - loss: 0.0931 - accuracy: 0.9646 - val_loss: 0.1038 - val_accuracy: 0.9642 - 11s/epoch - 2ms/step\n",
            "Epoch 412/800\n",
            "6930/6930 - 12s - loss: 0.0929 - accuracy: 0.9654 - val_loss: 0.0917 - val_accuracy: 0.9682 - 12s/epoch - 2ms/step\n",
            "Epoch 413/800\n",
            "6930/6930 - 12s - loss: 0.0928 - accuracy: 0.9657 - val_loss: 0.1246 - val_accuracy: 0.9566 - 12s/epoch - 2ms/step\n",
            "Epoch 414/800\n",
            "6930/6930 - 12s - loss: 0.0934 - accuracy: 0.9650 - val_loss: 0.0940 - val_accuracy: 0.9681 - 12s/epoch - 2ms/step\n",
            "Epoch 415/800\n",
            "6930/6930 - 12s - loss: 0.0924 - accuracy: 0.9657 - val_loss: 0.1016 - val_accuracy: 0.9632 - 12s/epoch - 2ms/step\n",
            "Epoch 416/800\n",
            "6930/6930 - 12s - loss: 0.0931 - accuracy: 0.9655 - val_loss: 0.0969 - val_accuracy: 0.9644 - 12s/epoch - 2ms/step\n",
            "Epoch 417/800\n",
            "6930/6930 - 12s - loss: 0.0935 - accuracy: 0.9651 - val_loss: 0.1222 - val_accuracy: 0.9555 - 12s/epoch - 2ms/step\n",
            "Epoch 418/800\n",
            "6930/6930 - 12s - loss: 0.0924 - accuracy: 0.9659 - val_loss: 0.0957 - val_accuracy: 0.9678 - 12s/epoch - 2ms/step\n",
            "Epoch 419/800\n",
            "6930/6930 - 12s - loss: 0.0923 - accuracy: 0.9658 - val_loss: 0.1009 - val_accuracy: 0.9640 - 12s/epoch - 2ms/step\n",
            "Epoch 420/800\n",
            "6930/6930 - 12s - loss: 0.0919 - accuracy: 0.9662 - val_loss: 0.0952 - val_accuracy: 0.9673 - 12s/epoch - 2ms/step\n",
            "Epoch 421/800\n",
            "6930/6930 - 12s - loss: 0.0919 - accuracy: 0.9660 - val_loss: 0.0917 - val_accuracy: 0.9662 - 12s/epoch - 2ms/step\n",
            "Epoch 422/800\n",
            "6930/6930 - 12s - loss: 0.0923 - accuracy: 0.9651 - val_loss: 0.1050 - val_accuracy: 0.9629 - 12s/epoch - 2ms/step\n",
            "Epoch 423/800\n",
            "6930/6930 - 12s - loss: 0.0919 - accuracy: 0.9653 - val_loss: 0.0963 - val_accuracy: 0.9684 - 12s/epoch - 2ms/step\n",
            "Epoch 424/800\n",
            "6930/6930 - 12s - loss: 0.0926 - accuracy: 0.9656 - val_loss: 0.1047 - val_accuracy: 0.9635 - 12s/epoch - 2ms/step\n",
            "Epoch 425/800\n",
            "6930/6930 - 12s - loss: 0.0917 - accuracy: 0.9659 - val_loss: 0.0963 - val_accuracy: 0.9675 - 12s/epoch - 2ms/step\n",
            "Epoch 426/800\n",
            "6930/6930 - 12s - loss: 0.0912 - accuracy: 0.9664 - val_loss: 0.0965 - val_accuracy: 0.9665 - 12s/epoch - 2ms/step\n",
            "Epoch 427/800\n",
            "6930/6930 - 12s - loss: 0.0917 - accuracy: 0.9663 - val_loss: 0.0925 - val_accuracy: 0.9666 - 12s/epoch - 2ms/step\n",
            "Epoch 428/800\n",
            "6930/6930 - 12s - loss: 0.0911 - accuracy: 0.9661 - val_loss: 0.0962 - val_accuracy: 0.9653 - 12s/epoch - 2ms/step\n",
            "Epoch 429/800\n",
            "6930/6930 - 12s - loss: 0.0915 - accuracy: 0.9655 - val_loss: 0.0975 - val_accuracy: 0.9645 - 12s/epoch - 2ms/step\n",
            "Epoch 430/800\n",
            "6930/6930 - 12s - loss: 0.0904 - accuracy: 0.9665 - val_loss: 0.0978 - val_accuracy: 0.9655 - 12s/epoch - 2ms/step\n",
            "Epoch 431/800\n",
            "6930/6930 - 12s - loss: 0.0910 - accuracy: 0.9666 - val_loss: 0.0907 - val_accuracy: 0.9684 - 12s/epoch - 2ms/step\n",
            "Epoch 432/800\n",
            "6930/6930 - 11s - loss: 0.0905 - accuracy: 0.9664 - val_loss: 0.0954 - val_accuracy: 0.9669 - 11s/epoch - 2ms/step\n",
            "Epoch 433/800\n",
            "6930/6930 - 12s - loss: 0.0916 - accuracy: 0.9655 - val_loss: 0.0905 - val_accuracy: 0.9692 - 12s/epoch - 2ms/step\n",
            "Epoch 434/800\n",
            "6930/6930 - 12s - loss: 0.0916 - accuracy: 0.9657 - val_loss: 0.0946 - val_accuracy: 0.9664 - 12s/epoch - 2ms/step\n",
            "Epoch 435/800\n",
            "6930/6930 - 12s - loss: 0.0916 - accuracy: 0.9660 - val_loss: 0.1033 - val_accuracy: 0.9639 - 12s/epoch - 2ms/step\n",
            "Epoch 436/800\n",
            "6930/6930 - 12s - loss: 0.0900 - accuracy: 0.9665 - val_loss: 0.0885 - val_accuracy: 0.9709 - 12s/epoch - 2ms/step\n",
            "Epoch 437/800\n",
            "6930/6930 - 12s - loss: 0.0909 - accuracy: 0.9665 - val_loss: 0.0883 - val_accuracy: 0.9681 - 12s/epoch - 2ms/step\n",
            "Epoch 438/800\n",
            "6930/6930 - 12s - loss: 0.0901 - accuracy: 0.9664 - val_loss: 0.0977 - val_accuracy: 0.9655 - 12s/epoch - 2ms/step\n",
            "Epoch 439/800\n",
            "6930/6930 - 12s - loss: 0.0901 - accuracy: 0.9669 - val_loss: 0.0952 - val_accuracy: 0.9678 - 12s/epoch - 2ms/step\n",
            "Epoch 440/800\n",
            "6930/6930 - 12s - loss: 0.0901 - accuracy: 0.9659 - val_loss: 0.1023 - val_accuracy: 0.9651 - 12s/epoch - 2ms/step\n",
            "Epoch 441/800\n",
            "6930/6930 - 12s - loss: 0.0907 - accuracy: 0.9663 - val_loss: 0.1055 - val_accuracy: 0.9617 - 12s/epoch - 2ms/step\n",
            "Epoch 442/800\n",
            "6930/6930 - 12s - loss: 0.0904 - accuracy: 0.9669 - val_loss: 0.1265 - val_accuracy: 0.9517 - 12s/epoch - 2ms/step\n",
            "Epoch 443/800\n",
            "6930/6930 - 12s - loss: 0.0905 - accuracy: 0.9660 - val_loss: 0.0976 - val_accuracy: 0.9661 - 12s/epoch - 2ms/step\n",
            "Epoch 444/800\n",
            "6930/6930 - 12s - loss: 0.0894 - accuracy: 0.9671 - val_loss: 0.0915 - val_accuracy: 0.9688 - 12s/epoch - 2ms/step\n",
            "Epoch 445/800\n",
            "6930/6930 - 12s - loss: 0.0897 - accuracy: 0.9664 - val_loss: 0.0989 - val_accuracy: 0.9644 - 12s/epoch - 2ms/step\n",
            "Epoch 446/800\n",
            "6930/6930 - 12s - loss: 0.0898 - accuracy: 0.9666 - val_loss: 0.1211 - val_accuracy: 0.9553 - 12s/epoch - 2ms/step\n",
            "Epoch 447/800\n",
            "6930/6930 - 12s - loss: 0.0900 - accuracy: 0.9666 - val_loss: 0.1011 - val_accuracy: 0.9657 - 12s/epoch - 2ms/step\n",
            "Epoch 448/800\n",
            "6930/6930 - 12s - loss: 0.0895 - accuracy: 0.9665 - val_loss: 0.0942 - val_accuracy: 0.9670 - 12s/epoch - 2ms/step\n",
            "Epoch 449/800\n",
            "6930/6930 - 11s - loss: 0.0890 - accuracy: 0.9674 - val_loss: 0.1021 - val_accuracy: 0.9627 - 11s/epoch - 2ms/step\n",
            "Epoch 450/800\n",
            "6930/6930 - 12s - loss: 0.0890 - accuracy: 0.9667 - val_loss: 0.0985 - val_accuracy: 0.9655 - 12s/epoch - 2ms/step\n",
            "Epoch 451/800\n",
            "6930/6930 - 12s - loss: 0.0899 - accuracy: 0.9659 - val_loss: 0.0968 - val_accuracy: 0.9677 - 12s/epoch - 2ms/step\n",
            "Epoch 452/800\n",
            "6930/6930 - 12s - loss: 0.0890 - accuracy: 0.9666 - val_loss: 0.1098 - val_accuracy: 0.9642 - 12s/epoch - 2ms/step\n",
            "Epoch 453/800\n",
            "6930/6930 - 12s - loss: 0.0894 - accuracy: 0.9661 - val_loss: 0.1004 - val_accuracy: 0.9644 - 12s/epoch - 2ms/step\n",
            "Epoch 454/800\n",
            "6930/6930 - 12s - loss: 0.0889 - accuracy: 0.9663 - val_loss: 0.0970 - val_accuracy: 0.9664 - 12s/epoch - 2ms/step\n",
            "Epoch 455/800\n",
            "6930/6930 - 12s - loss: 0.0887 - accuracy: 0.9667 - val_loss: 0.0960 - val_accuracy: 0.9671 - 12s/epoch - 2ms/step\n",
            "Epoch 456/800\n",
            "6930/6930 - 12s - loss: 0.0886 - accuracy: 0.9671 - val_loss: 0.0951 - val_accuracy: 0.9683 - 12s/epoch - 2ms/step\n",
            "Epoch 457/800\n",
            "6930/6930 - 12s - loss: 0.0893 - accuracy: 0.9664 - val_loss: 0.1205 - val_accuracy: 0.9578 - 12s/epoch - 2ms/step\n",
            "Epoch 458/800\n",
            "6930/6930 - 12s - loss: 0.0884 - accuracy: 0.9670 - val_loss: 0.1146 - val_accuracy: 0.9599 - 12s/epoch - 2ms/step\n",
            "Epoch 459/800\n",
            "6930/6930 - 12s - loss: 0.0878 - accuracy: 0.9674 - val_loss: 0.0955 - val_accuracy: 0.9687 - 12s/epoch - 2ms/step\n",
            "Epoch 460/800\n",
            "6930/6930 - 12s - loss: 0.0879 - accuracy: 0.9673 - val_loss: 0.0978 - val_accuracy: 0.9673 - 12s/epoch - 2ms/step\n",
            "Epoch 461/800\n",
            "6930/6930 - 12s - loss: 0.0884 - accuracy: 0.9664 - val_loss: 0.0926 - val_accuracy: 0.9683 - 12s/epoch - 2ms/step\n",
            "Epoch 462/800\n",
            "6930/6930 - 12s - loss: 0.0884 - accuracy: 0.9662 - val_loss: 0.1020 - val_accuracy: 0.9645 - 12s/epoch - 2ms/step\n",
            "Epoch 463/800\n",
            "6930/6930 - 11s - loss: 0.0882 - accuracy: 0.9675 - val_loss: 0.1239 - val_accuracy: 0.9548 - 11s/epoch - 2ms/step\n",
            "Epoch 464/800\n",
            "6930/6930 - 12s - loss: 0.0881 - accuracy: 0.9671 - val_loss: 0.0906 - val_accuracy: 0.9696 - 12s/epoch - 2ms/step\n",
            "Epoch 465/800\n",
            "6930/6930 - 12s - loss: 0.0890 - accuracy: 0.9668 - val_loss: 0.0921 - val_accuracy: 0.9681 - 12s/epoch - 2ms/step\n",
            "Epoch 466/800\n",
            "6930/6930 - 12s - loss: 0.0870 - accuracy: 0.9675 - val_loss: 0.0907 - val_accuracy: 0.9697 - 12s/epoch - 2ms/step\n",
            "Epoch 467/800\n",
            "6930/6930 - 12s - loss: 0.0884 - accuracy: 0.9667 - val_loss: 0.1030 - val_accuracy: 0.9632 - 12s/epoch - 2ms/step\n",
            "Epoch 468/800\n",
            "6930/6930 - 11s - loss: 0.0872 - accuracy: 0.9677 - val_loss: 0.0875 - val_accuracy: 0.9704 - 11s/epoch - 2ms/step\n",
            "Epoch 469/800\n",
            "6930/6930 - 12s - loss: 0.0879 - accuracy: 0.9676 - val_loss: 0.1038 - val_accuracy: 0.9653 - 12s/epoch - 2ms/step\n",
            "Epoch 470/800\n",
            "6930/6930 - 12s - loss: 0.0872 - accuracy: 0.9679 - val_loss: 0.0922 - val_accuracy: 0.9684 - 12s/epoch - 2ms/step\n",
            "Epoch 471/800\n",
            "6930/6930 - 11s - loss: 0.0867 - accuracy: 0.9676 - val_loss: 0.0938 - val_accuracy: 0.9673 - 11s/epoch - 2ms/step\n",
            "Epoch 472/800\n",
            "6930/6930 - 12s - loss: 0.0878 - accuracy: 0.9671 - val_loss: 0.1093 - val_accuracy: 0.9594 - 12s/epoch - 2ms/step\n",
            "Epoch 473/800\n",
            "6930/6930 - 11s - loss: 0.0868 - accuracy: 0.9678 - val_loss: 0.0954 - val_accuracy: 0.9668 - 11s/epoch - 2ms/step\n",
            "Epoch 474/800\n",
            "6930/6930 - 12s - loss: 0.0872 - accuracy: 0.9670 - val_loss: 0.1533 - val_accuracy: 0.9456 - 12s/epoch - 2ms/step\n",
            "Epoch 475/800\n",
            "6930/6930 - 12s - loss: 0.0874 - accuracy: 0.9674 - val_loss: 0.0879 - val_accuracy: 0.9709 - 12s/epoch - 2ms/step\n",
            "Epoch 476/800\n",
            "6930/6930 - 12s - loss: 0.0884 - accuracy: 0.9671 - val_loss: 0.0915 - val_accuracy: 0.9683 - 12s/epoch - 2ms/step\n",
            "Epoch 477/800\n",
            "6930/6930 - 12s - loss: 0.0872 - accuracy: 0.9672 - val_loss: 0.0916 - val_accuracy: 0.9683 - 12s/epoch - 2ms/step\n",
            "Epoch 478/800\n",
            "6930/6930 - 12s - loss: 0.0880 - accuracy: 0.9667 - val_loss: 0.0927 - val_accuracy: 0.9690 - 12s/epoch - 2ms/step\n",
            "Epoch 479/800\n",
            "6930/6930 - 11s - loss: 0.0878 - accuracy: 0.9672 - val_loss: 0.1040 - val_accuracy: 0.9613 - 11s/epoch - 2ms/step\n",
            "Epoch 480/800\n",
            "6930/6930 - 12s - loss: 0.0864 - accuracy: 0.9677 - val_loss: 0.0855 - val_accuracy: 0.9708 - 12s/epoch - 2ms/step\n",
            "Epoch 481/800\n",
            "6930/6930 - 12s - loss: 0.0866 - accuracy: 0.9671 - val_loss: 0.0920 - val_accuracy: 0.9686 - 12s/epoch - 2ms/step\n",
            "Epoch 482/800\n",
            "6930/6930 - 12s - loss: 0.0870 - accuracy: 0.9678 - val_loss: 0.0997 - val_accuracy: 0.9661 - 12s/epoch - 2ms/step\n",
            "Epoch 483/800\n",
            "6930/6930 - 12s - loss: 0.0864 - accuracy: 0.9679 - val_loss: 0.0973 - val_accuracy: 0.9677 - 12s/epoch - 2ms/step\n",
            "Epoch 484/800\n",
            "6930/6930 - 12s - loss: 0.0869 - accuracy: 0.9671 - val_loss: 0.0920 - val_accuracy: 0.9668 - 12s/epoch - 2ms/step\n",
            "Epoch 485/800\n",
            "6930/6930 - 12s - loss: 0.0872 - accuracy: 0.9672 - val_loss: 0.0943 - val_accuracy: 0.9660 - 12s/epoch - 2ms/step\n",
            "Epoch 486/800\n",
            "6930/6930 - 12s - loss: 0.0866 - accuracy: 0.9680 - val_loss: 0.0872 - val_accuracy: 0.9710 - 12s/epoch - 2ms/step\n",
            "Epoch 487/800\n",
            "6930/6930 - 12s - loss: 0.0864 - accuracy: 0.9677 - val_loss: 0.0980 - val_accuracy: 0.9660 - 12s/epoch - 2ms/step\n",
            "Epoch 488/800\n",
            "6930/6930 - 12s - loss: 0.0863 - accuracy: 0.9675 - val_loss: 0.0861 - val_accuracy: 0.9712 - 12s/epoch - 2ms/step\n",
            "Epoch 489/800\n",
            "6930/6930 - 12s - loss: 0.0859 - accuracy: 0.9682 - val_loss: 0.0924 - val_accuracy: 0.9668 - 12s/epoch - 2ms/step\n",
            "Epoch 490/800\n",
            "6930/6930 - 12s - loss: 0.0853 - accuracy: 0.9685 - val_loss: 0.1196 - val_accuracy: 0.9562 - 12s/epoch - 2ms/step\n",
            "Epoch 491/800\n",
            "6930/6930 - 12s - loss: 0.0864 - accuracy: 0.9676 - val_loss: 0.1049 - val_accuracy: 0.9632 - 12s/epoch - 2ms/step\n",
            "Epoch 492/800\n",
            "6930/6930 - 12s - loss: 0.0865 - accuracy: 0.9670 - val_loss: 0.0992 - val_accuracy: 0.9662 - 12s/epoch - 2ms/step\n",
            "Epoch 493/800\n",
            "6930/6930 - 12s - loss: 0.0861 - accuracy: 0.9679 - val_loss: 0.0947 - val_accuracy: 0.9665 - 12s/epoch - 2ms/step\n",
            "Epoch 494/800\n",
            "6930/6930 - 12s - loss: 0.0856 - accuracy: 0.9678 - val_loss: 0.1354 - val_accuracy: 0.9531 - 12s/epoch - 2ms/step\n",
            "Epoch 495/800\n",
            "6930/6930 - 11s - loss: 0.0859 - accuracy: 0.9675 - val_loss: 0.0847 - val_accuracy: 0.9716 - 11s/epoch - 2ms/step\n",
            "Epoch 496/800\n",
            "6930/6930 - 12s - loss: 0.0852 - accuracy: 0.9680 - val_loss: 0.1215 - val_accuracy: 0.9553 - 12s/epoch - 2ms/step\n",
            "Epoch 497/800\n",
            "6930/6930 - 12s - loss: 0.0856 - accuracy: 0.9679 - val_loss: 0.0908 - val_accuracy: 0.9714 - 12s/epoch - 2ms/step\n",
            "Epoch 498/800\n",
            "6930/6930 - 12s - loss: 0.0851 - accuracy: 0.9674 - val_loss: 0.0913 - val_accuracy: 0.9706 - 12s/epoch - 2ms/step\n",
            "Epoch 499/800\n",
            "6930/6930 - 12s - loss: 0.0853 - accuracy: 0.9684 - val_loss: 0.1027 - val_accuracy: 0.9655 - 12s/epoch - 2ms/step\n",
            "Epoch 500/800\n",
            "6930/6930 - 12s - loss: 0.0852 - accuracy: 0.9690 - val_loss: 0.0956 - val_accuracy: 0.9687 - 12s/epoch - 2ms/step\n",
            "Epoch 501/800\n",
            "6930/6930 - 12s - loss: 0.0850 - accuracy: 0.9681 - val_loss: 0.1110 - val_accuracy: 0.9614 - 12s/epoch - 2ms/step\n",
            "Epoch 502/800\n",
            "6930/6930 - 12s - loss: 0.0858 - accuracy: 0.9676 - val_loss: 0.0909 - val_accuracy: 0.9696 - 12s/epoch - 2ms/step\n",
            "Epoch 503/800\n",
            "6930/6930 - 12s - loss: 0.0852 - accuracy: 0.9676 - val_loss: 0.1268 - val_accuracy: 0.9562 - 12s/epoch - 2ms/step\n",
            "Epoch 504/800\n",
            "6930/6930 - 12s - loss: 0.0854 - accuracy: 0.9677 - val_loss: 0.0901 - val_accuracy: 0.9692 - 12s/epoch - 2ms/step\n",
            "Epoch 505/800\n",
            "6930/6930 - 12s - loss: 0.0841 - accuracy: 0.9689 - val_loss: 0.0990 - val_accuracy: 0.9644 - 12s/epoch - 2ms/step\n",
            "Epoch 506/800\n",
            "6930/6930 - 12s - loss: 0.0850 - accuracy: 0.9679 - val_loss: 0.0873 - val_accuracy: 0.9714 - 12s/epoch - 2ms/step\n",
            "Epoch 507/800\n",
            "6930/6930 - 12s - loss: 0.0851 - accuracy: 0.9680 - val_loss: 0.0932 - val_accuracy: 0.9674 - 12s/epoch - 2ms/step\n",
            "Epoch 508/800\n",
            "6930/6930 - 12s - loss: 0.0848 - accuracy: 0.9685 - val_loss: 0.0895 - val_accuracy: 0.9697 - 12s/epoch - 2ms/step\n",
            "Epoch 509/800\n",
            "6930/6930 - 12s - loss: 0.0844 - accuracy: 0.9685 - val_loss: 0.1025 - val_accuracy: 0.9645 - 12s/epoch - 2ms/step\n",
            "Epoch 510/800\n",
            "6930/6930 - 12s - loss: 0.0846 - accuracy: 0.9680 - val_loss: 0.0960 - val_accuracy: 0.9682 - 12s/epoch - 2ms/step\n",
            "Epoch 511/800\n",
            "6930/6930 - 12s - loss: 0.0845 - accuracy: 0.9685 - val_loss: 0.0929 - val_accuracy: 0.9679 - 12s/epoch - 2ms/step\n",
            "Epoch 512/800\n",
            "6930/6930 - 12s - loss: 0.0845 - accuracy: 0.9686 - val_loss: 0.0956 - val_accuracy: 0.9682 - 12s/epoch - 2ms/step\n",
            "Epoch 513/800\n",
            "6930/6930 - 11s - loss: 0.0844 - accuracy: 0.9683 - val_loss: 0.0988 - val_accuracy: 0.9669 - 11s/epoch - 2ms/step\n",
            "Epoch 514/800\n",
            "6930/6930 - 12s - loss: 0.0837 - accuracy: 0.9687 - val_loss: 0.0925 - val_accuracy: 0.9678 - 12s/epoch - 2ms/step\n",
            "Epoch 515/800\n",
            "6930/6930 - 12s - loss: 0.0847 - accuracy: 0.9683 - val_loss: 0.0981 - val_accuracy: 0.9647 - 12s/epoch - 2ms/step\n",
            "Epoch 516/800\n",
            "6930/6930 - 12s - loss: 0.0834 - accuracy: 0.9685 - val_loss: 0.0913 - val_accuracy: 0.9682 - 12s/epoch - 2ms/step\n",
            "Epoch 517/800\n",
            "6930/6930 - 12s - loss: 0.0844 - accuracy: 0.9681 - val_loss: 0.0969 - val_accuracy: 0.9675 - 12s/epoch - 2ms/step\n",
            "Epoch 518/800\n",
            "6930/6930 - 12s - loss: 0.0847 - accuracy: 0.9685 - val_loss: 0.1107 - val_accuracy: 0.9595 - 12s/epoch - 2ms/step\n",
            "Epoch 519/800\n",
            "6930/6930 - 11s - loss: 0.0837 - accuracy: 0.9690 - val_loss: 0.0949 - val_accuracy: 0.9677 - 11s/epoch - 2ms/step\n",
            "Epoch 520/800\n",
            "6930/6930 - 12s - loss: 0.0844 - accuracy: 0.9683 - val_loss: 0.0915 - val_accuracy: 0.9700 - 12s/epoch - 2ms/step\n",
            "Epoch 521/800\n",
            "6930/6930 - 12s - loss: 0.0838 - accuracy: 0.9684 - val_loss: 0.0863 - val_accuracy: 0.9719 - 12s/epoch - 2ms/step\n",
            "Epoch 522/800\n",
            "6930/6930 - 11s - loss: 0.0831 - accuracy: 0.9685 - val_loss: 0.0847 - val_accuracy: 0.9708 - 11s/epoch - 2ms/step\n",
            "Epoch 523/800\n",
            "6930/6930 - 11s - loss: 0.0830 - accuracy: 0.9688 - val_loss: 0.1079 - val_accuracy: 0.9627 - 11s/epoch - 2ms/step\n",
            "Epoch 524/800\n",
            "6930/6930 - 12s - loss: 0.0839 - accuracy: 0.9688 - val_loss: 0.0889 - val_accuracy: 0.9712 - 12s/epoch - 2ms/step\n",
            "Epoch 525/800\n",
            "6930/6930 - 12s - loss: 0.0844 - accuracy: 0.9685 - val_loss: 0.0974 - val_accuracy: 0.9664 - 12s/epoch - 2ms/step\n",
            "Epoch 526/800\n",
            "6930/6930 - 12s - loss: 0.0832 - accuracy: 0.9688 - val_loss: 0.0941 - val_accuracy: 0.9665 - 12s/epoch - 2ms/step\n",
            "Epoch 527/800\n",
            "6930/6930 - 12s - loss: 0.0830 - accuracy: 0.9685 - val_loss: 0.0997 - val_accuracy: 0.9657 - 12s/epoch - 2ms/step\n",
            "Epoch 528/800\n",
            "6930/6930 - 11s - loss: 0.0833 - accuracy: 0.9691 - val_loss: 0.0882 - val_accuracy: 0.9709 - 11s/epoch - 2ms/step\n",
            "Epoch 529/800\n",
            "6930/6930 - 12s - loss: 0.0827 - accuracy: 0.9691 - val_loss: 0.0903 - val_accuracy: 0.9688 - 12s/epoch - 2ms/step\n",
            "Epoch 530/800\n",
            "6930/6930 - 11s - loss: 0.0833 - accuracy: 0.9693 - val_loss: 0.0973 - val_accuracy: 0.9660 - 11s/epoch - 2ms/step\n",
            "Epoch 531/800\n",
            "6930/6930 - 12s - loss: 0.0826 - accuracy: 0.9694 - val_loss: 0.0937 - val_accuracy: 0.9658 - 12s/epoch - 2ms/step\n",
            "Epoch 532/800\n",
            "6930/6930 - 11s - loss: 0.0832 - accuracy: 0.9692 - val_loss: 0.0966 - val_accuracy: 0.9679 - 11s/epoch - 2ms/step\n",
            "Epoch 533/800\n",
            "6930/6930 - 12s - loss: 0.0829 - accuracy: 0.9687 - val_loss: 0.1427 - val_accuracy: 0.9460 - 12s/epoch - 2ms/step\n",
            "Epoch 534/800\n",
            "6930/6930 - 12s - loss: 0.0840 - accuracy: 0.9686 - val_loss: 0.0939 - val_accuracy: 0.9686 - 12s/epoch - 2ms/step\n",
            "Epoch 535/800\n",
            "6930/6930 - 12s - loss: 0.0832 - accuracy: 0.9687 - val_loss: 0.0893 - val_accuracy: 0.9688 - 12s/epoch - 2ms/step\n",
            "Epoch 536/800\n",
            "6930/6930 - 12s - loss: 0.0840 - accuracy: 0.9688 - val_loss: 0.0975 - val_accuracy: 0.9642 - 12s/epoch - 2ms/step\n",
            "Epoch 537/800\n",
            "6930/6930 - 12s - loss: 0.0816 - accuracy: 0.9695 - val_loss: 0.0845 - val_accuracy: 0.9719 - 12s/epoch - 2ms/step\n",
            "Epoch 538/800\n",
            "6930/6930 - 12s - loss: 0.0830 - accuracy: 0.9691 - val_loss: 0.0873 - val_accuracy: 0.9717 - 12s/epoch - 2ms/step\n",
            "Epoch 539/800\n",
            "6930/6930 - 12s - loss: 0.0829 - accuracy: 0.9689 - val_loss: 0.1240 - val_accuracy: 0.9578 - 12s/epoch - 2ms/step\n",
            "Epoch 540/800\n",
            "6930/6930 - 12s - loss: 0.0822 - accuracy: 0.9696 - val_loss: 0.1149 - val_accuracy: 0.9612 - 12s/epoch - 2ms/step\n",
            "Epoch 541/800\n",
            "6930/6930 - 12s - loss: 0.0819 - accuracy: 0.9693 - val_loss: 0.0892 - val_accuracy: 0.9705 - 12s/epoch - 2ms/step\n",
            "Epoch 542/800\n",
            "6930/6930 - 12s - loss: 0.0827 - accuracy: 0.9694 - val_loss: 0.0931 - val_accuracy: 0.9688 - 12s/epoch - 2ms/step\n",
            "Epoch 543/800\n",
            "6930/6930 - 12s - loss: 0.0822 - accuracy: 0.9689 - val_loss: 0.0923 - val_accuracy: 0.9700 - 12s/epoch - 2ms/step\n",
            "Epoch 544/800\n",
            "6930/6930 - 12s - loss: 0.0819 - accuracy: 0.9692 - val_loss: 0.1067 - val_accuracy: 0.9623 - 12s/epoch - 2ms/step\n",
            "Epoch 545/800\n",
            "6930/6930 - 11s - loss: 0.0823 - accuracy: 0.9695 - val_loss: 0.0845 - val_accuracy: 0.9725 - 11s/epoch - 2ms/step\n",
            "Epoch 546/800\n",
            "6930/6930 - 12s - loss: 0.0831 - accuracy: 0.9689 - val_loss: 0.0970 - val_accuracy: 0.9661 - 12s/epoch - 2ms/step\n",
            "Epoch 547/800\n",
            "6930/6930 - 12s - loss: 0.0815 - accuracy: 0.9692 - val_loss: 0.0922 - val_accuracy: 0.9687 - 12s/epoch - 2ms/step\n",
            "Epoch 548/800\n",
            "6930/6930 - 12s - loss: 0.0829 - accuracy: 0.9688 - val_loss: 0.0880 - val_accuracy: 0.9699 - 12s/epoch - 2ms/step\n",
            "Epoch 549/800\n",
            "6930/6930 - 11s - loss: 0.0828 - accuracy: 0.9688 - val_loss: 0.1258 - val_accuracy: 0.9561 - 11s/epoch - 2ms/step\n",
            "Epoch 550/800\n",
            "6930/6930 - 12s - loss: 0.0812 - accuracy: 0.9695 - val_loss: 0.0898 - val_accuracy: 0.9690 - 12s/epoch - 2ms/step\n",
            "Epoch 551/800\n",
            "6930/6930 - 12s - loss: 0.0823 - accuracy: 0.9693 - val_loss: 0.0898 - val_accuracy: 0.9694 - 12s/epoch - 2ms/step\n",
            "Epoch 552/800\n",
            "6930/6930 - 12s - loss: 0.0824 - accuracy: 0.9699 - val_loss: 0.0881 - val_accuracy: 0.9708 - 12s/epoch - 2ms/step\n",
            "Epoch 553/800\n",
            "6930/6930 - 11s - loss: 0.0831 - accuracy: 0.9689 - val_loss: 0.0988 - val_accuracy: 0.9643 - 11s/epoch - 2ms/step\n",
            "Epoch 554/800\n",
            "6930/6930 - 12s - loss: 0.0815 - accuracy: 0.9694 - val_loss: 0.0868 - val_accuracy: 0.9700 - 12s/epoch - 2ms/step\n",
            "Epoch 555/800\n",
            "6930/6930 - 12s - loss: 0.0814 - accuracy: 0.9696 - val_loss: 0.1035 - val_accuracy: 0.9638 - 12s/epoch - 2ms/step\n",
            "Epoch 556/800\n",
            "6930/6930 - 12s - loss: 0.0806 - accuracy: 0.9700 - val_loss: 0.0822 - val_accuracy: 0.9718 - 12s/epoch - 2ms/step\n",
            "Epoch 557/800\n",
            "6930/6930 - 12s - loss: 0.0822 - accuracy: 0.9684 - val_loss: 0.0823 - val_accuracy: 0.9722 - 12s/epoch - 2ms/step\n",
            "Epoch 558/800\n",
            "6930/6930 - 12s - loss: 0.0818 - accuracy: 0.9692 - val_loss: 0.0901 - val_accuracy: 0.9700 - 12s/epoch - 2ms/step\n",
            "Epoch 559/800\n",
            "6930/6930 - 12s - loss: 0.0813 - accuracy: 0.9698 - val_loss: 0.0862 - val_accuracy: 0.9718 - 12s/epoch - 2ms/step\n",
            "Epoch 560/800\n",
            "6930/6930 - 12s - loss: 0.0808 - accuracy: 0.9695 - val_loss: 0.0950 - val_accuracy: 0.9662 - 12s/epoch - 2ms/step\n",
            "Epoch 561/800\n",
            "6930/6930 - 12s - loss: 0.0813 - accuracy: 0.9699 - val_loss: 0.0902 - val_accuracy: 0.9700 - 12s/epoch - 2ms/step\n",
            "Epoch 562/800\n",
            "6930/6930 - 12s - loss: 0.0815 - accuracy: 0.9691 - val_loss: 0.0925 - val_accuracy: 0.9692 - 12s/epoch - 2ms/step\n",
            "Epoch 563/800\n",
            "6930/6930 - 12s - loss: 0.0813 - accuracy: 0.9694 - val_loss: 0.0966 - val_accuracy: 0.9653 - 12s/epoch - 2ms/step\n",
            "Epoch 564/800\n",
            "6930/6930 - 12s - loss: 0.0808 - accuracy: 0.9700 - val_loss: 0.0963 - val_accuracy: 0.9666 - 12s/epoch - 2ms/step\n",
            "Epoch 565/800\n",
            "6930/6930 - 12s - loss: 0.0806 - accuracy: 0.9694 - val_loss: 0.1180 - val_accuracy: 0.9574 - 12s/epoch - 2ms/step\n",
            "Epoch 566/800\n",
            "6930/6930 - 12s - loss: 0.0810 - accuracy: 0.9698 - val_loss: 0.1030 - val_accuracy: 0.9623 - 12s/epoch - 2ms/step\n",
            "Epoch 567/800\n",
            "6930/6930 - 12s - loss: 0.0823 - accuracy: 0.9693 - val_loss: 0.0945 - val_accuracy: 0.9677 - 12s/epoch - 2ms/step\n",
            "Epoch 568/800\n",
            "6930/6930 - 11s - loss: 0.0813 - accuracy: 0.9693 - val_loss: 0.0836 - val_accuracy: 0.9736 - 11s/epoch - 2ms/step\n",
            "Epoch 569/800\n",
            "6930/6930 - 12s - loss: 0.0811 - accuracy: 0.9695 - val_loss: 0.1006 - val_accuracy: 0.9648 - 12s/epoch - 2ms/step\n",
            "Epoch 570/800\n",
            "6930/6930 - 11s - loss: 0.0809 - accuracy: 0.9702 - val_loss: 0.0897 - val_accuracy: 0.9701 - 11s/epoch - 2ms/step\n",
            "Epoch 571/800\n",
            "6930/6930 - 12s - loss: 0.0802 - accuracy: 0.9700 - val_loss: 0.0851 - val_accuracy: 0.9713 - 12s/epoch - 2ms/step\n",
            "Epoch 572/800\n",
            "6930/6930 - 12s - loss: 0.0808 - accuracy: 0.9694 - val_loss: 0.0868 - val_accuracy: 0.9719 - 12s/epoch - 2ms/step\n",
            "Epoch 573/800\n",
            "6930/6930 - 12s - loss: 0.0811 - accuracy: 0.9691 - val_loss: 0.0851 - val_accuracy: 0.9713 - 12s/epoch - 2ms/step\n",
            "Epoch 574/800\n",
            "6930/6930 - 12s - loss: 0.0820 - accuracy: 0.9694 - val_loss: 0.0863 - val_accuracy: 0.9700 - 12s/epoch - 2ms/step\n",
            "Epoch 575/800\n",
            "6930/6930 - 12s - loss: 0.0801 - accuracy: 0.9699 - val_loss: 0.0847 - val_accuracy: 0.9730 - 12s/epoch - 2ms/step\n",
            "Epoch 576/800\n",
            "6930/6930 - 12s - loss: 0.0809 - accuracy: 0.9693 - val_loss: 0.0892 - val_accuracy: 0.9704 - 12s/epoch - 2ms/step\n",
            "Epoch 577/800\n",
            "6930/6930 - 12s - loss: 0.0809 - accuracy: 0.9698 - val_loss: 0.1391 - val_accuracy: 0.9490 - 12s/epoch - 2ms/step\n",
            "Epoch 578/800\n",
            "6930/6930 - 12s - loss: 0.0806 - accuracy: 0.9693 - val_loss: 0.0988 - val_accuracy: 0.9674 - 12s/epoch - 2ms/step\n",
            "Epoch 579/800\n",
            "6930/6930 - 12s - loss: 0.0810 - accuracy: 0.9693 - val_loss: 0.0842 - val_accuracy: 0.9710 - 12s/epoch - 2ms/step\n",
            "Epoch 580/800\n",
            "6930/6930 - 12s - loss: 0.0799 - accuracy: 0.9701 - val_loss: 0.1054 - val_accuracy: 0.9634 - 12s/epoch - 2ms/step\n",
            "Epoch 581/800\n",
            "6930/6930 - 12s - loss: 0.0799 - accuracy: 0.9706 - val_loss: 0.0837 - val_accuracy: 0.9719 - 12s/epoch - 2ms/step\n",
            "Epoch 582/800\n",
            "6930/6930 - 12s - loss: 0.0795 - accuracy: 0.9701 - val_loss: 0.0846 - val_accuracy: 0.9706 - 12s/epoch - 2ms/step\n",
            "Epoch 583/800\n",
            "6930/6930 - 12s - loss: 0.0807 - accuracy: 0.9700 - val_loss: 0.0873 - val_accuracy: 0.9705 - 12s/epoch - 2ms/step\n",
            "Epoch 584/800\n",
            "6930/6930 - 12s - loss: 0.0804 - accuracy: 0.9697 - val_loss: 0.0846 - val_accuracy: 0.9718 - 12s/epoch - 2ms/step\n",
            "Epoch 585/800\n",
            "6930/6930 - 12s - loss: 0.0798 - accuracy: 0.9702 - val_loss: 0.1199 - val_accuracy: 0.9605 - 12s/epoch - 2ms/step\n",
            "Epoch 586/800\n",
            "6930/6930 - 12s - loss: 0.0799 - accuracy: 0.9697 - val_loss: 0.0998 - val_accuracy: 0.9636 - 12s/epoch - 2ms/step\n",
            "Epoch 587/800\n",
            "6930/6930 - 12s - loss: 0.0807 - accuracy: 0.9698 - val_loss: 0.0901 - val_accuracy: 0.9703 - 12s/epoch - 2ms/step\n",
            "Epoch 588/800\n",
            "6930/6930 - 12s - loss: 0.0794 - accuracy: 0.9704 - val_loss: 0.0863 - val_accuracy: 0.9708 - 12s/epoch - 2ms/step\n",
            "Epoch 589/800\n",
            "6930/6930 - 11s - loss: 0.0802 - accuracy: 0.9700 - val_loss: 0.0866 - val_accuracy: 0.9718 - 11s/epoch - 2ms/step\n",
            "Epoch 590/800\n",
            "6930/6930 - 12s - loss: 0.0798 - accuracy: 0.9705 - val_loss: 0.0871 - val_accuracy: 0.9700 - 12s/epoch - 2ms/step\n",
            "Epoch 591/800\n",
            "6930/6930 - 12s - loss: 0.0799 - accuracy: 0.9698 - val_loss: 0.0925 - val_accuracy: 0.9699 - 12s/epoch - 2ms/step\n",
            "Epoch 592/800\n",
            "6930/6930 - 12s - loss: 0.0790 - accuracy: 0.9700 - val_loss: 0.1110 - val_accuracy: 0.9582 - 12s/epoch - 2ms/step\n",
            "Epoch 593/800\n",
            "6930/6930 - 12s - loss: 0.0792 - accuracy: 0.9706 - val_loss: 0.0961 - val_accuracy: 0.9660 - 12s/epoch - 2ms/step\n",
            "Epoch 594/800\n",
            "6930/6930 - 11s - loss: 0.0791 - accuracy: 0.9704 - val_loss: 0.0813 - val_accuracy: 0.9731 - 11s/epoch - 2ms/step\n",
            "Epoch 595/800\n",
            "6930/6930 - 12s - loss: 0.0801 - accuracy: 0.9696 - val_loss: 0.0946 - val_accuracy: 0.9668 - 12s/epoch - 2ms/step\n",
            "Epoch 596/800\n",
            "6930/6930 - 12s - loss: 0.0784 - accuracy: 0.9708 - val_loss: 0.0942 - val_accuracy: 0.9668 - 12s/epoch - 2ms/step\n",
            "Epoch 597/800\n",
            "6930/6930 - 12s - loss: 0.0800 - accuracy: 0.9699 - val_loss: 0.0870 - val_accuracy: 0.9721 - 12s/epoch - 2ms/step\n",
            "Epoch 598/800\n",
            "6930/6930 - 12s - loss: 0.0798 - accuracy: 0.9704 - val_loss: 0.0963 - val_accuracy: 0.9658 - 12s/epoch - 2ms/step\n",
            "Epoch 599/800\n",
            "6930/6930 - 12s - loss: 0.0795 - accuracy: 0.9697 - val_loss: 0.0916 - val_accuracy: 0.9704 - 12s/epoch - 2ms/step\n",
            "Epoch 600/800\n",
            "6930/6930 - 11s - loss: 0.0788 - accuracy: 0.9704 - val_loss: 0.1592 - val_accuracy: 0.9399 - 11s/epoch - 2ms/step\n",
            "Epoch 601/800\n",
            "6930/6930 - 12s - loss: 0.0795 - accuracy: 0.9701 - val_loss: 0.0843 - val_accuracy: 0.9721 - 12s/epoch - 2ms/step\n",
            "Epoch 602/800\n",
            "6930/6930 - 11s - loss: 0.0797 - accuracy: 0.9696 - val_loss: 0.0835 - val_accuracy: 0.9727 - 11s/epoch - 2ms/step\n",
            "Epoch 603/800\n",
            "6930/6930 - 12s - loss: 0.0796 - accuracy: 0.9701 - val_loss: 0.0855 - val_accuracy: 0.9712 - 12s/epoch - 2ms/step\n",
            "Epoch 604/800\n",
            "6930/6930 - 12s - loss: 0.0787 - accuracy: 0.9705 - val_loss: 0.0838 - val_accuracy: 0.9726 - 12s/epoch - 2ms/step\n",
            "Epoch 605/800\n",
            "6930/6930 - 12s - loss: 0.0778 - accuracy: 0.9710 - val_loss: 0.0882 - val_accuracy: 0.9706 - 12s/epoch - 2ms/step\n",
            "Epoch 606/800\n",
            "6930/6930 - 12s - loss: 0.0786 - accuracy: 0.9701 - val_loss: 0.0868 - val_accuracy: 0.9706 - 12s/epoch - 2ms/step\n",
            "Epoch 607/800\n",
            "6930/6930 - 12s - loss: 0.0780 - accuracy: 0.9712 - val_loss: 0.0933 - val_accuracy: 0.9662 - 12s/epoch - 2ms/step\n",
            "Epoch 608/800\n",
            "6930/6930 - 12s - loss: 0.0795 - accuracy: 0.9700 - val_loss: 0.0881 - val_accuracy: 0.9706 - 12s/epoch - 2ms/step\n",
            "Epoch 609/800\n",
            "6930/6930 - 12s - loss: 0.0798 - accuracy: 0.9701 - val_loss: 0.0822 - val_accuracy: 0.9714 - 12s/epoch - 2ms/step\n",
            "Epoch 610/800\n",
            "6930/6930 - 12s - loss: 0.0784 - accuracy: 0.9703 - val_loss: 0.1110 - val_accuracy: 0.9608 - 12s/epoch - 2ms/step\n",
            "Epoch 611/800\n",
            "6930/6930 - 12s - loss: 0.0794 - accuracy: 0.9703 - val_loss: 0.1219 - val_accuracy: 0.9545 - 12s/epoch - 2ms/step\n",
            "Epoch 612/800\n",
            "6930/6930 - 12s - loss: 0.0788 - accuracy: 0.9701 - val_loss: 0.0850 - val_accuracy: 0.9710 - 12s/epoch - 2ms/step\n",
            "Epoch 613/800\n",
            "6930/6930 - 12s - loss: 0.0786 - accuracy: 0.9708 - val_loss: 0.0844 - val_accuracy: 0.9722 - 12s/epoch - 2ms/step\n",
            "Epoch 614/800\n",
            "6930/6930 - 12s - loss: 0.0787 - accuracy: 0.9706 - val_loss: 0.0860 - val_accuracy: 0.9695 - 12s/epoch - 2ms/step\n",
            "Epoch 615/800\n",
            "6930/6930 - 12s - loss: 0.0786 - accuracy: 0.9702 - val_loss: 0.1004 - val_accuracy: 0.9671 - 12s/epoch - 2ms/step\n",
            "Epoch 616/800\n",
            "6930/6930 - 12s - loss: 0.0789 - accuracy: 0.9703 - val_loss: 0.1079 - val_accuracy: 0.9614 - 12s/epoch - 2ms/step\n",
            "Epoch 617/800\n",
            "6930/6930 - 12s - loss: 0.0784 - accuracy: 0.9702 - val_loss: 0.0921 - val_accuracy: 0.9699 - 12s/epoch - 2ms/step\n",
            "Epoch 618/800\n",
            "6930/6930 - 12s - loss: 0.0783 - accuracy: 0.9712 - val_loss: 0.0912 - val_accuracy: 0.9687 - 12s/epoch - 2ms/step\n",
            "Epoch 619/800\n",
            "6930/6930 - 12s - loss: 0.0792 - accuracy: 0.9697 - val_loss: 0.0882 - val_accuracy: 0.9688 - 12s/epoch - 2ms/step\n",
            "Epoch 620/800\n",
            "6930/6930 - 12s - loss: 0.0780 - accuracy: 0.9708 - val_loss: 0.0876 - val_accuracy: 0.9721 - 12s/epoch - 2ms/step\n",
            "Epoch 621/800\n",
            "6930/6930 - 12s - loss: 0.0782 - accuracy: 0.9705 - val_loss: 0.0845 - val_accuracy: 0.9714 - 12s/epoch - 2ms/step\n",
            "Epoch 622/800\n",
            "6930/6930 - 12s - loss: 0.0778 - accuracy: 0.9708 - val_loss: 0.0835 - val_accuracy: 0.9729 - 12s/epoch - 2ms/step\n",
            "Epoch 623/800\n",
            "6930/6930 - 12s - loss: 0.0785 - accuracy: 0.9702 - val_loss: 0.1055 - val_accuracy: 0.9617 - 12s/epoch - 2ms/step\n",
            "Epoch 624/800\n",
            "6930/6930 - 12s - loss: 0.0777 - accuracy: 0.9712 - val_loss: 0.0892 - val_accuracy: 0.9712 - 12s/epoch - 2ms/step\n",
            "Epoch 625/800\n",
            "6930/6930 - 12s - loss: 0.0786 - accuracy: 0.9705 - val_loss: 0.0832 - val_accuracy: 0.9739 - 12s/epoch - 2ms/step\n",
            "Epoch 626/800\n",
            "6930/6930 - 12s - loss: 0.0775 - accuracy: 0.9708 - val_loss: 0.1075 - val_accuracy: 0.9648 - 12s/epoch - 2ms/step\n",
            "Epoch 627/800\n",
            "6930/6930 - 12s - loss: 0.0790 - accuracy: 0.9705 - val_loss: 0.0990 - val_accuracy: 0.9655 - 12s/epoch - 2ms/step\n",
            "Epoch 628/800\n",
            "6930/6930 - 11s - loss: 0.0787 - accuracy: 0.9704 - val_loss: 0.0860 - val_accuracy: 0.9723 - 11s/epoch - 2ms/step\n",
            "Epoch 629/800\n",
            "6930/6930 - 12s - loss: 0.0770 - accuracy: 0.9707 - val_loss: 0.1000 - val_accuracy: 0.9643 - 12s/epoch - 2ms/step\n",
            "Epoch 630/800\n",
            "6930/6930 - 12s - loss: 0.0776 - accuracy: 0.9706 - val_loss: 0.1031 - val_accuracy: 0.9645 - 12s/epoch - 2ms/step\n",
            "Epoch 631/800\n",
            "6930/6930 - 12s - loss: 0.0775 - accuracy: 0.9705 - val_loss: 0.0888 - val_accuracy: 0.9706 - 12s/epoch - 2ms/step\n",
            "Epoch 632/800\n",
            "6930/6930 - 12s - loss: 0.0776 - accuracy: 0.9700 - val_loss: 0.0818 - val_accuracy: 0.9744 - 12s/epoch - 2ms/step\n",
            "Epoch 633/800\n",
            "6930/6930 - 12s - loss: 0.0778 - accuracy: 0.9707 - val_loss: 0.0895 - val_accuracy: 0.9713 - 12s/epoch - 2ms/step\n",
            "Epoch 634/800\n",
            "6930/6930 - 12s - loss: 0.0767 - accuracy: 0.9709 - val_loss: 0.0858 - val_accuracy: 0.9706 - 12s/epoch - 2ms/step\n",
            "Epoch 635/800\n",
            "6930/6930 - 11s - loss: 0.0777 - accuracy: 0.9711 - val_loss: 0.0919 - val_accuracy: 0.9682 - 11s/epoch - 2ms/step\n",
            "Epoch 636/800\n",
            "6930/6930 - 12s - loss: 0.0778 - accuracy: 0.9708 - val_loss: 0.0882 - val_accuracy: 0.9697 - 12s/epoch - 2ms/step\n",
            "Epoch 637/800\n",
            "6930/6930 - 12s - loss: 0.0770 - accuracy: 0.9709 - val_loss: 0.1146 - val_accuracy: 0.9613 - 12s/epoch - 2ms/step\n",
            "Epoch 638/800\n",
            "6930/6930 - 12s - loss: 0.0783 - accuracy: 0.9706 - val_loss: 0.0897 - val_accuracy: 0.9708 - 12s/epoch - 2ms/step\n",
            "Epoch 639/800\n",
            "6930/6930 - 12s - loss: 0.0776 - accuracy: 0.9711 - val_loss: 0.0919 - val_accuracy: 0.9683 - 12s/epoch - 2ms/step\n",
            "Epoch 640/800\n",
            "6930/6930 - 12s - loss: 0.0778 - accuracy: 0.9706 - val_loss: 0.0924 - val_accuracy: 0.9709 - 12s/epoch - 2ms/step\n",
            "Epoch 641/800\n",
            "6930/6930 - 12s - loss: 0.0777 - accuracy: 0.9711 - val_loss: 0.0870 - val_accuracy: 0.9717 - 12s/epoch - 2ms/step\n",
            "Epoch 642/800\n",
            "6930/6930 - 12s - loss: 0.0764 - accuracy: 0.9714 - val_loss: 0.0884 - val_accuracy: 0.9721 - 12s/epoch - 2ms/step\n",
            "Epoch 643/800\n",
            "6930/6930 - 12s - loss: 0.0772 - accuracy: 0.9708 - val_loss: 0.0877 - val_accuracy: 0.9716 - 12s/epoch - 2ms/step\n",
            "Epoch 644/800\n",
            "6930/6930 - 12s - loss: 0.0772 - accuracy: 0.9707 - val_loss: 0.0877 - val_accuracy: 0.9682 - 12s/epoch - 2ms/step\n",
            "Epoch 645/800\n",
            "6930/6930 - 12s - loss: 0.0765 - accuracy: 0.9713 - val_loss: 0.1056 - val_accuracy: 0.9626 - 12s/epoch - 2ms/step\n",
            "Epoch 646/800\n",
            "6930/6930 - 12s - loss: 0.0758 - accuracy: 0.9717 - val_loss: 0.0943 - val_accuracy: 0.9677 - 12s/epoch - 2ms/step\n",
            "Epoch 647/800\n",
            "6930/6930 - 12s - loss: 0.0762 - accuracy: 0.9707 - val_loss: 0.0847 - val_accuracy: 0.9716 - 12s/epoch - 2ms/step\n",
            "Epoch 648/800\n",
            "6930/6930 - 12s - loss: 0.0770 - accuracy: 0.9705 - val_loss: 0.1155 - val_accuracy: 0.9584 - 12s/epoch - 2ms/step\n",
            "Epoch 649/800\n",
            "6930/6930 - 12s - loss: 0.0770 - accuracy: 0.9708 - val_loss: 0.0944 - val_accuracy: 0.9678 - 12s/epoch - 2ms/step\n",
            "Epoch 650/800\n",
            "6930/6930 - 12s - loss: 0.0760 - accuracy: 0.9713 - val_loss: 0.1109 - val_accuracy: 0.9608 - 12s/epoch - 2ms/step\n",
            "Epoch 651/800\n",
            "6930/6930 - 12s - loss: 0.0764 - accuracy: 0.9714 - val_loss: 0.0909 - val_accuracy: 0.9690 - 12s/epoch - 2ms/step\n",
            "Epoch 652/800\n",
            "6930/6930 - 11s - loss: 0.0766 - accuracy: 0.9713 - val_loss: 0.0995 - val_accuracy: 0.9642 - 11s/epoch - 2ms/step\n",
            "Epoch 653/800\n",
            "6930/6930 - 12s - loss: 0.0772 - accuracy: 0.9709 - val_loss: 0.1110 - val_accuracy: 0.9617 - 12s/epoch - 2ms/step\n",
            "Epoch 654/800\n",
            "6930/6930 - 12s - loss: 0.0760 - accuracy: 0.9714 - val_loss: 0.0865 - val_accuracy: 0.9712 - 12s/epoch - 2ms/step\n",
            "Epoch 655/800\n",
            "6930/6930 - 12s - loss: 0.0763 - accuracy: 0.9706 - val_loss: 0.0985 - val_accuracy: 0.9648 - 12s/epoch - 2ms/step\n",
            "Epoch 656/800\n",
            "6930/6930 - 12s - loss: 0.0773 - accuracy: 0.9706 - val_loss: 0.0937 - val_accuracy: 0.9665 - 12s/epoch - 2ms/step\n",
            "Epoch 657/800\n",
            "6930/6930 - 12s - loss: 0.0770 - accuracy: 0.9713 - val_loss: 0.0863 - val_accuracy: 0.9731 - 12s/epoch - 2ms/step\n",
            "Epoch 658/800\n",
            "6930/6930 - 12s - loss: 0.0766 - accuracy: 0.9715 - val_loss: 0.0913 - val_accuracy: 0.9697 - 12s/epoch - 2ms/step\n",
            "Epoch 659/800\n",
            "6930/6930 - 12s - loss: 0.0763 - accuracy: 0.9705 - val_loss: 0.0848 - val_accuracy: 0.9729 - 12s/epoch - 2ms/step\n",
            "Epoch 660/800\n",
            "6930/6930 - 12s - loss: 0.0764 - accuracy: 0.9716 - val_loss: 0.0843 - val_accuracy: 0.9708 - 12s/epoch - 2ms/step\n",
            "Epoch 661/800\n",
            "6930/6930 - 11s - loss: 0.0764 - accuracy: 0.9715 - val_loss: 0.1050 - val_accuracy: 0.9656 - 11s/epoch - 2ms/step\n",
            "Epoch 662/800\n",
            "6930/6930 - 12s - loss: 0.0771 - accuracy: 0.9706 - val_loss: 0.0940 - val_accuracy: 0.9679 - 12s/epoch - 2ms/step\n",
            "Epoch 663/800\n",
            "6930/6930 - 12s - loss: 0.0753 - accuracy: 0.9719 - val_loss: 0.0868 - val_accuracy: 0.9721 - 12s/epoch - 2ms/step\n",
            "Epoch 664/800\n",
            "6930/6930 - 12s - loss: 0.0757 - accuracy: 0.9715 - val_loss: 0.0967 - val_accuracy: 0.9688 - 12s/epoch - 2ms/step\n",
            "Epoch 665/800\n",
            "6930/6930 - 12s - loss: 0.0755 - accuracy: 0.9722 - val_loss: 0.0967 - val_accuracy: 0.9674 - 12s/epoch - 2ms/step\n",
            "Epoch 666/800\n",
            "6930/6930 - 12s - loss: 0.0761 - accuracy: 0.9712 - val_loss: 0.0900 - val_accuracy: 0.9704 - 12s/epoch - 2ms/step\n",
            "Epoch 667/800\n",
            "6930/6930 - 12s - loss: 0.0758 - accuracy: 0.9714 - val_loss: 0.0843 - val_accuracy: 0.9722 - 12s/epoch - 2ms/step\n",
            "Epoch 668/800\n",
            "6930/6930 - 12s - loss: 0.0762 - accuracy: 0.9715 - val_loss: 0.0968 - val_accuracy: 0.9674 - 12s/epoch - 2ms/step\n",
            "Epoch 669/800\n",
            "6930/6930 - 12s - loss: 0.0755 - accuracy: 0.9714 - val_loss: 0.0925 - val_accuracy: 0.9696 - 12s/epoch - 2ms/step\n",
            "Epoch 670/800\n",
            "6930/6930 - 12s - loss: 0.0757 - accuracy: 0.9714 - val_loss: 0.1144 - val_accuracy: 0.9605 - 12s/epoch - 2ms/step\n",
            "Epoch 671/800\n",
            "6930/6930 - 12s - loss: 0.0755 - accuracy: 0.9714 - val_loss: 0.0904 - val_accuracy: 0.9690 - 12s/epoch - 2ms/step\n",
            "Epoch 672/800\n",
            "6930/6930 - 12s - loss: 0.0755 - accuracy: 0.9715 - val_loss: 0.0870 - val_accuracy: 0.9721 - 12s/epoch - 2ms/step\n",
            "Epoch 673/800\n",
            "6930/6930 - 12s - loss: 0.0766 - accuracy: 0.9710 - val_loss: 0.0824 - val_accuracy: 0.9725 - 12s/epoch - 2ms/step\n",
            "Epoch 674/800\n",
            "6930/6930 - 12s - loss: 0.0752 - accuracy: 0.9718 - val_loss: 0.0974 - val_accuracy: 0.9678 - 12s/epoch - 2ms/step\n",
            "Epoch 675/800\n",
            "6930/6930 - 12s - loss: 0.0753 - accuracy: 0.9722 - val_loss: 0.0966 - val_accuracy: 0.9691 - 12s/epoch - 2ms/step\n",
            "Epoch 676/800\n",
            "6930/6930 - 12s - loss: 0.0747 - accuracy: 0.9722 - val_loss: 0.0837 - val_accuracy: 0.9716 - 12s/epoch - 2ms/step\n",
            "Epoch 677/800\n",
            "6930/6930 - 12s - loss: 0.0759 - accuracy: 0.9712 - val_loss: 0.0824 - val_accuracy: 0.9744 - 12s/epoch - 2ms/step\n",
            "Epoch 678/800\n",
            "6930/6930 - 12s - loss: 0.0761 - accuracy: 0.9710 - val_loss: 0.0923 - val_accuracy: 0.9700 - 12s/epoch - 2ms/step\n",
            "Epoch 679/800\n",
            "6930/6930 - 11s - loss: 0.0761 - accuracy: 0.9715 - val_loss: 0.0909 - val_accuracy: 0.9686 - 11s/epoch - 2ms/step\n",
            "Epoch 680/800\n",
            "6930/6930 - 12s - loss: 0.0759 - accuracy: 0.9713 - val_loss: 0.0885 - val_accuracy: 0.9700 - 12s/epoch - 2ms/step\n",
            "Epoch 681/800\n",
            "6930/6930 - 12s - loss: 0.0751 - accuracy: 0.9716 - val_loss: 0.0887 - val_accuracy: 0.9709 - 12s/epoch - 2ms/step\n",
            "Epoch 682/800\n",
            "6930/6930 - 12s - loss: 0.0749 - accuracy: 0.9716 - val_loss: 0.0821 - val_accuracy: 0.9716 - 12s/epoch - 2ms/step\n",
            "Epoch 683/800\n",
            "6930/6930 - 12s - loss: 0.0757 - accuracy: 0.9715 - val_loss: 0.0893 - val_accuracy: 0.9695 - 12s/epoch - 2ms/step\n",
            "Epoch 684/800\n",
            "6930/6930 - 12s - loss: 0.0752 - accuracy: 0.9709 - val_loss: 0.0842 - val_accuracy: 0.9714 - 12s/epoch - 2ms/step\n",
            "Epoch 685/800\n",
            "6930/6930 - 12s - loss: 0.0749 - accuracy: 0.9723 - val_loss: 0.0868 - val_accuracy: 0.9717 - 12s/epoch - 2ms/step\n",
            "Epoch 686/800\n",
            "6930/6930 - 12s - loss: 0.0758 - accuracy: 0.9715 - val_loss: 0.1169 - val_accuracy: 0.9605 - 12s/epoch - 2ms/step\n",
            "Epoch 687/800\n",
            "6930/6930 - 12s - loss: 0.0750 - accuracy: 0.9720 - val_loss: 0.1070 - val_accuracy: 0.9617 - 12s/epoch - 2ms/step\n",
            "Epoch 688/800\n",
            "6930/6930 - 12s - loss: 0.0756 - accuracy: 0.9719 - val_loss: 0.0824 - val_accuracy: 0.9734 - 12s/epoch - 2ms/step\n",
            "Epoch 689/800\n",
            "6930/6930 - 12s - loss: 0.0751 - accuracy: 0.9721 - val_loss: 0.0926 - val_accuracy: 0.9699 - 12s/epoch - 2ms/step\n",
            "Epoch 690/800\n",
            "6930/6930 - 12s - loss: 0.0749 - accuracy: 0.9718 - val_loss: 0.0831 - val_accuracy: 0.9725 - 12s/epoch - 2ms/step\n",
            "Epoch 691/800\n",
            "6930/6930 - 12s - loss: 0.0747 - accuracy: 0.9722 - val_loss: 0.1008 - val_accuracy: 0.9674 - 12s/epoch - 2ms/step\n",
            "Epoch 692/800\n",
            "6930/6930 - 12s - loss: 0.0749 - accuracy: 0.9714 - val_loss: 0.0908 - val_accuracy: 0.9706 - 12s/epoch - 2ms/step\n",
            "Epoch 693/800\n",
            "6930/6930 - 12s - loss: 0.0753 - accuracy: 0.9710 - val_loss: 0.1154 - val_accuracy: 0.9591 - 12s/epoch - 2ms/step\n",
            "Epoch 694/800\n",
            "6930/6930 - 12s - loss: 0.0754 - accuracy: 0.9718 - val_loss: 0.1433 - val_accuracy: 0.9479 - 12s/epoch - 2ms/step\n",
            "Epoch 695/800\n",
            "6930/6930 - 12s - loss: 0.0747 - accuracy: 0.9717 - val_loss: 0.1131 - val_accuracy: 0.9610 - 12s/epoch - 2ms/step\n",
            "Epoch 696/800\n",
            "6930/6930 - 12s - loss: 0.0754 - accuracy: 0.9711 - val_loss: 0.0884 - val_accuracy: 0.9700 - 12s/epoch - 2ms/step\n",
            "Epoch 697/800\n",
            "6930/6930 - 12s - loss: 0.0743 - accuracy: 0.9718 - val_loss: 0.0923 - val_accuracy: 0.9718 - 12s/epoch - 2ms/step\n",
            "Epoch 698/800\n",
            "6930/6930 - 12s - loss: 0.0743 - accuracy: 0.9718 - val_loss: 0.0928 - val_accuracy: 0.9697 - 12s/epoch - 2ms/step\n",
            "Epoch 699/800\n",
            "6930/6930 - 12s - loss: 0.0744 - accuracy: 0.9716 - val_loss: 0.1045 - val_accuracy: 0.9635 - 12s/epoch - 2ms/step\n",
            "Epoch 700/800\n",
            "6930/6930 - 12s - loss: 0.0746 - accuracy: 0.9720 - val_loss: 0.0992 - val_accuracy: 0.9684 - 12s/epoch - 2ms/step\n",
            "Epoch 701/800\n",
            "6930/6930 - 12s - loss: 0.0753 - accuracy: 0.9721 - val_loss: 0.0876 - val_accuracy: 0.9734 - 12s/epoch - 2ms/step\n",
            "Epoch 702/800\n",
            "6930/6930 - 12s - loss: 0.0755 - accuracy: 0.9714 - val_loss: 0.0930 - val_accuracy: 0.9713 - 12s/epoch - 2ms/step\n",
            "Epoch 703/800\n",
            "6930/6930 - 12s - loss: 0.0745 - accuracy: 0.9721 - val_loss: 0.0876 - val_accuracy: 0.9721 - 12s/epoch - 2ms/step\n",
            "Epoch 704/800\n",
            "6930/6930 - 12s - loss: 0.0748 - accuracy: 0.9718 - val_loss: 0.0886 - val_accuracy: 0.9706 - 12s/epoch - 2ms/step\n",
            "Epoch 705/800\n",
            "6930/6930 - 12s - loss: 0.0746 - accuracy: 0.9722 - val_loss: 0.0848 - val_accuracy: 0.9725 - 12s/epoch - 2ms/step\n",
            "Epoch 706/800\n",
            "6930/6930 - 12s - loss: 0.0744 - accuracy: 0.9720 - val_loss: 0.0871 - val_accuracy: 0.9705 - 12s/epoch - 2ms/step\n",
            "Epoch 707/800\n",
            "6930/6930 - 12s - loss: 0.0746 - accuracy: 0.9722 - val_loss: 0.0834 - val_accuracy: 0.9732 - 12s/epoch - 2ms/step\n",
            "Epoch 708/800\n",
            "6930/6930 - 12s - loss: 0.0743 - accuracy: 0.9724 - val_loss: 0.0934 - val_accuracy: 0.9678 - 12s/epoch - 2ms/step\n",
            "Epoch 709/800\n",
            "6930/6930 - 12s - loss: 0.0743 - accuracy: 0.9720 - val_loss: 0.0846 - val_accuracy: 0.9730 - 12s/epoch - 2ms/step\n",
            "Epoch 710/800\n",
            "6930/6930 - 12s - loss: 0.0734 - accuracy: 0.9725 - val_loss: 0.1038 - val_accuracy: 0.9617 - 12s/epoch - 2ms/step\n",
            "Epoch 711/800\n",
            "6930/6930 - 12s - loss: 0.0734 - accuracy: 0.9724 - val_loss: 0.0907 - val_accuracy: 0.9703 - 12s/epoch - 2ms/step\n",
            "Epoch 712/800\n",
            "6930/6930 - 12s - loss: 0.0742 - accuracy: 0.9724 - val_loss: 0.1152 - val_accuracy: 0.9608 - 12s/epoch - 2ms/step\n",
            "Epoch 713/800\n",
            "6930/6930 - 12s - loss: 0.0738 - accuracy: 0.9723 - val_loss: 0.0869 - val_accuracy: 0.9694 - 12s/epoch - 2ms/step\n",
            "Epoch 714/800\n",
            "6930/6930 - 12s - loss: 0.0740 - accuracy: 0.9720 - val_loss: 0.0933 - val_accuracy: 0.9673 - 12s/epoch - 2ms/step\n",
            "Epoch 715/800\n",
            "6930/6930 - 12s - loss: 0.0743 - accuracy: 0.9721 - val_loss: 0.0847 - val_accuracy: 0.9717 - 12s/epoch - 2ms/step\n",
            "Epoch 716/800\n",
            "6930/6930 - 12s - loss: 0.0739 - accuracy: 0.9722 - val_loss: 0.0856 - val_accuracy: 0.9719 - 12s/epoch - 2ms/step\n",
            "Epoch 717/800\n",
            "6930/6930 - 12s - loss: 0.0744 - accuracy: 0.9714 - val_loss: 0.0919 - val_accuracy: 0.9701 - 12s/epoch - 2ms/step\n",
            "Epoch 718/800\n",
            "6930/6930 - 12s - loss: 0.0749 - accuracy: 0.9720 - val_loss: 0.0948 - val_accuracy: 0.9669 - 12s/epoch - 2ms/step\n",
            "Epoch 719/800\n",
            "6930/6930 - 12s - loss: 0.0740 - accuracy: 0.9726 - val_loss: 0.1132 - val_accuracy: 0.9606 - 12s/epoch - 2ms/step\n",
            "Epoch 720/800\n",
            "6930/6930 - 12s - loss: 0.0741 - accuracy: 0.9718 - val_loss: 0.0841 - val_accuracy: 0.9738 - 12s/epoch - 2ms/step\n",
            "Epoch 721/800\n",
            "6930/6930 - 12s - loss: 0.0733 - accuracy: 0.9724 - val_loss: 0.0873 - val_accuracy: 0.9706 - 12s/epoch - 2ms/step\n",
            "Epoch 722/800\n",
            "6930/6930 - 12s - loss: 0.0736 - accuracy: 0.9728 - val_loss: 0.0823 - val_accuracy: 0.9731 - 12s/epoch - 2ms/step\n",
            "Epoch 723/800\n",
            "6930/6930 - 12s - loss: 0.0742 - accuracy: 0.9722 - val_loss: 0.0930 - val_accuracy: 0.9687 - 12s/epoch - 2ms/step\n",
            "Epoch 724/800\n",
            "6930/6930 - 12s - loss: 0.0739 - accuracy: 0.9722 - val_loss: 0.0802 - val_accuracy: 0.9731 - 12s/epoch - 2ms/step\n",
            "Epoch 725/800\n",
            "6930/6930 - 12s - loss: 0.0730 - accuracy: 0.9723 - val_loss: 0.0903 - val_accuracy: 0.9705 - 12s/epoch - 2ms/step\n",
            "Epoch 726/800\n",
            "6930/6930 - 12s - loss: 0.0737 - accuracy: 0.9723 - val_loss: 0.1174 - val_accuracy: 0.9568 - 12s/epoch - 2ms/step\n",
            "Epoch 727/800\n",
            "6930/6930 - 12s - loss: 0.0730 - accuracy: 0.9726 - val_loss: 0.0839 - val_accuracy: 0.9731 - 12s/epoch - 2ms/step\n",
            "Epoch 728/800\n",
            "6930/6930 - 12s - loss: 0.0732 - accuracy: 0.9729 - val_loss: 0.0852 - val_accuracy: 0.9722 - 12s/epoch - 2ms/step\n",
            "Epoch 729/800\n",
            "6930/6930 - 11s - loss: 0.0733 - accuracy: 0.9727 - val_loss: 0.0859 - val_accuracy: 0.9725 - 11s/epoch - 2ms/step\n",
            "Epoch 730/800\n",
            "6930/6930 - 12s - loss: 0.0734 - accuracy: 0.9732 - val_loss: 0.0886 - val_accuracy: 0.9725 - 12s/epoch - 2ms/step\n",
            "Epoch 731/800\n",
            "6930/6930 - 12s - loss: 0.0732 - accuracy: 0.9719 - val_loss: 0.0900 - val_accuracy: 0.9684 - 12s/epoch - 2ms/step\n",
            "Epoch 732/800\n",
            "6930/6930 - 12s - loss: 0.0735 - accuracy: 0.9724 - val_loss: 0.0839 - val_accuracy: 0.9749 - 12s/epoch - 2ms/step\n",
            "Epoch 733/800\n",
            "6930/6930 - 12s - loss: 0.0729 - accuracy: 0.9727 - val_loss: 0.0901 - val_accuracy: 0.9705 - 12s/epoch - 2ms/step\n",
            "Epoch 734/800\n",
            "6930/6930 - 12s - loss: 0.0737 - accuracy: 0.9716 - val_loss: 0.0869 - val_accuracy: 0.9712 - 12s/epoch - 2ms/step\n",
            "Epoch 735/800\n",
            "6930/6930 - 12s - loss: 0.0732 - accuracy: 0.9724 - val_loss: 0.0835 - val_accuracy: 0.9736 - 12s/epoch - 2ms/step\n",
            "Epoch 736/800\n",
            "6930/6930 - 12s - loss: 0.0734 - accuracy: 0.9726 - val_loss: 0.0845 - val_accuracy: 0.9723 - 12s/epoch - 2ms/step\n",
            "Epoch 737/800\n",
            "6930/6930 - 12s - loss: 0.0736 - accuracy: 0.9718 - val_loss: 0.0854 - val_accuracy: 0.9732 - 12s/epoch - 2ms/step\n",
            "Epoch 738/800\n",
            "6930/6930 - 12s - loss: 0.0737 - accuracy: 0.9722 - val_loss: 0.0990 - val_accuracy: 0.9665 - 12s/epoch - 2ms/step\n",
            "Epoch 739/800\n",
            "6930/6930 - 12s - loss: 0.0736 - accuracy: 0.9719 - val_loss: 0.0931 - val_accuracy: 0.9703 - 12s/epoch - 2ms/step\n",
            "Epoch 740/800\n",
            "6930/6930 - 12s - loss: 0.0723 - accuracy: 0.9725 - val_loss: 0.0839 - val_accuracy: 0.9730 - 12s/epoch - 2ms/step\n",
            "Epoch 741/800\n",
            "6930/6930 - 12s - loss: 0.0731 - accuracy: 0.9724 - val_loss: 0.0860 - val_accuracy: 0.9705 - 12s/epoch - 2ms/step\n",
            "Epoch 742/800\n",
            "6930/6930 - 12s - loss: 0.0729 - accuracy: 0.9720 - val_loss: 0.0921 - val_accuracy: 0.9703 - 12s/epoch - 2ms/step\n",
            "Epoch 743/800\n",
            "6930/6930 - 12s - loss: 0.0732 - accuracy: 0.9728 - val_loss: 0.0959 - val_accuracy: 0.9688 - 12s/epoch - 2ms/step\n",
            "Epoch 744/800\n",
            "6930/6930 - 12s - loss: 0.0739 - accuracy: 0.9728 - val_loss: 0.1049 - val_accuracy: 0.9635 - 12s/epoch - 2ms/step\n",
            "Epoch 745/800\n",
            "6930/6930 - 12s - loss: 0.0723 - accuracy: 0.9732 - val_loss: 0.0872 - val_accuracy: 0.9719 - 12s/epoch - 2ms/step\n",
            "Epoch 746/800\n",
            "6930/6930 - 12s - loss: 0.0731 - accuracy: 0.9726 - val_loss: 0.0876 - val_accuracy: 0.9714 - 12s/epoch - 2ms/step\n",
            "Epoch 747/800\n",
            "6930/6930 - 12s - loss: 0.0727 - accuracy: 0.9729 - val_loss: 0.1116 - val_accuracy: 0.9622 - 12s/epoch - 2ms/step\n",
            "Epoch 748/800\n",
            "6930/6930 - 12s - loss: 0.0738 - accuracy: 0.9727 - val_loss: 0.0939 - val_accuracy: 0.9713 - 12s/epoch - 2ms/step\n",
            "Epoch 749/800\n",
            "6930/6930 - 12s - loss: 0.0726 - accuracy: 0.9726 - val_loss: 0.0885 - val_accuracy: 0.9706 - 12s/epoch - 2ms/step\n",
            "Epoch 750/800\n",
            "6930/6930 - 12s - loss: 0.0730 - accuracy: 0.9723 - val_loss: 0.0902 - val_accuracy: 0.9690 - 12s/epoch - 2ms/step\n",
            "Epoch 751/800\n",
            "6930/6930 - 12s - loss: 0.0724 - accuracy: 0.9727 - val_loss: 0.0955 - val_accuracy: 0.9686 - 12s/epoch - 2ms/step\n",
            "Epoch 752/800\n",
            "6930/6930 - 12s - loss: 0.0730 - accuracy: 0.9727 - val_loss: 0.0919 - val_accuracy: 0.9692 - 12s/epoch - 2ms/step\n",
            "Epoch 753/800\n",
            "6930/6930 - 12s - loss: 0.0730 - accuracy: 0.9727 - val_loss: 0.0823 - val_accuracy: 0.9723 - 12s/epoch - 2ms/step\n",
            "Epoch 754/800\n",
            "6930/6930 - 12s - loss: 0.0732 - accuracy: 0.9723 - val_loss: 0.0907 - val_accuracy: 0.9717 - 12s/epoch - 2ms/step\n",
            "Epoch 755/800\n",
            "6930/6930 - 12s - loss: 0.0719 - accuracy: 0.9733 - val_loss: 0.0831 - val_accuracy: 0.9732 - 12s/epoch - 2ms/step\n",
            "Epoch 756/800\n",
            "6930/6930 - 12s - loss: 0.0720 - accuracy: 0.9732 - val_loss: 0.0874 - val_accuracy: 0.9710 - 12s/epoch - 2ms/step\n",
            "Epoch 757/800\n",
            "6930/6930 - 12s - loss: 0.0738 - accuracy: 0.9718 - val_loss: 0.0978 - val_accuracy: 0.9692 - 12s/epoch - 2ms/step\n",
            "Epoch 758/800\n",
            "6930/6930 - 12s - loss: 0.0725 - accuracy: 0.9728 - val_loss: 0.1125 - val_accuracy: 0.9614 - 12s/epoch - 2ms/step\n",
            "Epoch 759/800\n",
            "6930/6930 - 12s - loss: 0.0716 - accuracy: 0.9728 - val_loss: 0.0844 - val_accuracy: 0.9722 - 12s/epoch - 2ms/step\n",
            "Epoch 760/800\n",
            "6930/6930 - 12s - loss: 0.0721 - accuracy: 0.9728 - val_loss: 0.0854 - val_accuracy: 0.9731 - 12s/epoch - 2ms/step\n",
            "Epoch 761/800\n",
            "6930/6930 - 12s - loss: 0.0718 - accuracy: 0.9727 - val_loss: 0.0829 - val_accuracy: 0.9725 - 12s/epoch - 2ms/step\n",
            "Epoch 762/800\n",
            "6930/6930 - 12s - loss: 0.0726 - accuracy: 0.9728 - val_loss: 0.0926 - val_accuracy: 0.9684 - 12s/epoch - 2ms/step\n",
            "Epoch 763/800\n",
            "6930/6930 - 12s - loss: 0.0725 - accuracy: 0.9728 - val_loss: 0.0857 - val_accuracy: 0.9710 - 12s/epoch - 2ms/step\n",
            "Epoch 764/800\n",
            "6930/6930 - 12s - loss: 0.0723 - accuracy: 0.9731 - val_loss: 0.0962 - val_accuracy: 0.9684 - 12s/epoch - 2ms/step\n",
            "Epoch 765/800\n",
            "6930/6930 - 12s - loss: 0.0728 - accuracy: 0.9724 - val_loss: 0.0974 - val_accuracy: 0.9681 - 12s/epoch - 2ms/step\n",
            "Epoch 766/800\n",
            "6930/6930 - 12s - loss: 0.0733 - accuracy: 0.9727 - val_loss: 0.0842 - val_accuracy: 0.9723 - 12s/epoch - 2ms/step\n",
            "Epoch 767/800\n",
            "6930/6930 - 12s - loss: 0.0720 - accuracy: 0.9727 - val_loss: 0.0906 - val_accuracy: 0.9687 - 12s/epoch - 2ms/step\n",
            "Epoch 768/800\n",
            "6930/6930 - 12s - loss: 0.0726 - accuracy: 0.9728 - val_loss: 0.0875 - val_accuracy: 0.9714 - 12s/epoch - 2ms/step\n",
            "Epoch 769/800\n",
            "6930/6930 - 12s - loss: 0.0722 - accuracy: 0.9728 - val_loss: 0.0804 - val_accuracy: 0.9730 - 12s/epoch - 2ms/step\n",
            "Epoch 770/800\n",
            "6930/6930 - 12s - loss: 0.0719 - accuracy: 0.9732 - val_loss: 0.0847 - val_accuracy: 0.9730 - 12s/epoch - 2ms/step\n",
            "Epoch 771/800\n",
            "6930/6930 - 12s - loss: 0.0717 - accuracy: 0.9735 - val_loss: 0.0853 - val_accuracy: 0.9729 - 12s/epoch - 2ms/step\n",
            "Epoch 772/800\n",
            "6930/6930 - 12s - loss: 0.0718 - accuracy: 0.9732 - val_loss: 0.1295 - val_accuracy: 0.9551 - 12s/epoch - 2ms/step\n",
            "Epoch 773/800\n",
            "6930/6930 - 12s - loss: 0.0709 - accuracy: 0.9731 - val_loss: 0.0881 - val_accuracy: 0.9701 - 12s/epoch - 2ms/step\n",
            "Epoch 774/800\n",
            "6930/6930 - 12s - loss: 0.0714 - accuracy: 0.9731 - val_loss: 0.0950 - val_accuracy: 0.9712 - 12s/epoch - 2ms/step\n",
            "Epoch 775/800\n",
            "6930/6930 - 12s - loss: 0.0723 - accuracy: 0.9728 - val_loss: 0.0824 - val_accuracy: 0.9725 - 12s/epoch - 2ms/step\n",
            "Epoch 776/800\n",
            "6930/6930 - 12s - loss: 0.0719 - accuracy: 0.9729 - val_loss: 0.0865 - val_accuracy: 0.9732 - 12s/epoch - 2ms/step\n",
            "Epoch 777/800\n",
            "6930/6930 - 12s - loss: 0.0713 - accuracy: 0.9737 - val_loss: 0.0851 - val_accuracy: 0.9705 - 12s/epoch - 2ms/step\n",
            "Epoch 778/800\n",
            "6930/6930 - 12s - loss: 0.0722 - accuracy: 0.9733 - val_loss: 0.0916 - val_accuracy: 0.9697 - 12s/epoch - 2ms/step\n",
            "Epoch 779/800\n",
            "6930/6930 - 12s - loss: 0.0725 - accuracy: 0.9726 - val_loss: 0.0802 - val_accuracy: 0.9747 - 12s/epoch - 2ms/step\n",
            "Epoch 780/800\n",
            "6930/6930 - 12s - loss: 0.0714 - accuracy: 0.9727 - val_loss: 0.0993 - val_accuracy: 0.9677 - 12s/epoch - 2ms/step\n",
            "Epoch 781/800\n",
            "6930/6930 - 12s - loss: 0.0728 - accuracy: 0.9726 - val_loss: 0.0955 - val_accuracy: 0.9675 - 12s/epoch - 2ms/step\n",
            "Epoch 782/800\n",
            "6930/6930 - 12s - loss: 0.0721 - accuracy: 0.9729 - val_loss: 0.1113 - val_accuracy: 0.9634 - 12s/epoch - 2ms/step\n",
            "Epoch 783/800\n",
            "6930/6930 - 12s - loss: 0.0723 - accuracy: 0.9723 - val_loss: 0.0868 - val_accuracy: 0.9709 - 12s/epoch - 2ms/step\n",
            "Epoch 784/800\n",
            "6930/6930 - 12s - loss: 0.0725 - accuracy: 0.9721 - val_loss: 0.0840 - val_accuracy: 0.9742 - 12s/epoch - 2ms/step\n",
            "Epoch 785/800\n",
            "6930/6930 - 12s - loss: 0.0711 - accuracy: 0.9730 - val_loss: 0.0804 - val_accuracy: 0.9736 - 12s/epoch - 2ms/step\n",
            "Epoch 786/800\n",
            "6930/6930 - 12s - loss: 0.0707 - accuracy: 0.9734 - val_loss: 0.1079 - val_accuracy: 0.9673 - 12s/epoch - 2ms/step\n",
            "Epoch 787/800\n",
            "6930/6930 - 12s - loss: 0.0719 - accuracy: 0.9726 - val_loss: 0.1133 - val_accuracy: 0.9616 - 12s/epoch - 2ms/step\n",
            "Epoch 788/800\n",
            "6930/6930 - 12s - loss: 0.0719 - accuracy: 0.9726 - val_loss: 0.0841 - val_accuracy: 0.9721 - 12s/epoch - 2ms/step\n",
            "Epoch 789/800\n",
            "6930/6930 - 12s - loss: 0.0709 - accuracy: 0.9730 - val_loss: 0.0854 - val_accuracy: 0.9705 - 12s/epoch - 2ms/step\n",
            "Epoch 790/800\n",
            "6930/6930 - 12s - loss: 0.0712 - accuracy: 0.9732 - val_loss: 0.0851 - val_accuracy: 0.9716 - 12s/epoch - 2ms/step\n",
            "Epoch 791/800\n",
            "6930/6930 - 12s - loss: 0.0718 - accuracy: 0.9731 - val_loss: 0.0922 - val_accuracy: 0.9697 - 12s/epoch - 2ms/step\n",
            "Epoch 792/800\n",
            "6930/6930 - 12s - loss: 0.0713 - accuracy: 0.9728 - val_loss: 0.1356 - val_accuracy: 0.9579 - 12s/epoch - 2ms/step\n",
            "Epoch 793/800\n",
            "6930/6930 - 12s - loss: 0.0718 - accuracy: 0.9722 - val_loss: 0.0857 - val_accuracy: 0.9712 - 12s/epoch - 2ms/step\n",
            "Epoch 794/800\n",
            "6930/6930 - 12s - loss: 0.0714 - accuracy: 0.9728 - val_loss: 0.0973 - val_accuracy: 0.9682 - 12s/epoch - 2ms/step\n",
            "Epoch 795/800\n",
            "6930/6930 - 12s - loss: 0.0712 - accuracy: 0.9737 - val_loss: 0.1019 - val_accuracy: 0.9656 - 12s/epoch - 2ms/step\n",
            "Epoch 796/800\n",
            "6930/6930 - 12s - loss: 0.0714 - accuracy: 0.9729 - val_loss: 0.0855 - val_accuracy: 0.9725 - 12s/epoch - 2ms/step\n",
            "Epoch 797/800\n",
            "6930/6930 - 12s - loss: 0.0719 - accuracy: 0.9733 - val_loss: 0.0794 - val_accuracy: 0.9721 - 12s/epoch - 2ms/step\n",
            "Epoch 798/800\n",
            "6930/6930 - 12s - loss: 0.0707 - accuracy: 0.9735 - val_loss: 0.0866 - val_accuracy: 0.9731 - 12s/epoch - 2ms/step\n",
            "Epoch 799/800\n",
            "6930/6930 - 12s - loss: 0.0708 - accuracy: 0.9738 - val_loss: 0.0891 - val_accuracy: 0.9697 - 12s/epoch - 2ms/step\n",
            "Epoch 800/800\n",
            "6930/6930 - 12s - loss: 0.0708 - accuracy: 0.9737 - val_loss: 0.0974 - val_accuracy: 0.9701 - 12s/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5b803803d0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KuqUldOsWhK",
        "outputId": "a8a7c0f3-8149-41bd-8ceb-1d9c102b1d86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "3850/3850 - 7s - loss: 1.6391 - accuracy: 0.4344 - val_loss: 0.4234 - val_accuracy: 1.0000 - 7s/epoch - 2ms/step\n",
            "Epoch 2/500\n",
            "3850/3850 - 6s - loss: 1.1015 - accuracy: 0.5578 - val_loss: 0.3966 - val_accuracy: 0.8261 - 6s/epoch - 1ms/step\n",
            "Epoch 3/500\n",
            "3850/3850 - 6s - loss: 0.8820 - accuracy: 0.6299 - val_loss: 0.4518 - val_accuracy: 0.8090 - 6s/epoch - 2ms/step\n",
            "Epoch 4/500\n",
            "3850/3850 - 6s - loss: 0.7355 - accuracy: 0.7040 - val_loss: 0.4633 - val_accuracy: 0.7899 - 6s/epoch - 1ms/step\n",
            "Epoch 5/500\n",
            "3850/3850 - 6s - loss: 0.6641 - accuracy: 0.7154 - val_loss: 0.3842 - val_accuracy: 0.8186 - 6s/epoch - 1ms/step\n",
            "Epoch 6/500\n",
            "3850/3850 - 6s - loss: 0.6274 - accuracy: 0.7229 - val_loss: 0.4612 - val_accuracy: 0.7433 - 6s/epoch - 2ms/step\n",
            "Epoch 7/500\n",
            "3850/3850 - 6s - loss: 0.6049 - accuracy: 0.7272 - val_loss: 0.4709 - val_accuracy: 0.7506 - 6s/epoch - 1ms/step\n",
            "Epoch 8/500\n",
            "3850/3850 - 6s - loss: 0.5899 - accuracy: 0.7311 - val_loss: 0.4037 - val_accuracy: 0.7571 - 6s/epoch - 1ms/step\n",
            "Epoch 9/500\n",
            "3850/3850 - 6s - loss: 0.5783 - accuracy: 0.7339 - val_loss: 0.3738 - val_accuracy: 0.7658 - 6s/epoch - 2ms/step\n",
            "Epoch 10/500\n",
            "3850/3850 - 6s - loss: 0.5673 - accuracy: 0.7362 - val_loss: 0.4190 - val_accuracy: 0.7999 - 6s/epoch - 2ms/step\n",
            "Epoch 11/500\n",
            "3850/3850 - 6s - loss: 0.5582 - accuracy: 0.7413 - val_loss: 0.3358 - val_accuracy: 0.8165 - 6s/epoch - 2ms/step\n",
            "Epoch 12/500\n",
            "3850/3850 - 6s - loss: 0.5488 - accuracy: 0.7450 - val_loss: 0.3861 - val_accuracy: 0.8347 - 6s/epoch - 1ms/step\n",
            "Epoch 13/500\n",
            "3850/3850 - 6s - loss: 0.5399 - accuracy: 0.7518 - val_loss: 0.3470 - val_accuracy: 0.8462 - 6s/epoch - 2ms/step\n",
            "Epoch 14/500\n",
            "3850/3850 - 6s - loss: 0.5313 - accuracy: 0.7564 - val_loss: 0.4088 - val_accuracy: 0.8083 - 6s/epoch - 2ms/step\n",
            "Epoch 15/500\n",
            "3850/3850 - 6s - loss: 0.5237 - accuracy: 0.7586 - val_loss: 0.2970 - val_accuracy: 0.9418 - 6s/epoch - 1ms/step\n",
            "Epoch 16/500\n",
            "3850/3850 - 6s - loss: 0.5178 - accuracy: 0.7629 - val_loss: 0.3646 - val_accuracy: 0.8396 - 6s/epoch - 1ms/step\n",
            "Epoch 17/500\n",
            "3850/3850 - 6s - loss: 0.5120 - accuracy: 0.7667 - val_loss: 0.2935 - val_accuracy: 0.8971 - 6s/epoch - 1ms/step\n",
            "Epoch 18/500\n",
            "3850/3850 - 6s - loss: 0.5068 - accuracy: 0.7709 - val_loss: 0.2964 - val_accuracy: 0.9268 - 6s/epoch - 2ms/step\n",
            "Epoch 19/500\n",
            "3850/3850 - 6s - loss: 0.5013 - accuracy: 0.7732 - val_loss: 0.3029 - val_accuracy: 0.8747 - 6s/epoch - 1ms/step\n",
            "Epoch 20/500\n",
            "3850/3850 - 6s - loss: 0.4980 - accuracy: 0.7748 - val_loss: 0.2936 - val_accuracy: 0.9091 - 6s/epoch - 1ms/step\n",
            "Epoch 21/500\n",
            "3850/3850 - 6s - loss: 0.4923 - accuracy: 0.7765 - val_loss: 0.3027 - val_accuracy: 0.9418 - 6s/epoch - 1ms/step\n",
            "Epoch 22/500\n",
            "3850/3850 - 6s - loss: 0.4880 - accuracy: 0.7791 - val_loss: 0.3182 - val_accuracy: 0.8724 - 6s/epoch - 2ms/step\n",
            "Epoch 23/500\n",
            "3850/3850 - 6s - loss: 0.4837 - accuracy: 0.7819 - val_loss: 0.3400 - val_accuracy: 0.9046 - 6s/epoch - 2ms/step\n",
            "Epoch 24/500\n",
            "3850/3850 - 6s - loss: 0.4793 - accuracy: 0.7841 - val_loss: 0.3144 - val_accuracy: 0.8922 - 6s/epoch - 1ms/step\n",
            "Epoch 25/500\n",
            "3850/3850 - 7s - loss: 0.4749 - accuracy: 0.7862 - val_loss: 0.2925 - val_accuracy: 0.9046 - 7s/epoch - 2ms/step\n",
            "Epoch 26/500\n",
            "3850/3850 - 6s - loss: 0.4711 - accuracy: 0.7870 - val_loss: 0.2872 - val_accuracy: 0.9294 - 6s/epoch - 2ms/step\n",
            "Epoch 27/500\n",
            "3850/3850 - 6s - loss: 0.4672 - accuracy: 0.7894 - val_loss: 0.3278 - val_accuracy: 0.8871 - 6s/epoch - 1ms/step\n",
            "Epoch 28/500\n",
            "3850/3850 - 6s - loss: 0.4633 - accuracy: 0.7888 - val_loss: 0.2343 - val_accuracy: 0.9481 - 6s/epoch - 1ms/step\n",
            "Epoch 29/500\n",
            "3850/3850 - 6s - loss: 0.4585 - accuracy: 0.7925 - val_loss: 0.2788 - val_accuracy: 0.9315 - 6s/epoch - 2ms/step\n",
            "Epoch 30/500\n",
            "3850/3850 - 6s - loss: 0.4559 - accuracy: 0.7942 - val_loss: 0.2064 - val_accuracy: 0.9659 - 6s/epoch - 2ms/step\n",
            "Epoch 31/500\n",
            "3850/3850 - 6s - loss: 0.4517 - accuracy: 0.7940 - val_loss: 0.2481 - val_accuracy: 0.9490 - 6s/epoch - 2ms/step\n",
            "Epoch 32/500\n",
            "3850/3850 - 6s - loss: 0.4485 - accuracy: 0.7952 - val_loss: 0.2678 - val_accuracy: 0.9395 - 6s/epoch - 2ms/step\n",
            "Epoch 33/500\n",
            "3850/3850 - 6s - loss: 0.4448 - accuracy: 0.7959 - val_loss: 0.1896 - val_accuracy: 0.9715 - 6s/epoch - 1ms/step\n",
            "Epoch 34/500\n",
            "3850/3850 - 6s - loss: 0.4427 - accuracy: 0.7957 - val_loss: 0.2739 - val_accuracy: 0.9360 - 6s/epoch - 1ms/step\n",
            "Epoch 35/500\n",
            "3850/3850 - 6s - loss: 0.4380 - accuracy: 0.7984 - val_loss: 0.1748 - val_accuracy: 0.9621 - 6s/epoch - 1ms/step\n",
            "Epoch 36/500\n",
            "3850/3850 - 6s - loss: 0.4351 - accuracy: 0.7993 - val_loss: 0.2532 - val_accuracy: 0.9343 - 6s/epoch - 1ms/step\n",
            "Epoch 37/500\n",
            "3850/3850 - 6s - loss: 0.4319 - accuracy: 0.8013 - val_loss: 0.2199 - val_accuracy: 0.9556 - 6s/epoch - 1ms/step\n",
            "Epoch 38/500\n",
            "3850/3850 - 6s - loss: 0.4275 - accuracy: 0.8028 - val_loss: 0.2269 - val_accuracy: 0.9596 - 6s/epoch - 2ms/step\n",
            "Epoch 39/500\n",
            "3850/3850 - 6s - loss: 0.4249 - accuracy: 0.8028 - val_loss: 0.2606 - val_accuracy: 0.9437 - 6s/epoch - 2ms/step\n",
            "Epoch 40/500\n",
            "3850/3850 - 6s - loss: 0.4213 - accuracy: 0.8043 - val_loss: 0.3486 - val_accuracy: 0.8801 - 6s/epoch - 2ms/step\n",
            "Epoch 41/500\n",
            "3850/3850 - 6s - loss: 0.4190 - accuracy: 0.8045 - val_loss: 0.2581 - val_accuracy: 0.9324 - 6s/epoch - 1ms/step\n",
            "Epoch 42/500\n",
            "3850/3850 - 6s - loss: 0.4147 - accuracy: 0.8084 - val_loss: 0.3223 - val_accuracy: 0.9042 - 6s/epoch - 1ms/step\n",
            "Epoch 43/500\n",
            "3850/3850 - 6s - loss: 0.4120 - accuracy: 0.8092 - val_loss: 0.2640 - val_accuracy: 0.9350 - 6s/epoch - 1ms/step\n",
            "Epoch 44/500\n",
            "3850/3850 - 6s - loss: 0.4094 - accuracy: 0.8102 - val_loss: 0.3465 - val_accuracy: 0.9086 - 6s/epoch - 2ms/step\n",
            "Epoch 45/500\n",
            "3850/3850 - 6s - loss: 0.4055 - accuracy: 0.8103 - val_loss: 0.2290 - val_accuracy: 0.9460 - 6s/epoch - 1ms/step\n",
            "Epoch 46/500\n",
            "3850/3850 - 6s - loss: 0.4017 - accuracy: 0.8127 - val_loss: 0.2210 - val_accuracy: 0.9472 - 6s/epoch - 1ms/step\n",
            "Epoch 47/500\n",
            "3850/3850 - 6s - loss: 0.3999 - accuracy: 0.8144 - val_loss: 0.2721 - val_accuracy: 0.9320 - 6s/epoch - 2ms/step\n",
            "Epoch 48/500\n",
            "3850/3850 - 6s - loss: 0.3962 - accuracy: 0.8170 - val_loss: 0.2646 - val_accuracy: 0.9310 - 6s/epoch - 2ms/step\n",
            "Epoch 49/500\n",
            "3850/3850 - 6s - loss: 0.3928 - accuracy: 0.8172 - val_loss: 0.2871 - val_accuracy: 0.9240 - 6s/epoch - 1ms/step\n",
            "Epoch 50/500\n",
            "3850/3850 - 6s - loss: 0.3901 - accuracy: 0.8189 - val_loss: 0.1454 - val_accuracy: 0.9673 - 6s/epoch - 2ms/step\n",
            "Epoch 51/500\n",
            "3850/3850 - 6s - loss: 0.3867 - accuracy: 0.8206 - val_loss: 0.3071 - val_accuracy: 0.9191 - 6s/epoch - 2ms/step\n",
            "Epoch 52/500\n",
            "3850/3850 - 6s - loss: 0.3828 - accuracy: 0.8248 - val_loss: 0.2796 - val_accuracy: 0.9336 - 6s/epoch - 2ms/step\n",
            "Epoch 53/500\n",
            "3850/3850 - 6s - loss: 0.3796 - accuracy: 0.8267 - val_loss: 0.3151 - val_accuracy: 0.9158 - 6s/epoch - 2ms/step\n",
            "Epoch 54/500\n",
            "3850/3850 - 6s - loss: 0.3763 - accuracy: 0.8294 - val_loss: 0.2481 - val_accuracy: 0.9406 - 6s/epoch - 2ms/step\n",
            "Epoch 55/500\n",
            "3850/3850 - 6s - loss: 0.3718 - accuracy: 0.8318 - val_loss: 0.4071 - val_accuracy: 0.8710 - 6s/epoch - 2ms/step\n",
            "Epoch 56/500\n",
            "3850/3850 - 6s - loss: 0.3673 - accuracy: 0.8359 - val_loss: 0.3170 - val_accuracy: 0.9161 - 6s/epoch - 1ms/step\n",
            "Epoch 57/500\n",
            "3850/3850 - 6s - loss: 0.3621 - accuracy: 0.8390 - val_loss: 0.3111 - val_accuracy: 0.9128 - 6s/epoch - 2ms/step\n",
            "Epoch 58/500\n",
            "3850/3850 - 6s - loss: 0.3548 - accuracy: 0.8443 - val_loss: 0.1584 - val_accuracy: 0.9712 - 6s/epoch - 2ms/step\n",
            "Epoch 59/500\n",
            "3850/3850 - 6s - loss: 0.3508 - accuracy: 0.8465 - val_loss: 0.2449 - val_accuracy: 0.9341 - 6s/epoch - 2ms/step\n",
            "Epoch 60/500\n",
            "3850/3850 - 6s - loss: 0.3455 - accuracy: 0.8524 - val_loss: 0.2093 - val_accuracy: 0.9467 - 6s/epoch - 2ms/step\n",
            "Epoch 61/500\n",
            "3850/3850 - 6s - loss: 0.3414 - accuracy: 0.8538 - val_loss: 0.3038 - val_accuracy: 0.9189 - 6s/epoch - 2ms/step\n",
            "Epoch 62/500\n",
            "3850/3850 - 6s - loss: 0.3355 - accuracy: 0.8585 - val_loss: 0.3268 - val_accuracy: 0.9100 - 6s/epoch - 2ms/step\n",
            "Epoch 63/500\n",
            "3850/3850 - 6s - loss: 0.3289 - accuracy: 0.8649 - val_loss: 0.1520 - val_accuracy: 0.9624 - 6s/epoch - 1ms/step\n",
            "Epoch 64/500\n",
            "3850/3850 - 6s - loss: 0.3260 - accuracy: 0.8646 - val_loss: 0.1473 - val_accuracy: 0.9617 - 6s/epoch - 1ms/step\n",
            "Epoch 65/500\n",
            "3850/3850 - 6s - loss: 0.3217 - accuracy: 0.8685 - val_loss: 0.3441 - val_accuracy: 0.9000 - 6s/epoch - 1ms/step\n",
            "Epoch 66/500\n",
            "3850/3850 - 6s - loss: 0.3152 - accuracy: 0.8719 - val_loss: 0.1875 - val_accuracy: 0.9556 - 6s/epoch - 1ms/step\n",
            "Epoch 67/500\n",
            "3850/3850 - 6s - loss: 0.3107 - accuracy: 0.8758 - val_loss: 0.1319 - val_accuracy: 0.9703 - 6s/epoch - 1ms/step\n",
            "Epoch 68/500\n",
            "3850/3850 - 6s - loss: 0.3078 - accuracy: 0.8758 - val_loss: 0.1933 - val_accuracy: 0.9437 - 6s/epoch - 2ms/step\n",
            "Epoch 69/500\n",
            "3850/3850 - 6s - loss: 0.3030 - accuracy: 0.8778 - val_loss: 0.1600 - val_accuracy: 0.9584 - 6s/epoch - 2ms/step\n",
            "Epoch 70/500\n",
            "3850/3850 - 6s - loss: 0.2990 - accuracy: 0.8811 - val_loss: 0.1717 - val_accuracy: 0.9572 - 6s/epoch - 2ms/step\n",
            "Epoch 71/500\n",
            "3850/3850 - 6s - loss: 0.2955 - accuracy: 0.8834 - val_loss: 0.2468 - val_accuracy: 0.9271 - 6s/epoch - 1ms/step\n",
            "Epoch 72/500\n",
            "3850/3850 - 6s - loss: 0.2914 - accuracy: 0.8850 - val_loss: 0.2766 - val_accuracy: 0.9194 - 6s/epoch - 1ms/step\n",
            "Epoch 73/500\n",
            "3850/3850 - 6s - loss: 0.2880 - accuracy: 0.8877 - val_loss: 0.2150 - val_accuracy: 0.9367 - 6s/epoch - 2ms/step\n",
            "Epoch 74/500\n",
            "3850/3850 - 6s - loss: 0.2849 - accuracy: 0.8891 - val_loss: 0.3363 - val_accuracy: 0.8810 - 6s/epoch - 2ms/step\n",
            "Epoch 75/500\n",
            "3850/3850 - 6s - loss: 0.2818 - accuracy: 0.8879 - val_loss: 0.1091 - val_accuracy: 0.9687 - 6s/epoch - 1ms/step\n",
            "Epoch 76/500\n",
            "3850/3850 - 6s - loss: 0.2771 - accuracy: 0.8918 - val_loss: 0.2480 - val_accuracy: 0.9215 - 6s/epoch - 2ms/step\n",
            "Epoch 77/500\n",
            "3850/3850 - 6s - loss: 0.2752 - accuracy: 0.8934 - val_loss: 0.1596 - val_accuracy: 0.9554 - 6s/epoch - 2ms/step\n",
            "Epoch 78/500\n",
            "3850/3850 - 6s - loss: 0.2728 - accuracy: 0.8941 - val_loss: 0.1949 - val_accuracy: 0.9481 - 6s/epoch - 1ms/step\n",
            "Epoch 79/500\n",
            "3850/3850 - 6s - loss: 0.2713 - accuracy: 0.8947 - val_loss: 0.2128 - val_accuracy: 0.9329 - 6s/epoch - 1ms/step\n",
            "Epoch 80/500\n",
            "3850/3850 - 6s - loss: 0.2672 - accuracy: 0.8956 - val_loss: 0.1794 - val_accuracy: 0.9483 - 6s/epoch - 1ms/step\n",
            "Epoch 81/500\n",
            "3850/3850 - 6s - loss: 0.2649 - accuracy: 0.8974 - val_loss: 0.1375 - val_accuracy: 0.9617 - 6s/epoch - 2ms/step\n",
            "Epoch 82/500\n",
            "3850/3850 - 6s - loss: 0.2636 - accuracy: 0.8991 - val_loss: 0.1232 - val_accuracy: 0.9624 - 6s/epoch - 2ms/step\n",
            "Epoch 83/500\n",
            "3850/3850 - 6s - loss: 0.2601 - accuracy: 0.8986 - val_loss: 0.1236 - val_accuracy: 0.9631 - 6s/epoch - 1ms/step\n",
            "Epoch 84/500\n",
            "3850/3850 - 6s - loss: 0.2595 - accuracy: 0.8994 - val_loss: 0.1369 - val_accuracy: 0.9586 - 6s/epoch - 2ms/step\n",
            "Epoch 85/500\n",
            "3850/3850 - 6s - loss: 0.2543 - accuracy: 0.9022 - val_loss: 0.2006 - val_accuracy: 0.9402 - 6s/epoch - 2ms/step\n",
            "Epoch 86/500\n",
            "3850/3850 - 6s - loss: 0.2538 - accuracy: 0.9029 - val_loss: 0.1987 - val_accuracy: 0.9404 - 6s/epoch - 1ms/step\n",
            "Epoch 87/500\n",
            "3850/3850 - 6s - loss: 0.2512 - accuracy: 0.9023 - val_loss: 0.1852 - val_accuracy: 0.9434 - 6s/epoch - 1ms/step\n",
            "Epoch 88/500\n",
            "3850/3850 - 6s - loss: 0.2504 - accuracy: 0.9048 - val_loss: 0.2215 - val_accuracy: 0.9301 - 6s/epoch - 1ms/step\n",
            "Epoch 89/500\n",
            "3850/3850 - 6s - loss: 0.2494 - accuracy: 0.9044 - val_loss: 0.1165 - val_accuracy: 0.9680 - 6s/epoch - 2ms/step\n",
            "Epoch 90/500\n",
            "3850/3850 - 6s - loss: 0.2473 - accuracy: 0.9064 - val_loss: 0.2644 - val_accuracy: 0.9095 - 6s/epoch - 1ms/step\n",
            "Epoch 91/500\n",
            "3850/3850 - 6s - loss: 0.2465 - accuracy: 0.9052 - val_loss: 0.0798 - val_accuracy: 0.9769 - 6s/epoch - 2ms/step\n",
            "Epoch 92/500\n",
            "3850/3850 - 6s - loss: 0.2430 - accuracy: 0.9049 - val_loss: 0.0887 - val_accuracy: 0.9743 - 6s/epoch - 1ms/step\n",
            "Epoch 93/500\n",
            "3850/3850 - 6s - loss: 0.2408 - accuracy: 0.9091 - val_loss: 0.3403 - val_accuracy: 0.8689 - 6s/epoch - 2ms/step\n",
            "Epoch 94/500\n",
            "3850/3850 - 6s - loss: 0.2423 - accuracy: 0.9071 - val_loss: 0.1431 - val_accuracy: 0.9584 - 6s/epoch - 1ms/step\n",
            "Epoch 95/500\n",
            "3850/3850 - 6s - loss: 0.2403 - accuracy: 0.9074 - val_loss: 0.0642 - val_accuracy: 0.9792 - 6s/epoch - 1ms/step\n",
            "Epoch 96/500\n",
            "3850/3850 - 6s - loss: 0.2369 - accuracy: 0.9094 - val_loss: 0.1167 - val_accuracy: 0.9638 - 6s/epoch - 2ms/step\n",
            "Epoch 97/500\n",
            "3850/3850 - 6s - loss: 0.2354 - accuracy: 0.9100 - val_loss: 0.1752 - val_accuracy: 0.9458 - 6s/epoch - 1ms/step\n",
            "Epoch 98/500\n",
            "3850/3850 - 6s - loss: 0.2339 - accuracy: 0.9100 - val_loss: 0.3511 - val_accuracy: 0.8651 - 6s/epoch - 1ms/step\n",
            "Epoch 99/500\n",
            "3850/3850 - 6s - loss: 0.2319 - accuracy: 0.9123 - val_loss: 0.1341 - val_accuracy: 0.9614 - 6s/epoch - 1ms/step\n",
            "Epoch 100/500\n",
            "3850/3850 - 6s - loss: 0.2304 - accuracy: 0.9130 - val_loss: 0.2385 - val_accuracy: 0.9156 - 6s/epoch - 1ms/step\n",
            "Epoch 101/500\n",
            "3850/3850 - 6s - loss: 0.2307 - accuracy: 0.9120 - val_loss: 0.1393 - val_accuracy: 0.9586 - 6s/epoch - 1ms/step\n",
            "Epoch 102/500\n",
            "3850/3850 - 6s - loss: 0.2277 - accuracy: 0.9127 - val_loss: 0.1837 - val_accuracy: 0.9434 - 6s/epoch - 1ms/step\n",
            "Epoch 103/500\n",
            "3850/3850 - 6s - loss: 0.2252 - accuracy: 0.9153 - val_loss: 0.1369 - val_accuracy: 0.9586 - 6s/epoch - 2ms/step\n",
            "Epoch 104/500\n",
            "3850/3850 - 6s - loss: 0.2278 - accuracy: 0.9130 - val_loss: 0.4665 - val_accuracy: 0.8029 - 6s/epoch - 2ms/step\n",
            "Epoch 105/500\n",
            "3850/3850 - 6s - loss: 0.2249 - accuracy: 0.9141 - val_loss: 0.1786 - val_accuracy: 0.9404 - 6s/epoch - 2ms/step\n",
            "Epoch 106/500\n",
            "3850/3850 - 6s - loss: 0.2224 - accuracy: 0.9159 - val_loss: 0.1030 - val_accuracy: 0.9661 - 6s/epoch - 2ms/step\n",
            "Epoch 107/500\n",
            "3850/3850 - 6s - loss: 0.2218 - accuracy: 0.9160 - val_loss: 0.0927 - val_accuracy: 0.9696 - 6s/epoch - 2ms/step\n",
            "Epoch 108/500\n",
            "3850/3850 - 6s - loss: 0.2197 - accuracy: 0.9177 - val_loss: 0.2017 - val_accuracy: 0.9343 - 6s/epoch - 2ms/step\n",
            "Epoch 109/500\n",
            "3850/3850 - 6s - loss: 0.2186 - accuracy: 0.9179 - val_loss: 0.2317 - val_accuracy: 0.9210 - 6s/epoch - 1ms/step\n",
            "Epoch 110/500\n",
            "3850/3850 - 6s - loss: 0.2186 - accuracy: 0.9179 - val_loss: 0.1687 - val_accuracy: 0.9509 - 6s/epoch - 1ms/step\n",
            "Epoch 111/500\n",
            "3850/3850 - 6s - loss: 0.2163 - accuracy: 0.9179 - val_loss: 0.1463 - val_accuracy: 0.9554 - 6s/epoch - 1ms/step\n",
            "Epoch 112/500\n",
            "3850/3850 - 6s - loss: 0.2163 - accuracy: 0.9175 - val_loss: 0.1017 - val_accuracy: 0.9684 - 6s/epoch - 1ms/step\n",
            "Epoch 113/500\n",
            "3850/3850 - 6s - loss: 0.2143 - accuracy: 0.9194 - val_loss: 0.0895 - val_accuracy: 0.9736 - 6s/epoch - 2ms/step\n",
            "Epoch 114/500\n",
            "3850/3850 - 6s - loss: 0.2119 - accuracy: 0.9202 - val_loss: 0.2091 - val_accuracy: 0.9303 - 6s/epoch - 2ms/step\n",
            "Epoch 115/500\n",
            "3850/3850 - 6s - loss: 0.2116 - accuracy: 0.9203 - val_loss: 0.1482 - val_accuracy: 0.9532 - 6s/epoch - 2ms/step\n",
            "Epoch 116/500\n",
            "3850/3850 - 6s - loss: 0.2102 - accuracy: 0.9203 - val_loss: 0.1556 - val_accuracy: 0.9462 - 6s/epoch - 1ms/step\n",
            "Epoch 117/500\n",
            "3850/3850 - 6s - loss: 0.2092 - accuracy: 0.9204 - val_loss: 0.2296 - val_accuracy: 0.9165 - 6s/epoch - 1ms/step\n",
            "Epoch 118/500\n",
            "3850/3850 - 6s - loss: 0.2089 - accuracy: 0.9206 - val_loss: 0.2078 - val_accuracy: 0.9278 - 6s/epoch - 2ms/step\n",
            "Epoch 119/500\n",
            "3850/3850 - 6s - loss: 0.2072 - accuracy: 0.9216 - val_loss: 0.1609 - val_accuracy: 0.9472 - 6s/epoch - 1ms/step\n",
            "Epoch 120/500\n",
            "3850/3850 - 6s - loss: 0.2069 - accuracy: 0.9207 - val_loss: 0.2039 - val_accuracy: 0.9371 - 6s/epoch - 2ms/step\n",
            "Epoch 121/500\n",
            "3850/3850 - 6s - loss: 0.2048 - accuracy: 0.9226 - val_loss: 0.2461 - val_accuracy: 0.9093 - 6s/epoch - 2ms/step\n",
            "Epoch 122/500\n",
            "3850/3850 - 6s - loss: 0.2038 - accuracy: 0.9223 - val_loss: 0.2572 - val_accuracy: 0.9086 - 6s/epoch - 2ms/step\n",
            "Epoch 123/500\n",
            "3850/3850 - 6s - loss: 0.2019 - accuracy: 0.9233 - val_loss: 0.2012 - val_accuracy: 0.9329 - 6s/epoch - 2ms/step\n",
            "Epoch 124/500\n",
            "3850/3850 - 6s - loss: 0.2027 - accuracy: 0.9225 - val_loss: 0.1449 - val_accuracy: 0.9537 - 6s/epoch - 1ms/step\n",
            "Epoch 125/500\n",
            "3850/3850 - 6s - loss: 0.2007 - accuracy: 0.9243 - val_loss: 0.1233 - val_accuracy: 0.9600 - 6s/epoch - 2ms/step\n",
            "Epoch 126/500\n",
            "3850/3850 - 6s - loss: 0.1987 - accuracy: 0.9242 - val_loss: 0.0806 - val_accuracy: 0.9750 - 6s/epoch - 2ms/step\n",
            "Epoch 127/500\n",
            "3850/3850 - 6s - loss: 0.1990 - accuracy: 0.9256 - val_loss: 0.1913 - val_accuracy: 0.9383 - 6s/epoch - 1ms/step\n",
            "Epoch 128/500\n",
            "3850/3850 - 6s - loss: 0.1968 - accuracy: 0.9251 - val_loss: 0.1591 - val_accuracy: 0.9467 - 6s/epoch - 2ms/step\n",
            "Epoch 129/500\n",
            "3850/3850 - 6s - loss: 0.1962 - accuracy: 0.9259 - val_loss: 0.2486 - val_accuracy: 0.9114 - 6s/epoch - 1ms/step\n",
            "Epoch 130/500\n",
            "3850/3850 - 6s - loss: 0.1959 - accuracy: 0.9258 - val_loss: 0.2288 - val_accuracy: 0.9219 - 6s/epoch - 1ms/step\n",
            "Epoch 131/500\n",
            "3850/3850 - 6s - loss: 0.1942 - accuracy: 0.9269 - val_loss: 0.3225 - val_accuracy: 0.8813 - 6s/epoch - 1ms/step\n",
            "Epoch 132/500\n",
            "3850/3850 - 6s - loss: 0.1951 - accuracy: 0.9274 - val_loss: 0.1643 - val_accuracy: 0.9474 - 6s/epoch - 2ms/step\n",
            "Epoch 133/500\n",
            "3850/3850 - 6s - loss: 0.1931 - accuracy: 0.9272 - val_loss: 0.1174 - val_accuracy: 0.9598 - 6s/epoch - 2ms/step\n",
            "Epoch 134/500\n",
            "3850/3850 - 6s - loss: 0.1937 - accuracy: 0.9261 - val_loss: 0.1453 - val_accuracy: 0.9502 - 6s/epoch - 2ms/step\n",
            "Epoch 135/500\n",
            "3850/3850 - 6s - loss: 0.1892 - accuracy: 0.9297 - val_loss: 0.0996 - val_accuracy: 0.9698 - 6s/epoch - 2ms/step\n",
            "Epoch 136/500\n",
            "3850/3850 - 6s - loss: 0.1899 - accuracy: 0.9283 - val_loss: 0.0994 - val_accuracy: 0.9696 - 6s/epoch - 2ms/step\n",
            "Epoch 137/500\n",
            "3850/3850 - 6s - loss: 0.1892 - accuracy: 0.9284 - val_loss: 0.0864 - val_accuracy: 0.9743 - 6s/epoch - 2ms/step\n",
            "Epoch 138/500\n",
            "3850/3850 - 6s - loss: 0.1890 - accuracy: 0.9295 - val_loss: 0.1773 - val_accuracy: 0.9437 - 6s/epoch - 2ms/step\n",
            "Epoch 139/500\n",
            "3850/3850 - 6s - loss: 0.1876 - accuracy: 0.9286 - val_loss: 0.1580 - val_accuracy: 0.9479 - 6s/epoch - 1ms/step\n",
            "Epoch 140/500\n",
            "3850/3850 - 6s - loss: 0.1865 - accuracy: 0.9305 - val_loss: 0.0866 - val_accuracy: 0.9731 - 6s/epoch - 1ms/step\n",
            "Epoch 141/500\n",
            "3850/3850 - 6s - loss: 0.1870 - accuracy: 0.9284 - val_loss: 0.1436 - val_accuracy: 0.9516 - 6s/epoch - 2ms/step\n",
            "Epoch 142/500\n",
            "3850/3850 - 6s - loss: 0.1856 - accuracy: 0.9310 - val_loss: 0.0704 - val_accuracy: 0.9808 - 6s/epoch - 1ms/step\n",
            "Epoch 143/500\n",
            "3850/3850 - 6s - loss: 0.1843 - accuracy: 0.9316 - val_loss: 0.0891 - val_accuracy: 0.9750 - 6s/epoch - 1ms/step\n",
            "Epoch 144/500\n",
            "3850/3850 - 6s - loss: 0.1849 - accuracy: 0.9301 - val_loss: 0.1273 - val_accuracy: 0.9610 - 6s/epoch - 1ms/step\n",
            "Epoch 145/500\n",
            "3850/3850 - 6s - loss: 0.1831 - accuracy: 0.9320 - val_loss: 0.2191 - val_accuracy: 0.9236 - 6s/epoch - 2ms/step\n",
            "Epoch 146/500\n",
            "3850/3850 - 6s - loss: 0.1824 - accuracy: 0.9313 - val_loss: 0.1851 - val_accuracy: 0.9343 - 6s/epoch - 2ms/step\n",
            "Epoch 147/500\n",
            "3850/3850 - 6s - loss: 0.1812 - accuracy: 0.9325 - val_loss: 0.1382 - val_accuracy: 0.9554 - 6s/epoch - 2ms/step\n",
            "Epoch 148/500\n",
            "3850/3850 - 6s - loss: 0.1799 - accuracy: 0.9330 - val_loss: 0.1814 - val_accuracy: 0.9406 - 6s/epoch - 2ms/step\n",
            "Epoch 149/500\n",
            "3850/3850 - 6s - loss: 0.1835 - accuracy: 0.9317 - val_loss: 0.1724 - val_accuracy: 0.9430 - 6s/epoch - 2ms/step\n",
            "Epoch 150/500\n",
            "3850/3850 - 6s - loss: 0.1795 - accuracy: 0.9329 - val_loss: 0.2169 - val_accuracy: 0.9254 - 6s/epoch - 1ms/step\n",
            "Epoch 151/500\n",
            "3850/3850 - 6s - loss: 0.1802 - accuracy: 0.9321 - val_loss: 0.1490 - val_accuracy: 0.9507 - 6s/epoch - 1ms/step\n",
            "Epoch 152/500\n",
            "3850/3850 - 6s - loss: 0.1799 - accuracy: 0.9329 - val_loss: 0.0948 - val_accuracy: 0.9712 - 6s/epoch - 2ms/step\n",
            "Epoch 153/500\n",
            "3850/3850 - 6s - loss: 0.1780 - accuracy: 0.9336 - val_loss: 0.0724 - val_accuracy: 0.9797 - 6s/epoch - 2ms/step\n",
            "Epoch 154/500\n",
            "3850/3850 - 6s - loss: 0.1778 - accuracy: 0.9351 - val_loss: 0.1327 - val_accuracy: 0.9584 - 6s/epoch - 1ms/step\n",
            "Epoch 155/500\n",
            "3850/3850 - 6s - loss: 0.1775 - accuracy: 0.9333 - val_loss: 0.1342 - val_accuracy: 0.9575 - 6s/epoch - 2ms/step\n",
            "Epoch 156/500\n",
            "3850/3850 - 6s - loss: 0.1749 - accuracy: 0.9343 - val_loss: 0.2065 - val_accuracy: 0.9278 - 6s/epoch - 2ms/step\n",
            "Epoch 157/500\n",
            "3850/3850 - 6s - loss: 0.1746 - accuracy: 0.9348 - val_loss: 0.2729 - val_accuracy: 0.9016 - 6s/epoch - 2ms/step\n",
            "Epoch 158/500\n",
            "3850/3850 - 6s - loss: 0.1749 - accuracy: 0.9348 - val_loss: 0.1743 - val_accuracy: 0.9397 - 6s/epoch - 2ms/step\n",
            "Epoch 159/500\n",
            "3850/3850 - 6s - loss: 0.1728 - accuracy: 0.9357 - val_loss: 0.1335 - val_accuracy: 0.9584 - 6s/epoch - 2ms/step\n",
            "Epoch 160/500\n",
            "3850/3850 - 6s - loss: 0.1737 - accuracy: 0.9360 - val_loss: 0.1288 - val_accuracy: 0.9584 - 6s/epoch - 2ms/step\n",
            "Epoch 161/500\n",
            "3850/3850 - 6s - loss: 0.1727 - accuracy: 0.9357 - val_loss: 0.1067 - val_accuracy: 0.9680 - 6s/epoch - 2ms/step\n",
            "Epoch 162/500\n",
            "3850/3850 - 6s - loss: 0.1720 - accuracy: 0.9348 - val_loss: 0.1086 - val_accuracy: 0.9656 - 6s/epoch - 1ms/step\n",
            "Epoch 163/500\n",
            "3850/3850 - 6s - loss: 0.1710 - accuracy: 0.9367 - val_loss: 0.3267 - val_accuracy: 0.8700 - 6s/epoch - 2ms/step\n",
            "Epoch 164/500\n",
            "3850/3850 - 6s - loss: 0.1725 - accuracy: 0.9352 - val_loss: 0.3096 - val_accuracy: 0.8824 - 6s/epoch - 1ms/step\n",
            "Epoch 165/500\n",
            "3850/3850 - 6s - loss: 0.1711 - accuracy: 0.9362 - val_loss: 0.2475 - val_accuracy: 0.9142 - 6s/epoch - 2ms/step\n",
            "Epoch 166/500\n",
            "3850/3850 - 6s - loss: 0.1707 - accuracy: 0.9363 - val_loss: 0.2327 - val_accuracy: 0.9135 - 6s/epoch - 1ms/step\n",
            "Epoch 167/500\n",
            "3850/3850 - 6s - loss: 0.1683 - accuracy: 0.9372 - val_loss: 0.1878 - val_accuracy: 0.9348 - 6s/epoch - 2ms/step\n",
            "Epoch 168/500\n",
            "3850/3850 - 6s - loss: 0.1687 - accuracy: 0.9366 - val_loss: 0.1946 - val_accuracy: 0.9343 - 6s/epoch - 1ms/step\n",
            "Epoch 169/500\n",
            "3850/3850 - 6s - loss: 0.1675 - accuracy: 0.9380 - val_loss: 0.1584 - val_accuracy: 0.9479 - 6s/epoch - 2ms/step\n",
            "Epoch 170/500\n",
            "3850/3850 - 6s - loss: 0.1697 - accuracy: 0.9356 - val_loss: 0.1238 - val_accuracy: 0.9617 - 6s/epoch - 1ms/step\n",
            "Epoch 171/500\n",
            "3850/3850 - 6s - loss: 0.1652 - accuracy: 0.9397 - val_loss: 0.0853 - val_accuracy: 0.9752 - 6s/epoch - 1ms/step\n",
            "Epoch 172/500\n",
            "3850/3850 - 6s - loss: 0.1676 - accuracy: 0.9383 - val_loss: 0.1894 - val_accuracy: 0.9364 - 6s/epoch - 1ms/step\n",
            "Epoch 173/500\n",
            "3850/3850 - 6s - loss: 0.1645 - accuracy: 0.9392 - val_loss: 0.2202 - val_accuracy: 0.9203 - 6s/epoch - 1ms/step\n",
            "Epoch 174/500\n",
            "3850/3850 - 6s - loss: 0.1637 - accuracy: 0.9391 - val_loss: 0.2208 - val_accuracy: 0.9226 - 6s/epoch - 1ms/step\n",
            "Epoch 175/500\n",
            "3850/3850 - 6s - loss: 0.1630 - accuracy: 0.9389 - val_loss: 0.1218 - val_accuracy: 0.9624 - 6s/epoch - 1ms/step\n",
            "Epoch 176/500\n",
            "3850/3850 - 6s - loss: 0.1620 - accuracy: 0.9395 - val_loss: 0.1293 - val_accuracy: 0.9589 - 6s/epoch - 1ms/step\n",
            "Epoch 177/500\n",
            "3850/3850 - 6s - loss: 0.1618 - accuracy: 0.9405 - val_loss: 0.2660 - val_accuracy: 0.8934 - 6s/epoch - 2ms/step\n",
            "Epoch 178/500\n",
            "3850/3850 - 6s - loss: 0.1629 - accuracy: 0.9392 - val_loss: 0.1451 - val_accuracy: 0.9514 - 6s/epoch - 1ms/step\n",
            "Epoch 179/500\n",
            "3850/3850 - 6s - loss: 0.1624 - accuracy: 0.9401 - val_loss: 0.2423 - val_accuracy: 0.9126 - 6s/epoch - 2ms/step\n",
            "Epoch 180/500\n",
            "3850/3850 - 6s - loss: 0.1613 - accuracy: 0.9412 - val_loss: 0.3559 - val_accuracy: 0.8569 - 6s/epoch - 1ms/step\n",
            "Epoch 181/500\n",
            "3850/3850 - 6s - loss: 0.1599 - accuracy: 0.9407 - val_loss: 0.1204 - val_accuracy: 0.9626 - 6s/epoch - 1ms/step\n",
            "Epoch 182/500\n",
            "3850/3850 - 6s - loss: 0.1574 - accuracy: 0.9410 - val_loss: 0.1110 - val_accuracy: 0.9670 - 6s/epoch - 2ms/step\n",
            "Epoch 183/500\n",
            "3850/3850 - 6s - loss: 0.1582 - accuracy: 0.9416 - val_loss: 0.1687 - val_accuracy: 0.9427 - 6s/epoch - 1ms/step\n",
            "Epoch 184/500\n",
            "3850/3850 - 6s - loss: 0.1573 - accuracy: 0.9410 - val_loss: 0.1387 - val_accuracy: 0.9549 - 6s/epoch - 2ms/step\n",
            "Epoch 185/500\n",
            "3850/3850 - 6s - loss: 0.1570 - accuracy: 0.9418 - val_loss: 0.2835 - val_accuracy: 0.8885 - 6s/epoch - 2ms/step\n",
            "Epoch 186/500\n",
            "3850/3850 - 6s - loss: 0.1566 - accuracy: 0.9423 - val_loss: 0.1342 - val_accuracy: 0.9561 - 6s/epoch - 1ms/step\n",
            "Epoch 187/500\n",
            "3850/3850 - 6s - loss: 0.1560 - accuracy: 0.9435 - val_loss: 0.2423 - val_accuracy: 0.9081 - 6s/epoch - 1ms/step\n",
            "Epoch 188/500\n",
            "3850/3850 - 6s - loss: 0.1549 - accuracy: 0.9426 - val_loss: 0.2875 - val_accuracy: 0.8836 - 6s/epoch - 1ms/step\n",
            "Epoch 189/500\n",
            "3850/3850 - 6s - loss: 0.1556 - accuracy: 0.9426 - val_loss: 0.0593 - val_accuracy: 0.9848 - 6s/epoch - 2ms/step\n",
            "Epoch 190/500\n",
            "3850/3850 - 6s - loss: 0.1553 - accuracy: 0.9423 - val_loss: 0.1215 - val_accuracy: 0.9603 - 6s/epoch - 2ms/step\n",
            "Epoch 191/500\n",
            "3850/3850 - 6s - loss: 0.1531 - accuracy: 0.9436 - val_loss: 0.0819 - val_accuracy: 0.9759 - 6s/epoch - 1ms/step\n",
            "Epoch 192/500\n",
            "3850/3850 - 6s - loss: 0.1537 - accuracy: 0.9426 - val_loss: 0.1789 - val_accuracy: 0.9402 - 6s/epoch - 2ms/step\n",
            "Epoch 193/500\n",
            "3850/3850 - 6s - loss: 0.1535 - accuracy: 0.9429 - val_loss: 0.2526 - val_accuracy: 0.9028 - 6s/epoch - 1ms/step\n",
            "Epoch 194/500\n",
            "3850/3850 - 6s - loss: 0.1520 - accuracy: 0.9437 - val_loss: 0.4128 - val_accuracy: 0.8259 - 6s/epoch - 1ms/step\n",
            "Epoch 195/500\n",
            "3850/3850 - 6s - loss: 0.1500 - accuracy: 0.9445 - val_loss: 0.1411 - val_accuracy: 0.9507 - 6s/epoch - 1ms/step\n",
            "Epoch 196/500\n",
            "3850/3850 - 6s - loss: 0.1500 - accuracy: 0.9454 - val_loss: 0.1756 - val_accuracy: 0.9395 - 6s/epoch - 2ms/step\n",
            "Epoch 197/500\n",
            "3850/3850 - 6s - loss: 0.1500 - accuracy: 0.9449 - val_loss: 0.2361 - val_accuracy: 0.9086 - 6s/epoch - 2ms/step\n",
            "Epoch 198/500\n",
            "3850/3850 - 6s - loss: 0.1502 - accuracy: 0.9441 - val_loss: 0.1004 - val_accuracy: 0.9708 - 6s/epoch - 2ms/step\n",
            "Epoch 199/500\n",
            "3850/3850 - 6s - loss: 0.1500 - accuracy: 0.9448 - val_loss: 0.2076 - val_accuracy: 0.9231 - 6s/epoch - 1ms/step\n",
            "Epoch 200/500\n",
            "3850/3850 - 6s - loss: 0.1486 - accuracy: 0.9449 - val_loss: 0.1418 - val_accuracy: 0.9540 - 6s/epoch - 1ms/step\n",
            "Epoch 201/500\n",
            "3850/3850 - 6s - loss: 0.1489 - accuracy: 0.9450 - val_loss: 0.6278 - val_accuracy: 0.7513 - 6s/epoch - 1ms/step\n",
            "Epoch 202/500\n",
            "3850/3850 - 6s - loss: 0.1468 - accuracy: 0.9462 - val_loss: 0.3492 - val_accuracy: 0.8516 - 6s/epoch - 1ms/step\n",
            "Epoch 203/500\n",
            "3850/3850 - 6s - loss: 0.1467 - accuracy: 0.9454 - val_loss: 0.1277 - val_accuracy: 0.9577 - 6s/epoch - 2ms/step\n",
            "Epoch 204/500\n",
            "3850/3850 - 6s - loss: 0.1462 - accuracy: 0.9458 - val_loss: 0.1326 - val_accuracy: 0.9558 - 6s/epoch - 2ms/step\n",
            "Epoch 205/500\n",
            "3850/3850 - 6s - loss: 0.1473 - accuracy: 0.9438 - val_loss: 0.2502 - val_accuracy: 0.9018 - 6s/epoch - 2ms/step\n",
            "Epoch 206/500\n",
            "3850/3850 - 6s - loss: 0.1453 - accuracy: 0.9471 - val_loss: 0.3383 - val_accuracy: 0.8546 - 6s/epoch - 2ms/step\n",
            "Epoch 207/500\n",
            "3850/3850 - 6s - loss: 0.1450 - accuracy: 0.9470 - val_loss: 0.0991 - val_accuracy: 0.9722 - 6s/epoch - 2ms/step\n",
            "Epoch 208/500\n",
            "3850/3850 - 6s - loss: 0.1450 - accuracy: 0.9473 - val_loss: 0.1492 - val_accuracy: 0.9493 - 6s/epoch - 2ms/step\n",
            "Epoch 209/500\n",
            "3850/3850 - 6s - loss: 0.1436 - accuracy: 0.9473 - val_loss: 0.2048 - val_accuracy: 0.9238 - 6s/epoch - 1ms/step\n",
            "Epoch 210/500\n",
            "3850/3850 - 6s - loss: 0.1448 - accuracy: 0.9466 - val_loss: 0.0888 - val_accuracy: 0.9766 - 6s/epoch - 2ms/step\n",
            "Epoch 211/500\n",
            "3850/3850 - 6s - loss: 0.1423 - accuracy: 0.9467 - val_loss: 0.0911 - val_accuracy: 0.9727 - 6s/epoch - 2ms/step\n",
            "Epoch 212/500\n",
            "3850/3850 - 6s - loss: 0.1430 - accuracy: 0.9468 - val_loss: 0.1707 - val_accuracy: 0.9385 - 6s/epoch - 2ms/step\n",
            "Epoch 213/500\n",
            "3850/3850 - 6s - loss: 0.1435 - accuracy: 0.9475 - val_loss: 0.1830 - val_accuracy: 0.9348 - 6s/epoch - 2ms/step\n",
            "Epoch 214/500\n",
            "3850/3850 - 6s - loss: 0.1425 - accuracy: 0.9467 - val_loss: 0.0893 - val_accuracy: 0.9750 - 6s/epoch - 1ms/step\n",
            "Epoch 215/500\n",
            "3850/3850 - 6s - loss: 0.1410 - accuracy: 0.9474 - val_loss: 0.0938 - val_accuracy: 0.9741 - 6s/epoch - 2ms/step\n",
            "Epoch 216/500\n",
            "3850/3850 - 6s - loss: 0.1418 - accuracy: 0.9472 - val_loss: 0.3969 - val_accuracy: 0.8378 - 6s/epoch - 1ms/step\n",
            "Epoch 217/500\n",
            "3850/3850 - 6s - loss: 0.1410 - accuracy: 0.9486 - val_loss: 0.1732 - val_accuracy: 0.9404 - 6s/epoch - 2ms/step\n",
            "Epoch 218/500\n",
            "3850/3850 - 6s - loss: 0.1390 - accuracy: 0.9493 - val_loss: 0.2056 - val_accuracy: 0.9252 - 6s/epoch - 1ms/step\n",
            "Epoch 219/500\n",
            "3850/3850 - 6s - loss: 0.1400 - accuracy: 0.9486 - val_loss: 0.1410 - val_accuracy: 0.9563 - 6s/epoch - 1ms/step\n",
            "Epoch 220/500\n",
            "3850/3850 - 6s - loss: 0.1393 - accuracy: 0.9483 - val_loss: 0.1083 - val_accuracy: 0.9668 - 6s/epoch - 1ms/step\n",
            "Epoch 221/500\n",
            "3850/3850 - 6s - loss: 0.1393 - accuracy: 0.9484 - val_loss: 0.1171 - val_accuracy: 0.9652 - 6s/epoch - 2ms/step\n",
            "Epoch 222/500\n",
            "3850/3850 - 6s - loss: 0.1384 - accuracy: 0.9499 - val_loss: 0.0903 - val_accuracy: 0.9771 - 6s/epoch - 2ms/step\n",
            "Epoch 223/500\n",
            "3850/3850 - 6s - loss: 0.1378 - accuracy: 0.9503 - val_loss: 0.2067 - val_accuracy: 0.9196 - 6s/epoch - 2ms/step\n",
            "Epoch 224/500\n",
            "3850/3850 - 6s - loss: 0.1368 - accuracy: 0.9500 - val_loss: 0.1367 - val_accuracy: 0.9547 - 6s/epoch - 2ms/step\n",
            "Epoch 225/500\n",
            "3850/3850 - 6s - loss: 0.1350 - accuracy: 0.9503 - val_loss: 0.2880 - val_accuracy: 0.8806 - 6s/epoch - 2ms/step\n",
            "Epoch 226/500\n",
            "3850/3850 - 6s - loss: 0.1366 - accuracy: 0.9495 - val_loss: 0.1279 - val_accuracy: 0.9596 - 6s/epoch - 1ms/step\n",
            "Epoch 227/500\n",
            "3850/3850 - 6s - loss: 0.1362 - accuracy: 0.9502 - val_loss: 0.1136 - val_accuracy: 0.9680 - 6s/epoch - 1ms/step\n",
            "Epoch 228/500\n",
            "3850/3850 - 6s - loss: 0.1359 - accuracy: 0.9500 - val_loss: 0.1871 - val_accuracy: 0.9348 - 6s/epoch - 1ms/step\n",
            "Epoch 229/500\n",
            "3850/3850 - 6s - loss: 0.1354 - accuracy: 0.9504 - val_loss: 0.1195 - val_accuracy: 0.9647 - 6s/epoch - 1ms/step\n",
            "Epoch 230/500\n",
            "3850/3850 - 6s - loss: 0.1363 - accuracy: 0.9499 - val_loss: 0.1266 - val_accuracy: 0.9617 - 6s/epoch - 1ms/step\n",
            "Epoch 231/500\n",
            "3850/3850 - 6s - loss: 0.1328 - accuracy: 0.9505 - val_loss: 0.0938 - val_accuracy: 0.9755 - 6s/epoch - 2ms/step\n",
            "Epoch 232/500\n",
            "3850/3850 - 6s - loss: 0.1354 - accuracy: 0.9504 - val_loss: 0.1956 - val_accuracy: 0.9271 - 6s/epoch - 2ms/step\n",
            "Epoch 233/500\n",
            "3850/3850 - 6s - loss: 0.1336 - accuracy: 0.9508 - val_loss: 0.1165 - val_accuracy: 0.9642 - 6s/epoch - 2ms/step\n",
            "Epoch 234/500\n",
            "3850/3850 - 6s - loss: 0.1354 - accuracy: 0.9505 - val_loss: 0.1527 - val_accuracy: 0.9472 - 6s/epoch - 2ms/step\n",
            "Epoch 235/500\n",
            "3850/3850 - 6s - loss: 0.1324 - accuracy: 0.9517 - val_loss: 0.0611 - val_accuracy: 0.9843 - 6s/epoch - 2ms/step\n",
            "Epoch 236/500\n",
            "3850/3850 - 6s - loss: 0.1356 - accuracy: 0.9499 - val_loss: 0.2487 - val_accuracy: 0.8986 - 6s/epoch - 2ms/step\n",
            "Epoch 237/500\n",
            "3850/3850 - 6s - loss: 0.1333 - accuracy: 0.9508 - val_loss: 0.2712 - val_accuracy: 0.8904 - 6s/epoch - 2ms/step\n",
            "Epoch 238/500\n",
            "3850/3850 - 6s - loss: 0.1321 - accuracy: 0.9517 - val_loss: 0.1580 - val_accuracy: 0.9504 - 6s/epoch - 1ms/step\n",
            "Epoch 239/500\n",
            "3850/3850 - 6s - loss: 0.1312 - accuracy: 0.9525 - val_loss: 0.2195 - val_accuracy: 0.9128 - 6s/epoch - 1ms/step\n",
            "Epoch 240/500\n",
            "3850/3850 - 6s - loss: 0.1312 - accuracy: 0.9523 - val_loss: 0.1460 - val_accuracy: 0.9509 - 6s/epoch - 2ms/step\n",
            "Epoch 241/500\n",
            "3850/3850 - 6s - loss: 0.1294 - accuracy: 0.9514 - val_loss: 0.1267 - val_accuracy: 0.9626 - 6s/epoch - 1ms/step\n",
            "Epoch 242/500\n",
            "3850/3850 - 6s - loss: 0.1314 - accuracy: 0.9510 - val_loss: 0.2071 - val_accuracy: 0.9231 - 6s/epoch - 2ms/step\n",
            "Epoch 243/500\n",
            "3850/3850 - 6s - loss: 0.1305 - accuracy: 0.9524 - val_loss: 0.2439 - val_accuracy: 0.9023 - 6s/epoch - 2ms/step\n",
            "Epoch 244/500\n",
            "3850/3850 - 6s - loss: 0.1291 - accuracy: 0.9522 - val_loss: 0.0842 - val_accuracy: 0.9776 - 6s/epoch - 1ms/step\n",
            "Epoch 245/500\n",
            "3850/3850 - 6s - loss: 0.1280 - accuracy: 0.9531 - val_loss: 0.1526 - val_accuracy: 0.9488 - 6s/epoch - 2ms/step\n",
            "Epoch 246/500\n",
            "3850/3850 - 6s - loss: 0.1294 - accuracy: 0.9527 - val_loss: 0.0929 - val_accuracy: 0.9752 - 6s/epoch - 2ms/step\n",
            "Epoch 247/500\n",
            "3850/3850 - 6s - loss: 0.1295 - accuracy: 0.9516 - val_loss: 0.2193 - val_accuracy: 0.9198 - 6s/epoch - 1ms/step\n",
            "Epoch 248/500\n",
            "3850/3850 - 6s - loss: 0.1283 - accuracy: 0.9528 - val_loss: 0.1364 - val_accuracy: 0.9540 - 6s/epoch - 1ms/step\n",
            "Epoch 249/500\n",
            "3850/3850 - 6s - loss: 0.1282 - accuracy: 0.9535 - val_loss: 0.1912 - val_accuracy: 0.9343 - 6s/epoch - 2ms/step\n",
            "Epoch 250/500\n",
            "3850/3850 - 6s - loss: 0.1274 - accuracy: 0.9530 - val_loss: 0.1376 - val_accuracy: 0.9530 - 6s/epoch - 1ms/step\n",
            "Epoch 251/500\n",
            "3850/3850 - 6s - loss: 0.1288 - accuracy: 0.9527 - val_loss: 0.1177 - val_accuracy: 0.9649 - 6s/epoch - 1ms/step\n",
            "Epoch 252/500\n",
            "3850/3850 - 6s - loss: 0.1275 - accuracy: 0.9538 - val_loss: 0.1480 - val_accuracy: 0.9521 - 6s/epoch - 2ms/step\n",
            "Epoch 253/500\n",
            "3850/3850 - 6s - loss: 0.1288 - accuracy: 0.9522 - val_loss: 0.0851 - val_accuracy: 0.9759 - 6s/epoch - 2ms/step\n",
            "Epoch 254/500\n",
            "3850/3850 - 6s - loss: 0.1268 - accuracy: 0.9547 - val_loss: 0.2411 - val_accuracy: 0.9032 - 6s/epoch - 1ms/step\n",
            "Epoch 255/500\n",
            "3850/3850 - 6s - loss: 0.1275 - accuracy: 0.9538 - val_loss: 0.2260 - val_accuracy: 0.9140 - 6s/epoch - 2ms/step\n",
            "Epoch 256/500\n",
            "3850/3850 - 6s - loss: 0.1250 - accuracy: 0.9549 - val_loss: 0.1394 - val_accuracy: 0.9563 - 6s/epoch - 1ms/step\n",
            "Epoch 257/500\n",
            "3850/3850 - 6s - loss: 0.1260 - accuracy: 0.9539 - val_loss: 0.2402 - val_accuracy: 0.9049 - 6s/epoch - 2ms/step\n",
            "Epoch 258/500\n",
            "3850/3850 - 6s - loss: 0.1247 - accuracy: 0.9538 - val_loss: 0.1506 - val_accuracy: 0.9518 - 6s/epoch - 2ms/step\n",
            "Epoch 259/500\n",
            "3850/3850 - 6s - loss: 0.1247 - accuracy: 0.9551 - val_loss: 0.1960 - val_accuracy: 0.9278 - 6s/epoch - 1ms/step\n",
            "Epoch 260/500\n",
            "3850/3850 - 6s - loss: 0.1249 - accuracy: 0.9533 - val_loss: 0.3605 - val_accuracy: 0.8558 - 6s/epoch - 1ms/step\n",
            "Epoch 261/500\n",
            "3850/3850 - 6s - loss: 0.1237 - accuracy: 0.9547 - val_loss: 0.1510 - val_accuracy: 0.9507 - 6s/epoch - 2ms/step\n",
            "Epoch 262/500\n",
            "3850/3850 - 6s - loss: 0.1250 - accuracy: 0.9545 - val_loss: 0.1506 - val_accuracy: 0.9490 - 6s/epoch - 2ms/step\n",
            "Epoch 263/500\n",
            "3850/3850 - 6s - loss: 0.1259 - accuracy: 0.9546 - val_loss: 0.1154 - val_accuracy: 0.9640 - 6s/epoch - 2ms/step\n",
            "Epoch 264/500\n",
            "3850/3850 - 6s - loss: 0.1232 - accuracy: 0.9541 - val_loss: 0.1773 - val_accuracy: 0.9353 - 6s/epoch - 1ms/step\n",
            "Epoch 265/500\n",
            "3850/3850 - 6s - loss: 0.1247 - accuracy: 0.9545 - val_loss: 0.1376 - val_accuracy: 0.9547 - 6s/epoch - 2ms/step\n",
            "Epoch 266/500\n",
            "3850/3850 - 6s - loss: 0.1242 - accuracy: 0.9548 - val_loss: 0.2864 - val_accuracy: 0.8784 - 6s/epoch - 2ms/step\n",
            "Epoch 267/500\n",
            "3850/3850 - 6s - loss: 0.1222 - accuracy: 0.9546 - val_loss: 0.2491 - val_accuracy: 0.9032 - 6s/epoch - 2ms/step\n",
            "Epoch 268/500\n",
            "3850/3850 - 6s - loss: 0.1231 - accuracy: 0.9544 - val_loss: 0.1814 - val_accuracy: 0.9350 - 6s/epoch - 2ms/step\n",
            "Epoch 269/500\n",
            "3850/3850 - 6s - loss: 0.1210 - accuracy: 0.9553 - val_loss: 0.2194 - val_accuracy: 0.9133 - 6s/epoch - 2ms/step\n",
            "Epoch 270/500\n",
            "3850/3850 - 6s - loss: 0.1220 - accuracy: 0.9557 - val_loss: 0.1563 - val_accuracy: 0.9458 - 6s/epoch - 1ms/step\n",
            "Epoch 271/500\n",
            "3850/3850 - 6s - loss: 0.1218 - accuracy: 0.9557 - val_loss: 0.3256 - val_accuracy: 0.8656 - 6s/epoch - 2ms/step\n",
            "Epoch 272/500\n",
            "3850/3850 - 6s - loss: 0.1209 - accuracy: 0.9559 - val_loss: 0.2020 - val_accuracy: 0.9275 - 6s/epoch - 2ms/step\n",
            "Epoch 273/500\n",
            "3850/3850 - 6s - loss: 0.1201 - accuracy: 0.9554 - val_loss: 0.1028 - val_accuracy: 0.9717 - 6s/epoch - 2ms/step\n",
            "Epoch 274/500\n",
            "3850/3850 - 6s - loss: 0.1214 - accuracy: 0.9551 - val_loss: 0.2724 - val_accuracy: 0.8887 - 6s/epoch - 1ms/step\n",
            "Epoch 275/500\n",
            "3850/3850 - 6s - loss: 0.1213 - accuracy: 0.9557 - val_loss: 0.2681 - val_accuracy: 0.8901 - 6s/epoch - 2ms/step\n",
            "Epoch 276/500\n",
            "3850/3850 - 6s - loss: 0.1220 - accuracy: 0.9552 - val_loss: 0.0936 - val_accuracy: 0.9750 - 6s/epoch - 2ms/step\n",
            "Epoch 277/500\n",
            "3850/3850 - 6s - loss: 0.1194 - accuracy: 0.9559 - val_loss: 0.0628 - val_accuracy: 0.9860 - 6s/epoch - 2ms/step\n",
            "Epoch 278/500\n",
            "3850/3850 - 6s - loss: 0.1197 - accuracy: 0.9553 - val_loss: 0.2742 - val_accuracy: 0.8834 - 6s/epoch - 2ms/step\n",
            "Epoch 279/500\n",
            "3850/3850 - 6s - loss: 0.1189 - accuracy: 0.9567 - val_loss: 0.1826 - val_accuracy: 0.9322 - 6s/epoch - 1ms/step\n",
            "Epoch 280/500\n",
            "3850/3850 - 6s - loss: 0.1195 - accuracy: 0.9558 - val_loss: 0.2239 - val_accuracy: 0.9100 - 6s/epoch - 2ms/step\n",
            "Epoch 281/500\n",
            "3850/3850 - 6s - loss: 0.1205 - accuracy: 0.9553 - val_loss: 0.2338 - val_accuracy: 0.9042 - 6s/epoch - 2ms/step\n",
            "Epoch 282/500\n",
            "3850/3850 - 6s - loss: 0.1198 - accuracy: 0.9556 - val_loss: 0.0849 - val_accuracy: 0.9764 - 6s/epoch - 1ms/step\n",
            "Epoch 283/500\n",
            "3850/3850 - 6s - loss: 0.1192 - accuracy: 0.9563 - val_loss: 0.0899 - val_accuracy: 0.9752 - 6s/epoch - 2ms/step\n",
            "Epoch 284/500\n",
            "3850/3850 - 6s - loss: 0.1186 - accuracy: 0.9564 - val_loss: 0.2935 - val_accuracy: 0.8824 - 6s/epoch - 1ms/step\n",
            "Epoch 285/500\n",
            "3850/3850 - 6s - loss: 0.1185 - accuracy: 0.9560 - val_loss: 0.1449 - val_accuracy: 0.9502 - 6s/epoch - 1ms/step\n",
            "Epoch 286/500\n",
            "3850/3850 - 6s - loss: 0.1183 - accuracy: 0.9570 - val_loss: 0.2077 - val_accuracy: 0.9212 - 6s/epoch - 1ms/step\n",
            "Epoch 287/500\n",
            "3850/3850 - 6s - loss: 0.1184 - accuracy: 0.9556 - val_loss: 0.1534 - val_accuracy: 0.9479 - 6s/epoch - 1ms/step\n",
            "Epoch 288/500\n",
            "3850/3850 - 6s - loss: 0.1162 - accuracy: 0.9574 - val_loss: 0.0893 - val_accuracy: 0.9743 - 6s/epoch - 2ms/step\n",
            "Epoch 289/500\n",
            "3850/3850 - 6s - loss: 0.1180 - accuracy: 0.9563 - val_loss: 0.1923 - val_accuracy: 0.9280 - 6s/epoch - 2ms/step\n",
            "Epoch 290/500\n",
            "3850/3850 - 6s - loss: 0.1182 - accuracy: 0.9572 - val_loss: 0.3502 - val_accuracy: 0.8548 - 6s/epoch - 1ms/step\n",
            "Epoch 291/500\n",
            "3850/3850 - 6s - loss: 0.1181 - accuracy: 0.9565 - val_loss: 0.1049 - val_accuracy: 0.9701 - 6s/epoch - 2ms/step\n",
            "Epoch 292/500\n",
            "3850/3850 - 6s - loss: 0.1174 - accuracy: 0.9575 - val_loss: 0.1699 - val_accuracy: 0.9374 - 6s/epoch - 1ms/step\n",
            "Epoch 293/500\n",
            "3850/3850 - 6s - loss: 0.1164 - accuracy: 0.9569 - val_loss: 0.2453 - val_accuracy: 0.9063 - 6s/epoch - 1ms/step\n",
            "Epoch 294/500\n",
            "3850/3850 - 6s - loss: 0.1157 - accuracy: 0.9579 - val_loss: 0.1046 - val_accuracy: 0.9712 - 6s/epoch - 2ms/step\n",
            "Epoch 295/500\n",
            "3850/3850 - 6s - loss: 0.1169 - accuracy: 0.9568 - val_loss: 0.3324 - val_accuracy: 0.8644 - 6s/epoch - 2ms/step\n",
            "Epoch 296/500\n",
            "3850/3850 - 6s - loss: 0.1162 - accuracy: 0.9576 - val_loss: 0.0900 - val_accuracy: 0.9759 - 6s/epoch - 2ms/step\n",
            "Epoch 297/500\n",
            "3850/3850 - 6s - loss: 0.1170 - accuracy: 0.9577 - val_loss: 0.2933 - val_accuracy: 0.8754 - 6s/epoch - 2ms/step\n",
            "Epoch 298/500\n",
            "3850/3850 - 6s - loss: 0.1153 - accuracy: 0.9572 - val_loss: 0.1124 - val_accuracy: 0.9652 - 6s/epoch - 1ms/step\n",
            "Epoch 299/500\n",
            "3850/3850 - 6s - loss: 0.1158 - accuracy: 0.9581 - val_loss: 0.2599 - val_accuracy: 0.8995 - 6s/epoch - 2ms/step\n",
            "Epoch 300/500\n",
            "3850/3850 - 6s - loss: 0.1142 - accuracy: 0.9585 - val_loss: 0.3302 - val_accuracy: 0.8682 - 6s/epoch - 1ms/step\n",
            "Epoch 301/500\n",
            "3850/3850 - 6s - loss: 0.1152 - accuracy: 0.9579 - val_loss: 0.1510 - val_accuracy: 0.9481 - 6s/epoch - 1ms/step\n",
            "Epoch 302/500\n",
            "3850/3850 - 6s - loss: 0.1131 - accuracy: 0.9581 - val_loss: 0.1700 - val_accuracy: 0.9420 - 6s/epoch - 1ms/step\n",
            "Epoch 303/500\n",
            "3850/3850 - 6s - loss: 0.1137 - accuracy: 0.9572 - val_loss: 0.1274 - val_accuracy: 0.9589 - 6s/epoch - 2ms/step\n",
            "Epoch 304/500\n",
            "3850/3850 - 6s - loss: 0.1144 - accuracy: 0.9577 - val_loss: 0.3240 - val_accuracy: 0.8656 - 6s/epoch - 1ms/step\n",
            "Epoch 305/500\n",
            "3850/3850 - 6s - loss: 0.1143 - accuracy: 0.9577 - val_loss: 0.0605 - val_accuracy: 0.9864 - 6s/epoch - 2ms/step\n",
            "Epoch 306/500\n",
            "3850/3850 - 6s - loss: 0.1135 - accuracy: 0.9586 - val_loss: 0.1294 - val_accuracy: 0.9572 - 6s/epoch - 1ms/step\n",
            "Epoch 307/500\n",
            "3850/3850 - 6s - loss: 0.1135 - accuracy: 0.9596 - val_loss: 0.1194 - val_accuracy: 0.9612 - 6s/epoch - 1ms/step\n",
            "Epoch 308/500\n",
            "3850/3850 - 6s - loss: 0.1121 - accuracy: 0.9584 - val_loss: 0.1037 - val_accuracy: 0.9708 - 6s/epoch - 2ms/step\n",
            "Epoch 309/500\n",
            "3850/3850 - 6s - loss: 0.1126 - accuracy: 0.9578 - val_loss: 0.1323 - val_accuracy: 0.9556 - 6s/epoch - 2ms/step\n",
            "Epoch 310/500\n",
            "3850/3850 - 6s - loss: 0.1128 - accuracy: 0.9585 - val_loss: 0.1545 - val_accuracy: 0.9465 - 6s/epoch - 2ms/step\n",
            "Epoch 311/500\n",
            "3850/3850 - 6s - loss: 0.1131 - accuracy: 0.9583 - val_loss: 0.2205 - val_accuracy: 0.9161 - 6s/epoch - 2ms/step\n",
            "Epoch 312/500\n",
            "3850/3850 - 6s - loss: 0.1129 - accuracy: 0.9580 - val_loss: 0.1853 - val_accuracy: 0.9280 - 6s/epoch - 1ms/step\n",
            "Epoch 313/500\n",
            "3850/3850 - 6s - loss: 0.1129 - accuracy: 0.9584 - val_loss: 0.0943 - val_accuracy: 0.9734 - 6s/epoch - 1ms/step\n",
            "Epoch 314/500\n",
            "3850/3850 - 6s - loss: 0.1095 - accuracy: 0.9594 - val_loss: 0.1268 - val_accuracy: 0.9617 - 6s/epoch - 2ms/step\n",
            "Epoch 315/500\n",
            "3850/3850 - 6s - loss: 0.1119 - accuracy: 0.9590 - val_loss: 0.1716 - val_accuracy: 0.9385 - 6s/epoch - 1ms/step\n",
            "Epoch 316/500\n",
            "3850/3850 - 6s - loss: 0.1122 - accuracy: 0.9591 - val_loss: 0.1155 - val_accuracy: 0.9628 - 6s/epoch - 2ms/step\n",
            "Epoch 317/500\n",
            "3850/3850 - 6s - loss: 0.1135 - accuracy: 0.9581 - val_loss: 0.1773 - val_accuracy: 0.9303 - 6s/epoch - 2ms/step\n",
            "Epoch 318/500\n",
            "3850/3850 - 6s - loss: 0.1126 - accuracy: 0.9573 - val_loss: 0.1255 - val_accuracy: 0.9624 - 6s/epoch - 1ms/step\n",
            "Epoch 319/500\n",
            "3850/3850 - 6s - loss: 0.1109 - accuracy: 0.9595 - val_loss: 0.3739 - val_accuracy: 0.8488 - 6s/epoch - 2ms/step\n",
            "Epoch 320/500\n",
            "3850/3850 - 6s - loss: 0.1109 - accuracy: 0.9589 - val_loss: 0.1233 - val_accuracy: 0.9596 - 6s/epoch - 1ms/step\n",
            "Epoch 321/500\n",
            "3850/3850 - 6s - loss: 0.1111 - accuracy: 0.9591 - val_loss: 0.0618 - val_accuracy: 0.9843 - 6s/epoch - 2ms/step\n",
            "Epoch 322/500\n",
            "3850/3850 - 6s - loss: 0.1095 - accuracy: 0.9593 - val_loss: 0.1109 - val_accuracy: 0.9673 - 6s/epoch - 1ms/step\n",
            "Epoch 323/500\n",
            "3850/3850 - 6s - loss: 0.1106 - accuracy: 0.9592 - val_loss: 0.1207 - val_accuracy: 0.9624 - 6s/epoch - 1ms/step\n",
            "Epoch 324/500\n",
            "3850/3850 - 6s - loss: 0.1117 - accuracy: 0.9588 - val_loss: 0.2451 - val_accuracy: 0.9025 - 6s/epoch - 2ms/step\n",
            "Epoch 325/500\n",
            "3850/3850 - 6s - loss: 0.1112 - accuracy: 0.9589 - val_loss: 0.1323 - val_accuracy: 0.9589 - 6s/epoch - 1ms/step\n",
            "Epoch 326/500\n",
            "3850/3850 - 6s - loss: 0.1098 - accuracy: 0.9595 - val_loss: 0.0762 - val_accuracy: 0.9808 - 6s/epoch - 2ms/step\n",
            "Epoch 327/500\n",
            "3850/3850 - 6s - loss: 0.1093 - accuracy: 0.9599 - val_loss: 0.0796 - val_accuracy: 0.9778 - 6s/epoch - 1ms/step\n",
            "Epoch 328/500\n",
            "3850/3850 - 6s - loss: 0.1109 - accuracy: 0.9586 - val_loss: 0.2938 - val_accuracy: 0.8780 - 6s/epoch - 1ms/step\n",
            "Epoch 329/500\n",
            "3850/3850 - 6s - loss: 0.1105 - accuracy: 0.9593 - val_loss: 0.1671 - val_accuracy: 0.9402 - 6s/epoch - 2ms/step\n",
            "Epoch 330/500\n",
            "3850/3850 - 6s - loss: 0.1091 - accuracy: 0.9597 - val_loss: 0.2687 - val_accuracy: 0.8862 - 6s/epoch - 2ms/step\n",
            "Epoch 331/500\n",
            "3850/3850 - 6s - loss: 0.1089 - accuracy: 0.9606 - val_loss: 0.4563 - val_accuracy: 0.8079 - 6s/epoch - 1ms/step\n",
            "Epoch 332/500\n",
            "3850/3850 - 6s - loss: 0.1087 - accuracy: 0.9611 - val_loss: 0.3527 - val_accuracy: 0.8576 - 6s/epoch - 2ms/step\n",
            "Epoch 333/500\n",
            "3850/3850 - 6s - loss: 0.1084 - accuracy: 0.9604 - val_loss: 0.1145 - val_accuracy: 0.9656 - 6s/epoch - 1ms/step\n",
            "Epoch 334/500\n",
            "3850/3850 - 6s - loss: 0.1093 - accuracy: 0.9592 - val_loss: 0.2451 - val_accuracy: 0.8986 - 6s/epoch - 2ms/step\n",
            "Epoch 335/500\n",
            "3850/3850 - 6s - loss: 0.1088 - accuracy: 0.9597 - val_loss: 0.1729 - val_accuracy: 0.9348 - 6s/epoch - 2ms/step\n",
            "Epoch 336/500\n",
            "3850/3850 - 6s - loss: 0.1087 - accuracy: 0.9599 - val_loss: 0.1234 - val_accuracy: 0.9586 - 6s/epoch - 1ms/step\n",
            "Epoch 337/500\n",
            "3850/3850 - 6s - loss: 0.1087 - accuracy: 0.9610 - val_loss: 0.1200 - val_accuracy: 0.9600 - 6s/epoch - 1ms/step\n",
            "Epoch 338/500\n",
            "3850/3850 - 6s - loss: 0.1082 - accuracy: 0.9604 - val_loss: 0.1678 - val_accuracy: 0.9395 - 6s/epoch - 1ms/step\n",
            "Epoch 339/500\n",
            "3850/3850 - 6s - loss: 0.1071 - accuracy: 0.9604 - val_loss: 0.2647 - val_accuracy: 0.8964 - 6s/epoch - 2ms/step\n",
            "Epoch 340/500\n",
            "3850/3850 - 6s - loss: 0.1068 - accuracy: 0.9604 - val_loss: 0.1079 - val_accuracy: 0.9666 - 6s/epoch - 2ms/step\n",
            "Epoch 341/500\n",
            "3850/3850 - 6s - loss: 0.1073 - accuracy: 0.9612 - val_loss: 0.2501 - val_accuracy: 0.8986 - 6s/epoch - 1ms/step\n",
            "Epoch 342/500\n",
            "3850/3850 - 6s - loss: 0.1066 - accuracy: 0.9600 - val_loss: 0.0898 - val_accuracy: 0.9769 - 6s/epoch - 1ms/step\n",
            "Epoch 343/500\n",
            "3850/3850 - 6s - loss: 0.1075 - accuracy: 0.9615 - val_loss: 0.0995 - val_accuracy: 0.9710 - 6s/epoch - 1ms/step\n",
            "Epoch 344/500\n",
            "3850/3850 - 6s - loss: 0.1063 - accuracy: 0.9603 - val_loss: 0.1487 - val_accuracy: 0.9500 - 6s/epoch - 1ms/step\n",
            "Epoch 345/500\n",
            "3850/3850 - 6s - loss: 0.1059 - accuracy: 0.9609 - val_loss: 0.1223 - val_accuracy: 0.9631 - 6s/epoch - 2ms/step\n",
            "Epoch 346/500\n",
            "3850/3850 - 6s - loss: 0.1068 - accuracy: 0.9600 - val_loss: 0.2742 - val_accuracy: 0.8922 - 6s/epoch - 1ms/step\n",
            "Epoch 347/500\n",
            "3850/3850 - 6s - loss: 0.1052 - accuracy: 0.9617 - val_loss: 0.2440 - val_accuracy: 0.9007 - 6s/epoch - 1ms/step\n",
            "Epoch 348/500\n",
            "3850/3850 - 6s - loss: 0.1042 - accuracy: 0.9617 - val_loss: 0.2894 - val_accuracy: 0.8789 - 6s/epoch - 2ms/step\n",
            "Epoch 349/500\n",
            "3850/3850 - 6s - loss: 0.1082 - accuracy: 0.9593 - val_loss: 0.1473 - val_accuracy: 0.9472 - 6s/epoch - 2ms/step\n",
            "Epoch 350/500\n",
            "3850/3850 - 6s - loss: 0.1060 - accuracy: 0.9601 - val_loss: 0.1490 - val_accuracy: 0.9472 - 6s/epoch - 2ms/step\n",
            "Epoch 351/500\n",
            "3850/3850 - 6s - loss: 0.1054 - accuracy: 0.9610 - val_loss: 0.3765 - val_accuracy: 0.8502 - 6s/epoch - 1ms/step\n",
            "Epoch 352/500\n",
            "3850/3850 - 6s - loss: 0.1062 - accuracy: 0.9609 - val_loss: 0.1742 - val_accuracy: 0.9355 - 6s/epoch - 2ms/step\n",
            "Epoch 353/500\n",
            "3850/3850 - 6s - loss: 0.1054 - accuracy: 0.9602 - val_loss: 0.1715 - val_accuracy: 0.9327 - 6s/epoch - 2ms/step\n",
            "Epoch 354/500\n",
            "3850/3850 - 6s - loss: 0.1052 - accuracy: 0.9611 - val_loss: 0.1490 - val_accuracy: 0.9486 - 6s/epoch - 1ms/step\n",
            "Epoch 355/500\n",
            "3850/3850 - 6s - loss: 0.1057 - accuracy: 0.9613 - val_loss: 0.1557 - val_accuracy: 0.9465 - 6s/epoch - 2ms/step\n",
            "Epoch 356/500\n",
            "3850/3850 - 6s - loss: 0.1048 - accuracy: 0.9612 - val_loss: 0.1688 - val_accuracy: 0.9331 - 6s/epoch - 1ms/step\n",
            "Epoch 357/500\n",
            "3850/3850 - 6s - loss: 0.1054 - accuracy: 0.9613 - val_loss: 0.2745 - val_accuracy: 0.8901 - 6s/epoch - 2ms/step\n",
            "Epoch 358/500\n",
            "3850/3850 - 6s - loss: 0.1048 - accuracy: 0.9614 - val_loss: 0.1245 - val_accuracy: 0.9598 - 6s/epoch - 1ms/step\n",
            "Epoch 359/500\n",
            "3850/3850 - 6s - loss: 0.1046 - accuracy: 0.9612 - val_loss: 0.1447 - val_accuracy: 0.9479 - 6s/epoch - 1ms/step\n",
            "Epoch 360/500\n",
            "3850/3850 - 6s - loss: 0.1055 - accuracy: 0.9610 - val_loss: 0.1525 - val_accuracy: 0.9455 - 6s/epoch - 1ms/step\n",
            "Epoch 361/500\n",
            "3850/3850 - 6s - loss: 0.1033 - accuracy: 0.9626 - val_loss: 0.1273 - val_accuracy: 0.9568 - 6s/epoch - 1ms/step\n",
            "Epoch 362/500\n",
            "3850/3850 - 6s - loss: 0.1042 - accuracy: 0.9622 - val_loss: 0.1778 - val_accuracy: 0.9315 - 6s/epoch - 2ms/step\n",
            "Epoch 363/500\n",
            "3850/3850 - 6s - loss: 0.1042 - accuracy: 0.9612 - val_loss: 0.1905 - val_accuracy: 0.9282 - 6s/epoch - 1ms/step\n",
            "Epoch 364/500\n",
            "3850/3850 - 6s - loss: 0.1033 - accuracy: 0.9620 - val_loss: 0.2001 - val_accuracy: 0.9226 - 6s/epoch - 2ms/step\n",
            "Epoch 365/500\n",
            "3850/3850 - 6s - loss: 0.1039 - accuracy: 0.9611 - val_loss: 0.2239 - val_accuracy: 0.9114 - 6s/epoch - 1ms/step\n",
            "Epoch 366/500\n",
            "3850/3850 - 6s - loss: 0.1031 - accuracy: 0.9622 - val_loss: 0.0793 - val_accuracy: 0.9794 - 6s/epoch - 2ms/step\n",
            "Epoch 367/500\n",
            "3850/3850 - 6s - loss: 0.1056 - accuracy: 0.9608 - val_loss: 0.1038 - val_accuracy: 0.9673 - 6s/epoch - 1ms/step\n",
            "Epoch 368/500\n",
            "3850/3850 - 6s - loss: 0.1018 - accuracy: 0.9626 - val_loss: 0.2202 - val_accuracy: 0.9130 - 6s/epoch - 2ms/step\n",
            "Epoch 369/500\n",
            "3850/3850 - 6s - loss: 0.1020 - accuracy: 0.9630 - val_loss: 0.1706 - val_accuracy: 0.9355 - 6s/epoch - 1ms/step\n",
            "Epoch 370/500\n",
            "3850/3850 - 6s - loss: 0.1021 - accuracy: 0.9628 - val_loss: 0.1376 - val_accuracy: 0.9523 - 6s/epoch - 1ms/step\n",
            "Epoch 371/500\n",
            "3850/3850 - 6s - loss: 0.1012 - accuracy: 0.9638 - val_loss: 0.1149 - val_accuracy: 0.9628 - 6s/epoch - 1ms/step\n",
            "Epoch 372/500\n",
            "3850/3850 - 6s - loss: 0.1018 - accuracy: 0.9632 - val_loss: 0.1117 - val_accuracy: 0.9631 - 6s/epoch - 1ms/step\n",
            "Epoch 373/500\n",
            "3850/3850 - 6s - loss: 0.1025 - accuracy: 0.9620 - val_loss: 0.2495 - val_accuracy: 0.9067 - 6s/epoch - 1ms/step\n",
            "Epoch 374/500\n",
            "3850/3850 - 6s - loss: 0.1022 - accuracy: 0.9623 - val_loss: 0.1683 - val_accuracy: 0.9371 - 6s/epoch - 1ms/step\n",
            "Epoch 375/500\n",
            "3850/3850 - 6s - loss: 0.1025 - accuracy: 0.9625 - val_loss: 0.2534 - val_accuracy: 0.8990 - 6s/epoch - 1ms/step\n",
            "Epoch 376/500\n",
            "3850/3850 - 6s - loss: 0.1005 - accuracy: 0.9625 - val_loss: 0.1871 - val_accuracy: 0.9247 - 6s/epoch - 1ms/step\n",
            "Epoch 377/500\n",
            "3850/3850 - 6s - loss: 0.1015 - accuracy: 0.9627 - val_loss: 0.3375 - val_accuracy: 0.8675 - 6s/epoch - 2ms/step\n",
            "Epoch 378/500\n",
            "3850/3850 - 6s - loss: 0.1021 - accuracy: 0.9618 - val_loss: 0.1367 - val_accuracy: 0.9516 - 6s/epoch - 2ms/step\n",
            "Epoch 379/500\n",
            "3850/3850 - 6s - loss: 0.1029 - accuracy: 0.9620 - val_loss: 0.2261 - val_accuracy: 0.9123 - 6s/epoch - 1ms/step\n",
            "Epoch 380/500\n",
            "3850/3850 - 6s - loss: 0.1022 - accuracy: 0.9631 - val_loss: 0.0907 - val_accuracy: 0.9764 - 6s/epoch - 1ms/step\n",
            "Epoch 381/500\n",
            "3850/3850 - 6s - loss: 0.1018 - accuracy: 0.9620 - val_loss: 0.3014 - val_accuracy: 0.8766 - 6s/epoch - 1ms/step\n",
            "Epoch 382/500\n",
            "3850/3850 - 6s - loss: 0.1000 - accuracy: 0.9631 - val_loss: 0.1780 - val_accuracy: 0.9338 - 6s/epoch - 1ms/step\n",
            "Epoch 383/500\n",
            "3850/3850 - 6s - loss: 0.1013 - accuracy: 0.9636 - val_loss: 0.1939 - val_accuracy: 0.9252 - 6s/epoch - 1ms/step\n",
            "Epoch 384/500\n",
            "3850/3850 - 6s - loss: 0.1020 - accuracy: 0.9630 - val_loss: 0.1000 - val_accuracy: 0.9736 - 6s/epoch - 1ms/step\n",
            "Epoch 385/500\n",
            "3850/3850 - 6s - loss: 0.1022 - accuracy: 0.9623 - val_loss: 0.1554 - val_accuracy: 0.9430 - 6s/epoch - 1ms/step\n",
            "Epoch 386/500\n",
            "3850/3850 - 6s - loss: 0.1010 - accuracy: 0.9633 - val_loss: 0.1862 - val_accuracy: 0.9287 - 6s/epoch - 1ms/step\n",
            "Epoch 387/500\n",
            "3850/3850 - 6s - loss: 0.0992 - accuracy: 0.9646 - val_loss: 0.0762 - val_accuracy: 0.9804 - 6s/epoch - 1ms/step\n",
            "Epoch 388/500\n",
            "3850/3850 - 6s - loss: 0.1013 - accuracy: 0.9624 - val_loss: 0.0966 - val_accuracy: 0.9691 - 6s/epoch - 1ms/step\n",
            "Epoch 389/500\n",
            "3850/3850 - 6s - loss: 0.1000 - accuracy: 0.9631 - val_loss: 0.1140 - val_accuracy: 0.9656 - 6s/epoch - 1ms/step\n",
            "Epoch 390/500\n",
            "3850/3850 - 6s - loss: 0.1002 - accuracy: 0.9641 - val_loss: 0.1296 - val_accuracy: 0.9568 - 6s/epoch - 1ms/step\n",
            "Epoch 391/500\n",
            "3850/3850 - 6s - loss: 0.1011 - accuracy: 0.9619 - val_loss: 0.1555 - val_accuracy: 0.9430 - 6s/epoch - 2ms/step\n",
            "Epoch 392/500\n",
            "3850/3850 - 6s - loss: 0.1016 - accuracy: 0.9627 - val_loss: 0.1587 - val_accuracy: 0.9409 - 6s/epoch - 1ms/step\n",
            "Epoch 393/500\n",
            "3850/3850 - 6s - loss: 0.0995 - accuracy: 0.9636 - val_loss: 0.1295 - val_accuracy: 0.9565 - 6s/epoch - 1ms/step\n",
            "Epoch 394/500\n",
            "3850/3850 - 6s - loss: 0.1005 - accuracy: 0.9631 - val_loss: 0.1985 - val_accuracy: 0.9210 - 6s/epoch - 1ms/step\n",
            "Epoch 395/500\n",
            "3850/3850 - 6s - loss: 0.0981 - accuracy: 0.9639 - val_loss: 0.0480 - val_accuracy: 0.9876 - 6s/epoch - 1ms/step\n",
            "Epoch 396/500\n",
            "3850/3850 - 6s - loss: 0.0991 - accuracy: 0.9643 - val_loss: 0.1149 - val_accuracy: 0.9607 - 6s/epoch - 1ms/step\n",
            "Epoch 397/500\n",
            "3850/3850 - 6s - loss: 0.0990 - accuracy: 0.9637 - val_loss: 0.2300 - val_accuracy: 0.9093 - 6s/epoch - 1ms/step\n",
            "Epoch 398/500\n",
            "3850/3850 - 6s - loss: 0.1003 - accuracy: 0.9633 - val_loss: 0.2574 - val_accuracy: 0.9002 - 6s/epoch - 1ms/step\n",
            "Epoch 399/500\n",
            "3850/3850 - 6s - loss: 0.0986 - accuracy: 0.9637 - val_loss: 0.1985 - val_accuracy: 0.9212 - 6s/epoch - 2ms/step\n",
            "Epoch 400/500\n",
            "3850/3850 - 6s - loss: 0.0991 - accuracy: 0.9643 - val_loss: 0.1125 - val_accuracy: 0.9640 - 6s/epoch - 1ms/step\n",
            "Epoch 401/500\n",
            "3850/3850 - 6s - loss: 0.0974 - accuracy: 0.9644 - val_loss: 0.2503 - val_accuracy: 0.9007 - 6s/epoch - 1ms/step\n",
            "Epoch 402/500\n",
            "3850/3850 - 6s - loss: 0.0999 - accuracy: 0.9640 - val_loss: 0.0778 - val_accuracy: 0.9790 - 6s/epoch - 1ms/step\n",
            "Epoch 403/500\n",
            "3850/3850 - 6s - loss: 0.0964 - accuracy: 0.9651 - val_loss: 0.1170 - val_accuracy: 0.9624 - 6s/epoch - 2ms/step\n",
            "Epoch 404/500\n",
            "3850/3850 - 6s - loss: 0.0980 - accuracy: 0.9637 - val_loss: 0.1189 - val_accuracy: 0.9596 - 6s/epoch - 1ms/step\n",
            "Epoch 405/500\n",
            "3850/3850 - 6s - loss: 0.0965 - accuracy: 0.9647 - val_loss: 0.1868 - val_accuracy: 0.9336 - 6s/epoch - 1ms/step\n",
            "Epoch 406/500\n",
            "3850/3850 - 6s - loss: 0.0988 - accuracy: 0.9633 - val_loss: 0.1250 - val_accuracy: 0.9624 - 6s/epoch - 2ms/step\n",
            "Epoch 407/500\n",
            "3850/3850 - 6s - loss: 0.0979 - accuracy: 0.9639 - val_loss: 0.2615 - val_accuracy: 0.8948 - 6s/epoch - 1ms/step\n",
            "Epoch 408/500\n",
            "3850/3850 - 6s - loss: 0.0976 - accuracy: 0.9636 - val_loss: 0.1180 - val_accuracy: 0.9652 - 6s/epoch - 1ms/step\n",
            "Epoch 409/500\n",
            "3850/3850 - 6s - loss: 0.0956 - accuracy: 0.9647 - val_loss: 0.1474 - val_accuracy: 0.9462 - 6s/epoch - 1ms/step\n",
            "Epoch 410/500\n",
            "3850/3850 - 6s - loss: 0.0971 - accuracy: 0.9644 - val_loss: 0.1221 - val_accuracy: 0.9591 - 6s/epoch - 1ms/step\n",
            "Epoch 411/500\n",
            "3850/3850 - 6s - loss: 0.0966 - accuracy: 0.9648 - val_loss: 0.0919 - val_accuracy: 0.9771 - 6s/epoch - 1ms/step\n",
            "Epoch 412/500\n",
            "3850/3850 - 6s - loss: 0.0961 - accuracy: 0.9650 - val_loss: 0.2486 - val_accuracy: 0.9030 - 6s/epoch - 2ms/step\n",
            "Epoch 413/500\n",
            "3850/3850 - 6s - loss: 0.0958 - accuracy: 0.9645 - val_loss: 0.1582 - val_accuracy: 0.9397 - 6s/epoch - 1ms/step\n",
            "Epoch 414/500\n",
            "3850/3850 - 6s - loss: 0.0962 - accuracy: 0.9642 - val_loss: 0.1646 - val_accuracy: 0.9404 - 6s/epoch - 1ms/step\n",
            "Epoch 415/500\n",
            "3850/3850 - 6s - loss: 0.0945 - accuracy: 0.9655 - val_loss: 0.1113 - val_accuracy: 0.9663 - 6s/epoch - 1ms/step\n",
            "Epoch 416/500\n",
            "3850/3850 - 6s - loss: 0.0960 - accuracy: 0.9639 - val_loss: 0.1080 - val_accuracy: 0.9677 - 6s/epoch - 1ms/step\n",
            "Epoch 417/500\n",
            "3850/3850 - 6s - loss: 0.0937 - accuracy: 0.9648 - val_loss: 0.0958 - val_accuracy: 0.9689 - 6s/epoch - 1ms/step\n",
            "Epoch 418/500\n",
            "3850/3850 - 6s - loss: 0.0959 - accuracy: 0.9651 - val_loss: 0.1164 - val_accuracy: 0.9656 - 6s/epoch - 2ms/step\n",
            "Epoch 419/500\n",
            "3850/3850 - 6s - loss: 0.0943 - accuracy: 0.9654 - val_loss: 0.3246 - val_accuracy: 0.8665 - 6s/epoch - 1ms/step\n",
            "Epoch 420/500\n",
            "3850/3850 - 6s - loss: 0.0952 - accuracy: 0.9654 - val_loss: 0.0994 - val_accuracy: 0.9682 - 6s/epoch - 1ms/step\n",
            "Epoch 421/500\n",
            "3850/3850 - 6s - loss: 0.0959 - accuracy: 0.9648 - val_loss: 0.1080 - val_accuracy: 0.9696 - 6s/epoch - 1ms/step\n",
            "Epoch 422/500\n",
            "3850/3850 - 6s - loss: 0.0937 - accuracy: 0.9655 - val_loss: 0.1019 - val_accuracy: 0.9670 - 6s/epoch - 1ms/step\n",
            "Epoch 423/500\n",
            "3850/3850 - 6s - loss: 0.0943 - accuracy: 0.9664 - val_loss: 0.1498 - val_accuracy: 0.9476 - 6s/epoch - 1ms/step\n",
            "Epoch 424/500\n",
            "3850/3850 - 6s - loss: 0.0930 - accuracy: 0.9663 - val_loss: 0.1059 - val_accuracy: 0.9680 - 6s/epoch - 1ms/step\n",
            "Epoch 425/500\n",
            "3850/3850 - 6s - loss: 0.0934 - accuracy: 0.9662 - val_loss: 0.2891 - val_accuracy: 0.8852 - 6s/epoch - 1ms/step\n",
            "Epoch 426/500\n",
            "3850/3850 - 6s - loss: 0.0931 - accuracy: 0.9664 - val_loss: 0.2308 - val_accuracy: 0.9098 - 6s/epoch - 1ms/step\n",
            "Epoch 427/500\n",
            "3850/3850 - 6s - loss: 0.0946 - accuracy: 0.9645 - val_loss: 0.1288 - val_accuracy: 0.9596 - 6s/epoch - 2ms/step\n",
            "Epoch 428/500\n",
            "3850/3850 - 6s - loss: 0.0954 - accuracy: 0.9646 - val_loss: 0.1141 - val_accuracy: 0.9677 - 6s/epoch - 2ms/step\n",
            "Epoch 429/500\n",
            "3850/3850 - 6s - loss: 0.0915 - accuracy: 0.9667 - val_loss: 0.0966 - val_accuracy: 0.9734 - 6s/epoch - 1ms/step\n",
            "Epoch 430/500\n",
            "3850/3850 - 6s - loss: 0.0932 - accuracy: 0.9655 - val_loss: 0.2660 - val_accuracy: 0.8960 - 6s/epoch - 1ms/step\n",
            "Epoch 431/500\n",
            "3850/3850 - 6s - loss: 0.0937 - accuracy: 0.9652 - val_loss: 0.1121 - val_accuracy: 0.9694 - 6s/epoch - 1ms/step\n",
            "Epoch 432/500\n",
            "3850/3850 - 6s - loss: 0.0929 - accuracy: 0.9666 - val_loss: 0.0979 - val_accuracy: 0.9724 - 6s/epoch - 1ms/step\n",
            "Epoch 433/500\n",
            "3850/3850 - 6s - loss: 0.0935 - accuracy: 0.9661 - val_loss: 0.0708 - val_accuracy: 0.9846 - 6s/epoch - 1ms/step\n",
            "Epoch 434/500\n",
            "3850/3850 - 6s - loss: 0.0922 - accuracy: 0.9651 - val_loss: 0.1563 - val_accuracy: 0.9465 - 6s/epoch - 1ms/step\n",
            "Epoch 435/500\n",
            "3850/3850 - 6s - loss: 0.0919 - accuracy: 0.9671 - val_loss: 0.1575 - val_accuracy: 0.9425 - 6s/epoch - 2ms/step\n",
            "Epoch 436/500\n",
            "3850/3850 - 6s - loss: 0.0909 - accuracy: 0.9661 - val_loss: 0.0857 - val_accuracy: 0.9778 - 6s/epoch - 1ms/step\n",
            "Epoch 437/500\n",
            "3850/3850 - 6s - loss: 0.0926 - accuracy: 0.9666 - val_loss: 0.1823 - val_accuracy: 0.9331 - 6s/epoch - 1ms/step\n",
            "Epoch 438/500\n",
            "3850/3850 - 6s - loss: 0.0910 - accuracy: 0.9670 - val_loss: 0.1401 - val_accuracy: 0.9558 - 6s/epoch - 2ms/step\n",
            "Epoch 439/500\n",
            "3850/3850 - 6s - loss: 0.0925 - accuracy: 0.9657 - val_loss: 0.2597 - val_accuracy: 0.8986 - 6s/epoch - 2ms/step\n",
            "Epoch 440/500\n",
            "3850/3850 - 6s - loss: 0.0924 - accuracy: 0.9652 - val_loss: 0.1049 - val_accuracy: 0.9680 - 6s/epoch - 1ms/step\n",
            "Epoch 441/500\n",
            "3850/3850 - 6s - loss: 0.0904 - accuracy: 0.9670 - val_loss: 0.1875 - val_accuracy: 0.9336 - 6s/epoch - 1ms/step\n",
            "Epoch 442/500\n",
            "3850/3850 - 6s - loss: 0.0920 - accuracy: 0.9662 - val_loss: 0.0581 - val_accuracy: 0.9860 - 6s/epoch - 2ms/step\n",
            "Epoch 443/500\n",
            "3850/3850 - 6s - loss: 0.0934 - accuracy: 0.9656 - val_loss: 0.2176 - val_accuracy: 0.9147 - 6s/epoch - 2ms/step\n",
            "Epoch 444/500\n",
            "3850/3850 - 6s - loss: 0.0907 - accuracy: 0.9672 - val_loss: 0.1766 - val_accuracy: 0.9348 - 6s/epoch - 1ms/step\n",
            "Epoch 445/500\n",
            "3850/3850 - 6s - loss: 0.0926 - accuracy: 0.9663 - val_loss: 0.1074 - val_accuracy: 0.9722 - 6s/epoch - 1ms/step\n",
            "Epoch 446/500\n",
            "3850/3850 - 6s - loss: 0.0908 - accuracy: 0.9668 - val_loss: 0.0800 - val_accuracy: 0.9778 - 6s/epoch - 1ms/step\n",
            "Epoch 447/500\n",
            "3850/3850 - 6s - loss: 0.0904 - accuracy: 0.9672 - val_loss: 0.1453 - val_accuracy: 0.9504 - 6s/epoch - 1ms/step\n",
            "Epoch 448/500\n",
            "3850/3850 - 6s - loss: 0.0910 - accuracy: 0.9664 - val_loss: 0.1667 - val_accuracy: 0.9369 - 6s/epoch - 2ms/step\n",
            "Epoch 449/500\n",
            "3850/3850 - 6s - loss: 0.0894 - accuracy: 0.9678 - val_loss: 0.0792 - val_accuracy: 0.9813 - 6s/epoch - 1ms/step\n",
            "Epoch 450/500\n",
            "3850/3850 - 6s - loss: 0.0931 - accuracy: 0.9658 - val_loss: 0.0741 - val_accuracy: 0.9808 - 6s/epoch - 1ms/step\n",
            "Epoch 451/500\n",
            "3850/3850 - 6s - loss: 0.0911 - accuracy: 0.9668 - val_loss: 0.1575 - val_accuracy: 0.9460 - 6s/epoch - 1ms/step\n",
            "Epoch 452/500\n",
            "3850/3850 - 6s - loss: 0.0910 - accuracy: 0.9652 - val_loss: 0.3493 - val_accuracy: 0.8637 - 6s/epoch - 2ms/step\n",
            "Epoch 453/500\n",
            "3850/3850 - 6s - loss: 0.0898 - accuracy: 0.9668 - val_loss: 0.2319 - val_accuracy: 0.9105 - 6s/epoch - 2ms/step\n",
            "Epoch 454/500\n",
            "3850/3850 - 6s - loss: 0.0907 - accuracy: 0.9660 - val_loss: 0.2650 - val_accuracy: 0.8943 - 6s/epoch - 1ms/step\n",
            "Epoch 455/500\n",
            "3850/3850 - 6s - loss: 0.0894 - accuracy: 0.9676 - val_loss: 0.1828 - val_accuracy: 0.9315 - 6s/epoch - 1ms/step\n",
            "Epoch 456/500\n",
            "3850/3850 - 6s - loss: 0.0903 - accuracy: 0.9672 - val_loss: 0.1098 - val_accuracy: 0.9705 - 6s/epoch - 1ms/step\n",
            "Epoch 457/500\n",
            "3850/3850 - 6s - loss: 0.0886 - accuracy: 0.9678 - val_loss: 0.1432 - val_accuracy: 0.9584 - 6s/epoch - 2ms/step\n",
            "Epoch 458/500\n",
            "3850/3850 - 6s - loss: 0.0907 - accuracy: 0.9677 - val_loss: 0.0698 - val_accuracy: 0.9827 - 6s/epoch - 1ms/step\n",
            "Epoch 459/500\n",
            "3850/3850 - 6s - loss: 0.0889 - accuracy: 0.9670 - val_loss: 0.1027 - val_accuracy: 0.9682 - 6s/epoch - 1ms/step\n",
            "Epoch 460/500\n",
            "3850/3850 - 6s - loss: 0.0918 - accuracy: 0.9663 - val_loss: 0.1887 - val_accuracy: 0.9282 - 6s/epoch - 2ms/step\n",
            "Epoch 461/500\n",
            "3850/3850 - 6s - loss: 0.0888 - accuracy: 0.9672 - val_loss: 0.2136 - val_accuracy: 0.9175 - 6s/epoch - 1ms/step\n",
            "Epoch 462/500\n",
            "3850/3850 - 6s - loss: 0.0897 - accuracy: 0.9670 - val_loss: 0.0917 - val_accuracy: 0.9745 - 6s/epoch - 1ms/step\n",
            "Epoch 463/500\n",
            "3850/3850 - 6s - loss: 0.0897 - accuracy: 0.9669 - val_loss: 0.0824 - val_accuracy: 0.9785 - 6s/epoch - 2ms/step\n",
            "Epoch 464/500\n",
            "3850/3850 - 6s - loss: 0.0891 - accuracy: 0.9671 - val_loss: 0.0523 - val_accuracy: 0.9869 - 6s/epoch - 2ms/step\n",
            "Epoch 465/500\n",
            "3850/3850 - 6s - loss: 0.0894 - accuracy: 0.9671 - val_loss: 0.1914 - val_accuracy: 0.9275 - 6s/epoch - 2ms/step\n",
            "Epoch 466/500\n",
            "3850/3850 - 6s - loss: 0.0890 - accuracy: 0.9677 - val_loss: 0.0797 - val_accuracy: 0.9806 - 6s/epoch - 2ms/step\n",
            "Epoch 467/500\n",
            "3850/3850 - 6s - loss: 0.0887 - accuracy: 0.9670 - val_loss: 0.1610 - val_accuracy: 0.9413 - 6s/epoch - 1ms/step\n",
            "Epoch 468/500\n",
            "3850/3850 - 6s - loss: 0.0896 - accuracy: 0.9671 - val_loss: 0.0964 - val_accuracy: 0.9729 - 6s/epoch - 1ms/step\n",
            "Epoch 469/500\n",
            "3850/3850 - 6s - loss: 0.0877 - accuracy: 0.9685 - val_loss: 0.0965 - val_accuracy: 0.9769 - 6s/epoch - 1ms/step\n",
            "Epoch 470/500\n",
            "3850/3850 - 6s - loss: 0.0895 - accuracy: 0.9672 - val_loss: 0.3647 - val_accuracy: 0.8579 - 6s/epoch - 1ms/step\n",
            "Epoch 471/500\n",
            "3850/3850 - 6s - loss: 0.0901 - accuracy: 0.9663 - val_loss: 0.4976 - val_accuracy: 0.8188 - 6s/epoch - 1ms/step\n",
            "Epoch 472/500\n",
            "3850/3850 - 6s - loss: 0.0884 - accuracy: 0.9678 - val_loss: 0.0837 - val_accuracy: 0.9764 - 6s/epoch - 1ms/step\n",
            "Epoch 473/500\n",
            "3850/3850 - 6s - loss: 0.0893 - accuracy: 0.9671 - val_loss: 0.2538 - val_accuracy: 0.9042 - 6s/epoch - 2ms/step\n",
            "Epoch 474/500\n",
            "3850/3850 - 6s - loss: 0.0881 - accuracy: 0.9675 - val_loss: 0.1709 - val_accuracy: 0.9353 - 6s/epoch - 1ms/step\n",
            "Epoch 475/500\n",
            "3850/3850 - 6s - loss: 0.0882 - accuracy: 0.9671 - val_loss: 0.2578 - val_accuracy: 0.8974 - 6s/epoch - 1ms/step\n",
            "Epoch 476/500\n",
            "3850/3850 - 6s - loss: 0.0878 - accuracy: 0.9671 - val_loss: 0.1333 - val_accuracy: 0.9563 - 6s/epoch - 2ms/step\n",
            "Epoch 477/500\n",
            "3850/3850 - 6s - loss: 0.0879 - accuracy: 0.9675 - val_loss: 0.1158 - val_accuracy: 0.9610 - 6s/epoch - 2ms/step\n",
            "Epoch 478/500\n",
            "3850/3850 - 6s - loss: 0.0879 - accuracy: 0.9681 - val_loss: 0.1184 - val_accuracy: 0.9633 - 6s/epoch - 1ms/step\n",
            "Epoch 479/500\n",
            "3850/3850 - 6s - loss: 0.0889 - accuracy: 0.9666 - val_loss: 0.2117 - val_accuracy: 0.9194 - 6s/epoch - 1ms/step\n",
            "Epoch 480/500\n",
            "3850/3850 - 6s - loss: 0.0872 - accuracy: 0.9676 - val_loss: 0.1611 - val_accuracy: 0.9420 - 6s/epoch - 2ms/step\n",
            "Epoch 481/500\n",
            "3850/3850 - 6s - loss: 0.0866 - accuracy: 0.9687 - val_loss: 0.1327 - val_accuracy: 0.9540 - 6s/epoch - 1ms/step\n",
            "Epoch 482/500\n",
            "3850/3850 - 6s - loss: 0.0885 - accuracy: 0.9671 - val_loss: 0.1048 - val_accuracy: 0.9719 - 6s/epoch - 1ms/step\n",
            "Epoch 483/500\n",
            "3850/3850 - 6s - loss: 0.0888 - accuracy: 0.9670 - val_loss: 0.2720 - val_accuracy: 0.8962 - 6s/epoch - 1ms/step\n",
            "Epoch 484/500\n",
            "3850/3850 - 6s - loss: 0.0876 - accuracy: 0.9674 - val_loss: 0.1261 - val_accuracy: 0.9631 - 6s/epoch - 1ms/step\n",
            "Epoch 485/500\n",
            "3850/3850 - 6s - loss: 0.0862 - accuracy: 0.9685 - val_loss: 0.1016 - val_accuracy: 0.9734 - 6s/epoch - 1ms/step\n",
            "Epoch 486/500\n",
            "3850/3850 - 6s - loss: 0.0878 - accuracy: 0.9675 - val_loss: 0.0673 - val_accuracy: 0.9818 - 6s/epoch - 1ms/step\n",
            "Epoch 487/500\n",
            "3850/3850 - 6s - loss: 0.0866 - accuracy: 0.9689 - val_loss: 0.2363 - val_accuracy: 0.9081 - 6s/epoch - 2ms/step\n",
            "Epoch 488/500\n",
            "3850/3850 - 6s - loss: 0.0861 - accuracy: 0.9680 - val_loss: 0.0932 - val_accuracy: 0.9719 - 6s/epoch - 1ms/step\n",
            "Epoch 489/500\n",
            "3850/3850 - 6s - loss: 0.0863 - accuracy: 0.9671 - val_loss: 0.0848 - val_accuracy: 0.9773 - 6s/epoch - 1ms/step\n",
            "Epoch 490/500\n",
            "3850/3850 - 6s - loss: 0.0864 - accuracy: 0.9673 - val_loss: 0.2247 - val_accuracy: 0.9123 - 6s/epoch - 1ms/step\n",
            "Epoch 491/500\n",
            "3850/3850 - 6s - loss: 0.0860 - accuracy: 0.9685 - val_loss: 0.0897 - val_accuracy: 0.9790 - 6s/epoch - 1ms/step\n",
            "Epoch 492/500\n",
            "3850/3850 - 6s - loss: 0.0861 - accuracy: 0.9680 - val_loss: 0.1848 - val_accuracy: 0.9320 - 6s/epoch - 1ms/step\n",
            "Epoch 493/500\n",
            "3850/3850 - 6s - loss: 0.0872 - accuracy: 0.9688 - val_loss: 0.2442 - val_accuracy: 0.9039 - 6s/epoch - 1ms/step\n",
            "Epoch 494/500\n",
            "3850/3850 - 6s - loss: 0.0864 - accuracy: 0.9683 - val_loss: 0.0943 - val_accuracy: 0.9722 - 6s/epoch - 2ms/step\n",
            "Epoch 495/500\n",
            "3850/3850 - 6s - loss: 0.0877 - accuracy: 0.9677 - val_loss: 0.1372 - val_accuracy: 0.9568 - 6s/epoch - 1ms/step\n",
            "Epoch 496/500\n",
            "3850/3850 - 6s - loss: 0.0869 - accuracy: 0.9678 - val_loss: 0.1083 - val_accuracy: 0.9694 - 6s/epoch - 1ms/step\n",
            "Epoch 497/500\n",
            "3850/3850 - 6s - loss: 0.0858 - accuracy: 0.9679 - val_loss: 0.0999 - val_accuracy: 0.9719 - 6s/epoch - 2ms/step\n",
            "Epoch 498/500\n",
            "3850/3850 - 6s - loss: 0.0870 - accuracy: 0.9686 - val_loss: 0.1279 - val_accuracy: 0.9593 - 6s/epoch - 1ms/step\n",
            "Epoch 499/500\n",
            "3850/3850 - 6s - loss: 0.0862 - accuracy: 0.9676 - val_loss: 0.1659 - val_accuracy: 0.9425 - 6s/epoch - 2ms/step\n",
            "Epoch 500/500\n",
            "3850/3850 - 6s - loss: 0.0858 - accuracy: 0.9676 - val_loss: 0.1260 - val_accuracy: 0.9589 - 6s/epoch - 1ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1d8ed83350>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# for spatial not duplicate \n",
        "model.fit(\n",
        "      x=scaled_samples_withoutzero\n",
        "    , y=label_withoutzero - 1\n",
        "    , validation_split=0.1\n",
        "    , batch_size=10\n",
        "    , epochs=500\n",
        "    , verbose=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "summary \n",
        "acc 94.5 at epoch 200\n",
        "acc 96.5 at 500"
      ],
      "metadata": {
        "id": "JYtThIc9fmpB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmYOwAjdkdE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f96c178-3a4c-48a8-a8e8-32c758f44440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "3850/3850 - 6s - loss: 1.7473 - accuracy: 0.3825 - val_loss: 0.5638 - val_accuracy: 1.0000 - 6s/epoch - 2ms/step\n",
            "Epoch 2/500\n",
            "3850/3850 - 6s - loss: 1.1915 - accuracy: 0.5677 - val_loss: 0.4913 - val_accuracy: 0.8340 - 6s/epoch - 1ms/step\n",
            "Epoch 3/500\n",
            "3850/3850 - 6s - loss: 0.9978 - accuracy: 0.6053 - val_loss: 0.4329 - val_accuracy: 0.7833 - 6s/epoch - 1ms/step\n",
            "Epoch 4/500\n",
            "3850/3850 - 6s - loss: 0.9405 - accuracy: 0.6068 - val_loss: 0.4661 - val_accuracy: 0.7793 - 6s/epoch - 1ms/step\n",
            "Epoch 5/500\n",
            "3850/3850 - 6s - loss: 0.9036 - accuracy: 0.6227 - val_loss: 0.4393 - val_accuracy: 0.7679 - 6s/epoch - 1ms/step\n",
            "Epoch 6/500\n",
            "3850/3850 - 6s - loss: 0.8643 - accuracy: 0.6515 - val_loss: 0.4212 - val_accuracy: 0.7803 - 6s/epoch - 2ms/step\n",
            "Epoch 7/500\n",
            "3850/3850 - 6s - loss: 0.8178 - accuracy: 0.6782 - val_loss: 0.4287 - val_accuracy: 0.7849 - 6s/epoch - 1ms/step\n",
            "Epoch 8/500\n",
            "3850/3850 - 6s - loss: 0.7672 - accuracy: 0.6898 - val_loss: 0.3847 - val_accuracy: 0.7943 - 6s/epoch - 2ms/step\n",
            "Epoch 9/500\n",
            "3850/3850 - 6s - loss: 0.7238 - accuracy: 0.7116 - val_loss: 0.3951 - val_accuracy: 0.8109 - 6s/epoch - 1ms/step\n",
            "Epoch 10/500\n",
            "3850/3850 - 6s - loss: 0.6914 - accuracy: 0.7175 - val_loss: 0.4475 - val_accuracy: 0.7985 - 6s/epoch - 1ms/step\n",
            "Epoch 11/500\n",
            "3850/3850 - 7s - loss: 0.6715 - accuracy: 0.7202 - val_loss: 0.4470 - val_accuracy: 0.7777 - 7s/epoch - 2ms/step\n",
            "Epoch 12/500\n",
            "3850/3850 - 6s - loss: 0.6584 - accuracy: 0.7209 - val_loss: 0.3843 - val_accuracy: 0.8146 - 6s/epoch - 1ms/step\n",
            "Epoch 13/500\n",
            "3850/3850 - 6s - loss: 0.6494 - accuracy: 0.7220 - val_loss: 0.4151 - val_accuracy: 0.8001 - 6s/epoch - 1ms/step\n",
            "Epoch 14/500\n",
            "3850/3850 - 6s - loss: 0.6410 - accuracy: 0.7239 - val_loss: 0.3825 - val_accuracy: 0.8039 - 6s/epoch - 1ms/step\n",
            "Epoch 15/500\n",
            "3850/3850 - 6s - loss: 0.6338 - accuracy: 0.7264 - val_loss: 0.3664 - val_accuracy: 0.8240 - 6s/epoch - 1ms/step\n",
            "Epoch 16/500\n",
            "3850/3850 - 6s - loss: 0.6281 - accuracy: 0.7269 - val_loss: 0.3943 - val_accuracy: 0.8118 - 6s/epoch - 2ms/step\n",
            "Epoch 17/500\n",
            "3850/3850 - 6s - loss: 0.6225 - accuracy: 0.7286 - val_loss: 0.4162 - val_accuracy: 0.8121 - 6s/epoch - 2ms/step\n",
            "Epoch 18/500\n",
            "3850/3850 - 7s - loss: 0.6171 - accuracy: 0.7292 - val_loss: 0.3695 - val_accuracy: 0.8237 - 7s/epoch - 2ms/step\n",
            "Epoch 19/500\n",
            "3850/3850 - 6s - loss: 0.6130 - accuracy: 0.7307 - val_loss: 0.3525 - val_accuracy: 0.8590 - 6s/epoch - 2ms/step\n",
            "Epoch 20/500\n",
            "3850/3850 - 6s - loss: 0.6088 - accuracy: 0.7325 - val_loss: 0.3241 - val_accuracy: 0.8558 - 6s/epoch - 1ms/step\n",
            "Epoch 21/500\n",
            "3850/3850 - 6s - loss: 0.6043 - accuracy: 0.7327 - val_loss: 0.3419 - val_accuracy: 0.8520 - 6s/epoch - 1ms/step\n",
            "Epoch 22/500\n",
            "3850/3850 - 6s - loss: 0.6002 - accuracy: 0.7358 - val_loss: 0.3614 - val_accuracy: 0.8263 - 6s/epoch - 2ms/step\n",
            "Epoch 23/500\n",
            "3850/3850 - 6s - loss: 0.5958 - accuracy: 0.7384 - val_loss: 0.3384 - val_accuracy: 0.8417 - 6s/epoch - 1ms/step\n",
            "Epoch 24/500\n",
            "3850/3850 - 6s - loss: 0.5917 - accuracy: 0.7391 - val_loss: 0.3929 - val_accuracy: 0.8228 - 6s/epoch - 2ms/step\n",
            "Epoch 25/500\n",
            "3850/3850 - 6s - loss: 0.5876 - accuracy: 0.7408 - val_loss: 0.3181 - val_accuracy: 0.8488 - 6s/epoch - 2ms/step\n",
            "Epoch 26/500\n",
            "3850/3850 - 6s - loss: 0.5843 - accuracy: 0.7422 - val_loss: 0.3322 - val_accuracy: 0.8689 - 6s/epoch - 2ms/step\n",
            "Epoch 27/500\n",
            "3850/3850 - 6s - loss: 0.5807 - accuracy: 0.7455 - val_loss: 0.3525 - val_accuracy: 0.8476 - 6s/epoch - 1ms/step\n",
            "Epoch 28/500\n",
            "3850/3850 - 6s - loss: 0.5771 - accuracy: 0.7476 - val_loss: 0.3581 - val_accuracy: 0.8357 - 6s/epoch - 2ms/step\n",
            "Epoch 29/500\n",
            "3850/3850 - 6s - loss: 0.5741 - accuracy: 0.7479 - val_loss: 0.3221 - val_accuracy: 0.8607 - 6s/epoch - 2ms/step\n",
            "Epoch 30/500\n",
            "3850/3850 - 6s - loss: 0.5706 - accuracy: 0.7495 - val_loss: 0.3644 - val_accuracy: 0.8275 - 6s/epoch - 2ms/step\n",
            "Epoch 31/500\n",
            "3850/3850 - 6s - loss: 0.5683 - accuracy: 0.7491 - val_loss: 0.2990 - val_accuracy: 0.8810 - 6s/epoch - 1ms/step\n",
            "Epoch 32/500\n",
            "3850/3850 - 6s - loss: 0.5652 - accuracy: 0.7498 - val_loss: 0.3226 - val_accuracy: 0.8387 - 6s/epoch - 1ms/step\n",
            "Epoch 33/500\n",
            "3850/3850 - 6s - loss: 0.5629 - accuracy: 0.7506 - val_loss: 0.3301 - val_accuracy: 0.8483 - 6s/epoch - 1ms/step\n",
            "Epoch 34/500\n",
            "3850/3850 - 6s - loss: 0.5599 - accuracy: 0.7525 - val_loss: 0.3147 - val_accuracy: 0.8803 - 6s/epoch - 1ms/step\n",
            "Epoch 35/500\n",
            "3850/3850 - 6s - loss: 0.5572 - accuracy: 0.7530 - val_loss: 0.3332 - val_accuracy: 0.8553 - 6s/epoch - 1ms/step\n",
            "Epoch 36/500\n",
            "3850/3850 - 6s - loss: 0.5546 - accuracy: 0.7527 - val_loss: 0.3230 - val_accuracy: 0.8509 - 6s/epoch - 1ms/step\n",
            "Epoch 37/500\n",
            "3850/3850 - 6s - loss: 0.5526 - accuracy: 0.7536 - val_loss: 0.3491 - val_accuracy: 0.8417 - 6s/epoch - 1ms/step\n",
            "Epoch 38/500\n",
            "3850/3850 - 6s - loss: 0.5501 - accuracy: 0.7559 - val_loss: 0.3033 - val_accuracy: 0.8742 - 6s/epoch - 2ms/step\n",
            "Epoch 39/500\n",
            "3850/3850 - 6s - loss: 0.5475 - accuracy: 0.7556 - val_loss: 0.3144 - val_accuracy: 0.8476 - 6s/epoch - 1ms/step\n",
            "Epoch 40/500\n",
            "3850/3850 - 6s - loss: 0.5451 - accuracy: 0.7567 - val_loss: 0.3063 - val_accuracy: 0.9191 - 6s/epoch - 2ms/step\n",
            "Epoch 41/500\n",
            "3850/3850 - 6s - loss: 0.5431 - accuracy: 0.7586 - val_loss: 0.3978 - val_accuracy: 0.8130 - 6s/epoch - 1ms/step\n",
            "Epoch 42/500\n",
            "3850/3850 - 6s - loss: 0.5409 - accuracy: 0.7601 - val_loss: 0.3210 - val_accuracy: 0.8791 - 6s/epoch - 2ms/step\n",
            "Epoch 43/500\n",
            "3850/3850 - 6s - loss: 0.5383 - accuracy: 0.7627 - val_loss: 0.3251 - val_accuracy: 0.8759 - 6s/epoch - 2ms/step\n",
            "Epoch 44/500\n",
            "3850/3850 - 6s - loss: 0.5368 - accuracy: 0.7623 - val_loss: 0.2956 - val_accuracy: 0.9056 - 6s/epoch - 1ms/step\n",
            "Epoch 45/500\n",
            "3850/3850 - 6s - loss: 0.5341 - accuracy: 0.7639 - val_loss: 0.2981 - val_accuracy: 0.8880 - 6s/epoch - 2ms/step\n",
            "Epoch 46/500\n",
            "3850/3850 - 6s - loss: 0.5326 - accuracy: 0.7654 - val_loss: 0.2859 - val_accuracy: 0.8948 - 6s/epoch - 1ms/step\n",
            "Epoch 47/500\n",
            "3850/3850 - 6s - loss: 0.5303 - accuracy: 0.7675 - val_loss: 0.2996 - val_accuracy: 0.8698 - 6s/epoch - 1ms/step\n",
            "Epoch 48/500\n",
            "3850/3850 - 6s - loss: 0.5281 - accuracy: 0.7696 - val_loss: 0.2762 - val_accuracy: 0.9144 - 6s/epoch - 2ms/step\n",
            "Epoch 49/500\n",
            "3850/3850 - 6s - loss: 0.5267 - accuracy: 0.7700 - val_loss: 0.3004 - val_accuracy: 0.8621 - 6s/epoch - 1ms/step\n",
            "Epoch 50/500\n",
            "3850/3850 - 6s - loss: 0.5253 - accuracy: 0.7709 - val_loss: 0.2533 - val_accuracy: 0.9114 - 6s/epoch - 2ms/step\n",
            "Epoch 51/500\n",
            "3850/3850 - 6s - loss: 0.5229 - accuracy: 0.7737 - val_loss: 0.2896 - val_accuracy: 0.8918 - 6s/epoch - 1ms/step\n",
            "Epoch 52/500\n",
            "3850/3850 - 6s - loss: 0.5209 - accuracy: 0.7734 - val_loss: 0.2567 - val_accuracy: 0.9301 - 6s/epoch - 1ms/step\n",
            "Epoch 53/500\n",
            "3850/3850 - 6s - loss: 0.5192 - accuracy: 0.7765 - val_loss: 0.2889 - val_accuracy: 0.8838 - 6s/epoch - 2ms/step\n",
            "Epoch 54/500\n",
            "3850/3850 - 6s - loss: 0.5170 - accuracy: 0.7765 - val_loss: 0.2527 - val_accuracy: 0.9065 - 6s/epoch - 1ms/step\n",
            "Epoch 55/500\n",
            "3850/3850 - 6s - loss: 0.5148 - accuracy: 0.7783 - val_loss: 0.2597 - val_accuracy: 0.9437 - 6s/epoch - 1ms/step\n",
            "Epoch 56/500\n",
            "3850/3850 - 6s - loss: 0.5136 - accuracy: 0.7809 - val_loss: 0.2944 - val_accuracy: 0.9030 - 6s/epoch - 1ms/step\n",
            "Epoch 57/500\n",
            "3850/3850 - 6s - loss: 0.5115 - accuracy: 0.7818 - val_loss: 0.2205 - val_accuracy: 0.9481 - 6s/epoch - 1ms/step\n",
            "Epoch 58/500\n",
            "3850/3850 - 6s - loss: 0.5098 - accuracy: 0.7837 - val_loss: 0.2953 - val_accuracy: 0.8899 - 6s/epoch - 2ms/step\n",
            "Epoch 59/500\n",
            "3850/3850 - 6s - loss: 0.5084 - accuracy: 0.7831 - val_loss: 0.2612 - val_accuracy: 0.9060 - 6s/epoch - 1ms/step\n",
            "Epoch 60/500\n",
            "3850/3850 - 6s - loss: 0.5070 - accuracy: 0.7855 - val_loss: 0.2914 - val_accuracy: 0.8934 - 6s/epoch - 2ms/step\n",
            "Epoch 61/500\n",
            "3850/3850 - 6s - loss: 0.5055 - accuracy: 0.7860 - val_loss: 0.2868 - val_accuracy: 0.8934 - 6s/epoch - 1ms/step\n",
            "Epoch 62/500\n",
            "3850/3850 - 6s - loss: 0.5042 - accuracy: 0.7867 - val_loss: 0.2642 - val_accuracy: 0.9504 - 6s/epoch - 1ms/step\n",
            "Epoch 63/500\n",
            "3850/3850 - 6s - loss: 0.5028 - accuracy: 0.7873 - val_loss: 0.2149 - val_accuracy: 0.9451 - 6s/epoch - 2ms/step\n",
            "Epoch 64/500\n",
            "3850/3850 - 6s - loss: 0.5010 - accuracy: 0.7885 - val_loss: 0.2116 - val_accuracy: 0.9717 - 6s/epoch - 2ms/step\n",
            "Epoch 65/500\n",
            "3850/3850 - 6s - loss: 0.5000 - accuracy: 0.7894 - val_loss: 0.3037 - val_accuracy: 0.8885 - 6s/epoch - 1ms/step\n",
            "Epoch 66/500\n",
            "3850/3850 - 6s - loss: 0.4988 - accuracy: 0.7913 - val_loss: 0.3763 - val_accuracy: 0.8553 - 6s/epoch - 1ms/step\n",
            "Epoch 67/500\n",
            "3850/3850 - 6s - loss: 0.4970 - accuracy: 0.7926 - val_loss: 0.2620 - val_accuracy: 0.9109 - 6s/epoch - 1ms/step\n",
            "Epoch 68/500\n",
            "3850/3850 - 6s - loss: 0.4958 - accuracy: 0.7920 - val_loss: 0.2711 - val_accuracy: 0.9413 - 6s/epoch - 2ms/step\n",
            "Epoch 69/500\n",
            "3850/3850 - 6s - loss: 0.4948 - accuracy: 0.7938 - val_loss: 0.2763 - val_accuracy: 0.8990 - 6s/epoch - 1ms/step\n",
            "Epoch 70/500\n",
            "3850/3850 - 6s - loss: 0.4934 - accuracy: 0.7945 - val_loss: 0.2860 - val_accuracy: 0.9007 - 6s/epoch - 2ms/step\n",
            "Epoch 71/500\n",
            "3850/3850 - 6s - loss: 0.4921 - accuracy: 0.7947 - val_loss: 0.2249 - val_accuracy: 0.9516 - 6s/epoch - 1ms/step\n",
            "Epoch 72/500\n",
            "3850/3850 - 6s - loss: 0.4907 - accuracy: 0.7946 - val_loss: 0.2647 - val_accuracy: 0.9201 - 6s/epoch - 1ms/step\n",
            "Epoch 73/500\n",
            "3850/3850 - 6s - loss: 0.4893 - accuracy: 0.7963 - val_loss: 0.2793 - val_accuracy: 0.8960 - 6s/epoch - 2ms/step\n",
            "Epoch 74/500\n",
            "3850/3850 - 6s - loss: 0.4886 - accuracy: 0.7977 - val_loss: 0.2252 - val_accuracy: 0.9362 - 6s/epoch - 1ms/step\n",
            "Epoch 75/500\n",
            "3850/3850 - 6s - loss: 0.4872 - accuracy: 0.7975 - val_loss: 0.2475 - val_accuracy: 0.9495 - 6s/epoch - 2ms/step\n",
            "Epoch 76/500\n",
            "3850/3850 - 6s - loss: 0.4858 - accuracy: 0.7969 - val_loss: 0.2089 - val_accuracy: 0.9504 - 6s/epoch - 2ms/step\n",
            "Epoch 77/500\n",
            "3850/3850 - 6s - loss: 0.4847 - accuracy: 0.7979 - val_loss: 0.2551 - val_accuracy: 0.9437 - 6s/epoch - 1ms/step\n",
            "Epoch 78/500\n",
            "3850/3850 - 6s - loss: 0.4833 - accuracy: 0.7983 - val_loss: 0.2656 - val_accuracy: 0.9334 - 6s/epoch - 1ms/step\n",
            "Epoch 79/500\n",
            "3850/3850 - 6s - loss: 0.4825 - accuracy: 0.8002 - val_loss: 0.2703 - val_accuracy: 0.9322 - 6s/epoch - 2ms/step\n",
            "Epoch 80/500\n",
            "3850/3850 - 6s - loss: 0.4815 - accuracy: 0.7992 - val_loss: 0.2361 - val_accuracy: 0.9455 - 6s/epoch - 1ms/step\n",
            "Epoch 81/500\n",
            "3850/3850 - 6s - loss: 0.4797 - accuracy: 0.8014 - val_loss: 0.2490 - val_accuracy: 0.9497 - 6s/epoch - 2ms/step\n",
            "Epoch 82/500\n",
            "3850/3850 - 6s - loss: 0.4786 - accuracy: 0.8019 - val_loss: 0.2304 - val_accuracy: 0.9631 - 6s/epoch - 2ms/step\n",
            "Epoch 83/500\n",
            "3850/3850 - 6s - loss: 0.4777 - accuracy: 0.8013 - val_loss: 0.2425 - val_accuracy: 0.9334 - 6s/epoch - 1ms/step\n",
            "Epoch 84/500\n",
            "3850/3850 - 6s - loss: 0.4759 - accuracy: 0.8031 - val_loss: 0.2797 - val_accuracy: 0.9163 - 6s/epoch - 1ms/step\n",
            "Epoch 85/500\n",
            "3850/3850 - 6s - loss: 0.4750 - accuracy: 0.8045 - val_loss: 0.3093 - val_accuracy: 0.9060 - 6s/epoch - 1ms/step\n",
            "Epoch 86/500\n",
            "3850/3850 - 6s - loss: 0.4733 - accuracy: 0.8048 - val_loss: 0.2632 - val_accuracy: 0.9406 - 6s/epoch - 2ms/step\n",
            "Epoch 87/500\n",
            "3850/3850 - 6s - loss: 0.4730 - accuracy: 0.8053 - val_loss: 0.2756 - val_accuracy: 0.9049 - 6s/epoch - 1ms/step\n",
            "Epoch 88/500\n",
            "3850/3850 - 6s - loss: 0.4716 - accuracy: 0.8047 - val_loss: 0.2814 - val_accuracy: 0.9310 - 6s/epoch - 2ms/step\n",
            "Epoch 89/500\n",
            "3850/3850 - 6s - loss: 0.4710 - accuracy: 0.8048 - val_loss: 0.2252 - val_accuracy: 0.9430 - 6s/epoch - 1ms/step\n",
            "Epoch 90/500\n",
            "3850/3850 - 6s - loss: 0.4692 - accuracy: 0.8055 - val_loss: 0.2670 - val_accuracy: 0.9327 - 6s/epoch - 2ms/step\n",
            "Epoch 91/500\n",
            "3850/3850 - 6s - loss: 0.4683 - accuracy: 0.8074 - val_loss: 0.2595 - val_accuracy: 0.9310 - 6s/epoch - 1ms/step\n",
            "Epoch 92/500\n",
            "3850/3850 - 6s - loss: 0.4673 - accuracy: 0.8068 - val_loss: 0.2101 - val_accuracy: 0.9542 - 6s/epoch - 2ms/step\n",
            "Epoch 93/500\n",
            "3850/3850 - 6s - loss: 0.4654 - accuracy: 0.8086 - val_loss: 0.2333 - val_accuracy: 0.9518 - 6s/epoch - 2ms/step\n",
            "Epoch 94/500\n",
            "3850/3850 - 6s - loss: 0.4643 - accuracy: 0.8069 - val_loss: 0.2297 - val_accuracy: 0.9327 - 6s/epoch - 2ms/step\n",
            "Epoch 95/500\n",
            "3850/3850 - 6s - loss: 0.4633 - accuracy: 0.8088 - val_loss: 0.2715 - val_accuracy: 0.9334 - 6s/epoch - 2ms/step\n",
            "Epoch 96/500\n",
            "3850/3850 - 6s - loss: 0.4628 - accuracy: 0.8089 - val_loss: 0.2837 - val_accuracy: 0.9285 - 6s/epoch - 2ms/step\n",
            "Epoch 97/500\n",
            "3850/3850 - 6s - loss: 0.4615 - accuracy: 0.8105 - val_loss: 0.2979 - val_accuracy: 0.9100 - 6s/epoch - 1ms/step\n",
            "Epoch 98/500\n",
            "3850/3850 - 6s - loss: 0.4606 - accuracy: 0.8098 - val_loss: 0.2206 - val_accuracy: 0.9467 - 6s/epoch - 2ms/step\n",
            "Epoch 99/500\n",
            "3850/3850 - 6s - loss: 0.4595 - accuracy: 0.8110 - val_loss: 0.1810 - val_accuracy: 0.9589 - 6s/epoch - 2ms/step\n",
            "Epoch 100/500\n",
            "3850/3850 - 6s - loss: 0.4575 - accuracy: 0.8127 - val_loss: 0.2939 - val_accuracy: 0.8899 - 6s/epoch - 2ms/step\n",
            "Epoch 101/500\n",
            "3850/3850 - 6s - loss: 0.4565 - accuracy: 0.8115 - val_loss: 0.2740 - val_accuracy: 0.9364 - 6s/epoch - 2ms/step\n",
            "Epoch 102/500\n",
            "3850/3850 - 6s - loss: 0.4549 - accuracy: 0.8125 - val_loss: 0.2029 - val_accuracy: 0.9565 - 6s/epoch - 2ms/step\n",
            "Epoch 103/500\n",
            "3850/3850 - 6s - loss: 0.4539 - accuracy: 0.8142 - val_loss: 0.2044 - val_accuracy: 0.9483 - 6s/epoch - 2ms/step\n",
            "Epoch 104/500\n",
            "3850/3850 - 6s - loss: 0.4526 - accuracy: 0.8139 - val_loss: 0.2940 - val_accuracy: 0.9203 - 6s/epoch - 2ms/step\n",
            "Epoch 105/500\n",
            "3850/3850 - 6s - loss: 0.4513 - accuracy: 0.8133 - val_loss: 0.2256 - val_accuracy: 0.9353 - 6s/epoch - 1ms/step\n",
            "Epoch 106/500\n",
            "3850/3850 - 6s - loss: 0.4508 - accuracy: 0.8138 - val_loss: 0.2230 - val_accuracy: 0.9525 - 6s/epoch - 1ms/step\n",
            "Epoch 107/500\n",
            "3850/3850 - 6s - loss: 0.4492 - accuracy: 0.8149 - val_loss: 0.3266 - val_accuracy: 0.8922 - 6s/epoch - 2ms/step\n",
            "Epoch 108/500\n",
            "3850/3850 - 6s - loss: 0.4483 - accuracy: 0.8164 - val_loss: 0.2775 - val_accuracy: 0.9201 - 6s/epoch - 2ms/step\n",
            "Epoch 109/500\n",
            "3850/3850 - 6s - loss: 0.4470 - accuracy: 0.8176 - val_loss: 0.3096 - val_accuracy: 0.9084 - 6s/epoch - 2ms/step\n",
            "Epoch 110/500\n",
            "3850/3850 - 6s - loss: 0.4455 - accuracy: 0.8176 - val_loss: 0.2415 - val_accuracy: 0.9430 - 6s/epoch - 2ms/step\n",
            "Epoch 111/500\n",
            "3850/3850 - 6s - loss: 0.4437 - accuracy: 0.8185 - val_loss: 0.2087 - val_accuracy: 0.9500 - 6s/epoch - 1ms/step\n",
            "Epoch 112/500\n",
            "3850/3850 - 6s - loss: 0.4435 - accuracy: 0.8198 - val_loss: 0.2860 - val_accuracy: 0.9224 - 6s/epoch - 1ms/step\n",
            "Epoch 113/500\n",
            "3850/3850 - 6s - loss: 0.4415 - accuracy: 0.8183 - val_loss: 0.2989 - val_accuracy: 0.9259 - 6s/epoch - 1ms/step\n",
            "Epoch 114/500\n",
            "3850/3850 - 6s - loss: 0.4392 - accuracy: 0.8207 - val_loss: 0.2014 - val_accuracy: 0.9656 - 6s/epoch - 2ms/step\n",
            "Epoch 115/500\n",
            "3850/3850 - 6s - loss: 0.4381 - accuracy: 0.8219 - val_loss: 0.2564 - val_accuracy: 0.9264 - 6s/epoch - 1ms/step\n",
            "Epoch 116/500\n",
            "3850/3850 - 6s - loss: 0.4371 - accuracy: 0.8225 - val_loss: 0.2390 - val_accuracy: 0.9514 - 6s/epoch - 1ms/step\n",
            "Epoch 117/500\n",
            "3850/3850 - 6s - loss: 0.4355 - accuracy: 0.8229 - val_loss: 0.2263 - val_accuracy: 0.9376 - 6s/epoch - 1ms/step\n",
            "Epoch 118/500\n",
            "3850/3850 - 6s - loss: 0.4339 - accuracy: 0.8234 - val_loss: 0.2345 - val_accuracy: 0.9285 - 6s/epoch - 1ms/step\n",
            "Epoch 119/500\n",
            "3850/3850 - 6s - loss: 0.4327 - accuracy: 0.8245 - val_loss: 0.2146 - val_accuracy: 0.9390 - 6s/epoch - 1ms/step\n",
            "Epoch 120/500\n",
            "3850/3850 - 6s - loss: 0.4312 - accuracy: 0.8241 - val_loss: 0.3087 - val_accuracy: 0.9116 - 6s/epoch - 1ms/step\n",
            "Epoch 121/500\n",
            "3850/3850 - 6s - loss: 0.4298 - accuracy: 0.8257 - val_loss: 0.1637 - val_accuracy: 0.9687 - 6s/epoch - 1ms/step\n",
            "Epoch 122/500\n",
            "3850/3850 - 6s - loss: 0.4285 - accuracy: 0.8247 - val_loss: 0.1913 - val_accuracy: 0.9589 - 6s/epoch - 1ms/step\n",
            "Epoch 123/500\n",
            "3850/3850 - 6s - loss: 0.4268 - accuracy: 0.8264 - val_loss: 0.2270 - val_accuracy: 0.9383 - 6s/epoch - 1ms/step\n",
            "Epoch 124/500\n",
            "3850/3850 - 6s - loss: 0.4254 - accuracy: 0.8277 - val_loss: 0.2073 - val_accuracy: 0.9544 - 6s/epoch - 2ms/step\n",
            "Epoch 125/500\n",
            "3850/3850 - 6s - loss: 0.4234 - accuracy: 0.8295 - val_loss: 0.1744 - val_accuracy: 0.9614 - 6s/epoch - 1ms/step\n",
            "Epoch 126/500\n",
            "3850/3850 - 6s - loss: 0.4220 - accuracy: 0.8293 - val_loss: 0.2271 - val_accuracy: 0.9542 - 6s/epoch - 1ms/step\n",
            "Epoch 127/500\n",
            "3850/3850 - 6s - loss: 0.4200 - accuracy: 0.8308 - val_loss: 0.3131 - val_accuracy: 0.9035 - 6s/epoch - 1ms/step\n",
            "Epoch 128/500\n",
            "3850/3850 - 6s - loss: 0.4189 - accuracy: 0.8308 - val_loss: 0.1825 - val_accuracy: 0.9535 - 6s/epoch - 1ms/step\n",
            "Epoch 129/500\n",
            "3850/3850 - 6s - loss: 0.4170 - accuracy: 0.8324 - val_loss: 0.1666 - val_accuracy: 0.9645 - 6s/epoch - 1ms/step\n",
            "Epoch 130/500\n",
            "3850/3850 - 6s - loss: 0.4145 - accuracy: 0.8344 - val_loss: 0.2375 - val_accuracy: 0.9381 - 6s/epoch - 2ms/step\n",
            "Epoch 131/500\n",
            "3850/3850 - 6s - loss: 0.4132 - accuracy: 0.8340 - val_loss: 0.1619 - val_accuracy: 0.9687 - 6s/epoch - 1ms/step\n",
            "Epoch 132/500\n",
            "3850/3850 - 6s - loss: 0.4116 - accuracy: 0.8347 - val_loss: 0.2133 - val_accuracy: 0.9388 - 6s/epoch - 2ms/step\n",
            "Epoch 133/500\n",
            "3850/3850 - 6s - loss: 0.4108 - accuracy: 0.8363 - val_loss: 0.1505 - val_accuracy: 0.9727 - 6s/epoch - 2ms/step\n",
            "Epoch 134/500\n",
            "3850/3850 - 6s - loss: 0.4078 - accuracy: 0.8367 - val_loss: 0.2039 - val_accuracy: 0.9549 - 6s/epoch - 2ms/step\n",
            "Epoch 135/500\n",
            "3850/3850 - 6s - loss: 0.4061 - accuracy: 0.8376 - val_loss: 0.2535 - val_accuracy: 0.9289 - 6s/epoch - 2ms/step\n",
            "Epoch 136/500\n",
            "3850/3850 - 6s - loss: 0.4046 - accuracy: 0.8387 - val_loss: 0.2514 - val_accuracy: 0.9343 - 6s/epoch - 2ms/step\n",
            "Epoch 137/500\n",
            "3850/3850 - 6s - loss: 0.4037 - accuracy: 0.8387 - val_loss: 0.1872 - val_accuracy: 0.9614 - 6s/epoch - 2ms/step\n",
            "Epoch 138/500\n",
            "3850/3850 - 6s - loss: 0.4007 - accuracy: 0.8410 - val_loss: 0.2679 - val_accuracy: 0.9114 - 6s/epoch - 2ms/step\n",
            "Epoch 139/500\n",
            "3850/3850 - 6s - loss: 0.3989 - accuracy: 0.8414 - val_loss: 0.2677 - val_accuracy: 0.9327 - 6s/epoch - 1ms/step\n",
            "Epoch 140/500\n",
            "3850/3850 - 6s - loss: 0.3971 - accuracy: 0.8429 - val_loss: 0.1991 - val_accuracy: 0.9516 - 6s/epoch - 2ms/step\n",
            "Epoch 141/500\n",
            "3850/3850 - 6s - loss: 0.3952 - accuracy: 0.8437 - val_loss: 0.2179 - val_accuracy: 0.9437 - 6s/epoch - 2ms/step\n",
            "Epoch 142/500\n",
            "3850/3850 - 6s - loss: 0.3934 - accuracy: 0.8438 - val_loss: 0.3608 - val_accuracy: 0.8932 - 6s/epoch - 1ms/step\n",
            "Epoch 143/500\n",
            "3850/3850 - 6s - loss: 0.3915 - accuracy: 0.8454 - val_loss: 0.2980 - val_accuracy: 0.9114 - 6s/epoch - 1ms/step\n",
            "Epoch 144/500\n",
            "3850/3850 - 6s - loss: 0.3901 - accuracy: 0.8476 - val_loss: 0.2071 - val_accuracy: 0.9523 - 6s/epoch - 1ms/step\n",
            "Epoch 145/500\n",
            "3850/3850 - 6s - loss: 0.3881 - accuracy: 0.8465 - val_loss: 0.1862 - val_accuracy: 0.9624 - 6s/epoch - 1ms/step\n",
            "Epoch 146/500\n",
            "3850/3850 - 6s - loss: 0.3853 - accuracy: 0.8484 - val_loss: 0.2628 - val_accuracy: 0.9289 - 6s/epoch - 1ms/step\n",
            "Epoch 147/500\n",
            "3850/3850 - 6s - loss: 0.3833 - accuracy: 0.8495 - val_loss: 0.1744 - val_accuracy: 0.9680 - 6s/epoch - 1ms/step\n",
            "Epoch 148/500\n",
            "3850/3850 - 6s - loss: 0.3813 - accuracy: 0.8499 - val_loss: 0.1527 - val_accuracy: 0.9717 - 6s/epoch - 1ms/step\n",
            "Epoch 149/500\n",
            "3850/3850 - 6s - loss: 0.3796 - accuracy: 0.8503 - val_loss: 0.1351 - val_accuracy: 0.9790 - 6s/epoch - 2ms/step\n",
            "Epoch 150/500\n",
            "3850/3850 - 6s - loss: 0.3772 - accuracy: 0.8516 - val_loss: 0.4192 - val_accuracy: 0.8509 - 6s/epoch - 1ms/step\n",
            "Epoch 151/500\n",
            "3850/3850 - 6s - loss: 0.3755 - accuracy: 0.8527 - val_loss: 0.1417 - val_accuracy: 0.9717 - 6s/epoch - 1ms/step\n",
            "Epoch 152/500\n",
            "3850/3850 - 6s - loss: 0.3733 - accuracy: 0.8535 - val_loss: 0.1775 - val_accuracy: 0.9605 - 6s/epoch - 2ms/step\n",
            "Epoch 153/500\n",
            "3850/3850 - 6s - loss: 0.3710 - accuracy: 0.8555 - val_loss: 0.2434 - val_accuracy: 0.9348 - 6s/epoch - 1ms/step\n",
            "Epoch 154/500\n",
            "3850/3850 - 6s - loss: 0.3692 - accuracy: 0.8558 - val_loss: 0.2082 - val_accuracy: 0.9411 - 6s/epoch - 2ms/step\n",
            "Epoch 155/500\n",
            "3850/3850 - 6s - loss: 0.3667 - accuracy: 0.8586 - val_loss: 0.2767 - val_accuracy: 0.9252 - 6s/epoch - 1ms/step\n",
            "Epoch 156/500\n",
            "3850/3850 - 6s - loss: 0.3644 - accuracy: 0.8604 - val_loss: 0.2453 - val_accuracy: 0.9423 - 6s/epoch - 1ms/step\n",
            "Epoch 157/500\n",
            "3850/3850 - 6s - loss: 0.3637 - accuracy: 0.8587 - val_loss: 0.2421 - val_accuracy: 0.9292 - 6s/epoch - 1ms/step\n",
            "Epoch 158/500\n",
            "3850/3850 - 6s - loss: 0.3612 - accuracy: 0.8607 - val_loss: 0.1423 - val_accuracy: 0.9684 - 6s/epoch - 1ms/step\n",
            "Epoch 159/500\n",
            "3850/3850 - 6s - loss: 0.3598 - accuracy: 0.8605 - val_loss: 0.1873 - val_accuracy: 0.9535 - 6s/epoch - 1ms/step\n",
            "Epoch 160/500\n",
            "3850/3850 - 6s - loss: 0.3577 - accuracy: 0.8623 - val_loss: 0.2738 - val_accuracy: 0.9313 - 6s/epoch - 1ms/step\n",
            "Epoch 161/500\n",
            "3850/3850 - 6s - loss: 0.3546 - accuracy: 0.8643 - val_loss: 0.1354 - val_accuracy: 0.9715 - 6s/epoch - 1ms/step\n",
            "Epoch 162/500\n",
            "3850/3850 - 6s - loss: 0.3533 - accuracy: 0.8637 - val_loss: 0.2607 - val_accuracy: 0.9348 - 6s/epoch - 1ms/step\n",
            "Epoch 163/500\n",
            "3850/3850 - 6s - loss: 0.3514 - accuracy: 0.8665 - val_loss: 0.1881 - val_accuracy: 0.9605 - 6s/epoch - 1ms/step\n",
            "Epoch 164/500\n",
            "3850/3850 - 6s - loss: 0.3490 - accuracy: 0.8664 - val_loss: 0.4344 - val_accuracy: 0.8532 - 6s/epoch - 1ms/step\n",
            "Epoch 165/500\n",
            "3850/3850 - 6s - loss: 0.3484 - accuracy: 0.8665 - val_loss: 0.1348 - val_accuracy: 0.9680 - 6s/epoch - 2ms/step\n",
            "Epoch 166/500\n",
            "3850/3850 - 6s - loss: 0.3454 - accuracy: 0.8688 - val_loss: 0.2123 - val_accuracy: 0.9500 - 6s/epoch - 1ms/step\n",
            "Epoch 167/500\n",
            "3850/3850 - 6s - loss: 0.3440 - accuracy: 0.8690 - val_loss: 0.2908 - val_accuracy: 0.9243 - 6s/epoch - 1ms/step\n",
            "Epoch 168/500\n",
            "3850/3850 - 6s - loss: 0.3431 - accuracy: 0.8692 - val_loss: 0.1610 - val_accuracy: 0.9537 - 6s/epoch - 2ms/step\n",
            "Epoch 169/500\n",
            "3850/3850 - 6s - loss: 0.3394 - accuracy: 0.8720 - val_loss: 0.2198 - val_accuracy: 0.9404 - 6s/epoch - 2ms/step\n",
            "Epoch 170/500\n",
            "3850/3850 - 6s - loss: 0.3371 - accuracy: 0.8716 - val_loss: 0.1919 - val_accuracy: 0.9600 - 6s/epoch - 1ms/step\n",
            "Epoch 171/500\n",
            "3850/3850 - 6s - loss: 0.3365 - accuracy: 0.8737 - val_loss: 0.0988 - val_accuracy: 0.9785 - 6s/epoch - 2ms/step\n",
            "Epoch 172/500\n",
            "3850/3850 - 6s - loss: 0.3347 - accuracy: 0.8736 - val_loss: 0.1831 - val_accuracy: 0.9554 - 6s/epoch - 1ms/step\n",
            "Epoch 173/500\n",
            "3850/3850 - 6s - loss: 0.3321 - accuracy: 0.8745 - val_loss: 0.1710 - val_accuracy: 0.9605 - 6s/epoch - 1ms/step\n",
            "Epoch 174/500\n",
            "3850/3850 - 6s - loss: 0.3309 - accuracy: 0.8748 - val_loss: 0.1755 - val_accuracy: 0.9591 - 6s/epoch - 1ms/step\n",
            "Epoch 175/500\n",
            "3850/3850 - 6s - loss: 0.3291 - accuracy: 0.8765 - val_loss: 0.2914 - val_accuracy: 0.9168 - 6s/epoch - 1ms/step\n",
            "Epoch 176/500\n",
            "3850/3850 - 6s - loss: 0.3281 - accuracy: 0.8771 - val_loss: 0.1922 - val_accuracy: 0.9547 - 6s/epoch - 2ms/step\n",
            "Epoch 177/500\n",
            "3850/3850 - 6s - loss: 0.3268 - accuracy: 0.8775 - val_loss: 0.2616 - val_accuracy: 0.9355 - 6s/epoch - 2ms/step\n",
            "Epoch 178/500\n",
            "3850/3850 - 6s - loss: 0.3250 - accuracy: 0.8772 - val_loss: 0.2027 - val_accuracy: 0.9540 - 6s/epoch - 2ms/step\n",
            "Epoch 179/500\n",
            "3850/3850 - 6s - loss: 0.3228 - accuracy: 0.8796 - val_loss: 0.1026 - val_accuracy: 0.9808 - 6s/epoch - 1ms/step\n",
            "Epoch 180/500\n",
            "3850/3850 - 6s - loss: 0.3209 - accuracy: 0.8804 - val_loss: 0.1998 - val_accuracy: 0.9530 - 6s/epoch - 1ms/step\n",
            "Epoch 181/500\n",
            "3850/3850 - 6s - loss: 0.3192 - accuracy: 0.8818 - val_loss: 0.3166 - val_accuracy: 0.9072 - 6s/epoch - 1ms/step\n",
            "Epoch 182/500\n",
            "3850/3850 - 6s - loss: 0.3169 - accuracy: 0.8816 - val_loss: 0.1695 - val_accuracy: 0.9607 - 6s/epoch - 2ms/step\n",
            "Epoch 183/500\n",
            "3850/3850 - 6s - loss: 0.3159 - accuracy: 0.8824 - val_loss: 0.2353 - val_accuracy: 0.9390 - 6s/epoch - 1ms/step\n",
            "Epoch 184/500\n",
            "3850/3850 - 6s - loss: 0.3147 - accuracy: 0.8824 - val_loss: 0.1691 - val_accuracy: 0.9621 - 6s/epoch - 2ms/step\n",
            "Epoch 185/500\n",
            "3850/3850 - 6s - loss: 0.3130 - accuracy: 0.8841 - val_loss: 0.1734 - val_accuracy: 0.9642 - 6s/epoch - 1ms/step\n",
            "Epoch 186/500\n",
            "3850/3850 - 6s - loss: 0.3120 - accuracy: 0.8845 - val_loss: 0.2303 - val_accuracy: 0.9434 - 6s/epoch - 1ms/step\n",
            "Epoch 187/500\n",
            "3850/3850 - 6s - loss: 0.3109 - accuracy: 0.8866 - val_loss: 0.1644 - val_accuracy: 0.9612 - 6s/epoch - 2ms/step\n",
            "Epoch 188/500\n",
            "3850/3850 - 6s - loss: 0.3093 - accuracy: 0.8867 - val_loss: 0.1717 - val_accuracy: 0.9656 - 6s/epoch - 1ms/step\n",
            "Epoch 189/500\n",
            "3850/3850 - 6s - loss: 0.3076 - accuracy: 0.8869 - val_loss: 0.3023 - val_accuracy: 0.9091 - 6s/epoch - 1ms/step\n",
            "Epoch 190/500\n",
            "3850/3850 - 6s - loss: 0.3076 - accuracy: 0.8858 - val_loss: 0.1522 - val_accuracy: 0.9656 - 6s/epoch - 1ms/step\n",
            "Epoch 191/500\n",
            "3850/3850 - 6s - loss: 0.3055 - accuracy: 0.8881 - val_loss: 0.1959 - val_accuracy: 0.9504 - 6s/epoch - 1ms/step\n",
            "Epoch 192/500\n",
            "3850/3850 - 6s - loss: 0.3030 - accuracy: 0.8896 - val_loss: 0.1799 - val_accuracy: 0.9556 - 6s/epoch - 1ms/step\n",
            "Epoch 193/500\n",
            "3850/3850 - 6s - loss: 0.3033 - accuracy: 0.8885 - val_loss: 0.1674 - val_accuracy: 0.9598 - 6s/epoch - 1ms/step\n",
            "Epoch 194/500\n",
            "3850/3850 - 6s - loss: 0.3017 - accuracy: 0.8885 - val_loss: 0.1487 - val_accuracy: 0.9694 - 6s/epoch - 1ms/step\n",
            "Epoch 195/500\n",
            "3850/3850 - 6s - loss: 0.2999 - accuracy: 0.8920 - val_loss: 0.1996 - val_accuracy: 0.9453 - 6s/epoch - 1ms/step\n",
            "Epoch 196/500\n",
            "3850/3850 - 6s - loss: 0.2989 - accuracy: 0.8915 - val_loss: 0.1710 - val_accuracy: 0.9523 - 6s/epoch - 2ms/step\n",
            "Epoch 197/500\n",
            "3850/3850 - 6s - loss: 0.2987 - accuracy: 0.8908 - val_loss: 0.1645 - val_accuracy: 0.9547 - 6s/epoch - 1ms/step\n",
            "Epoch 198/500\n",
            "3850/3850 - 6s - loss: 0.2969 - accuracy: 0.8906 - val_loss: 0.1734 - val_accuracy: 0.9554 - 6s/epoch - 2ms/step\n",
            "Epoch 199/500\n",
            "3850/3850 - 6s - loss: 0.2953 - accuracy: 0.8931 - val_loss: 0.2576 - val_accuracy: 0.9275 - 6s/epoch - 1ms/step\n",
            "Epoch 200/500\n",
            "3850/3850 - 6s - loss: 0.2942 - accuracy: 0.8932 - val_loss: 0.1764 - val_accuracy: 0.9547 - 6s/epoch - 1ms/step\n",
            "Epoch 201/500\n",
            "3850/3850 - 6s - loss: 0.2923 - accuracy: 0.8947 - val_loss: 0.2205 - val_accuracy: 0.9404 - 6s/epoch - 2ms/step\n",
            "Epoch 202/500\n",
            "3850/3850 - 6s - loss: 0.2918 - accuracy: 0.8936 - val_loss: 0.1485 - val_accuracy: 0.9577 - 6s/epoch - 1ms/step\n",
            "Epoch 203/500\n",
            "3850/3850 - 6s - loss: 0.2911 - accuracy: 0.8929 - val_loss: 0.2111 - val_accuracy: 0.9390 - 6s/epoch - 2ms/step\n",
            "Epoch 204/500\n",
            "3850/3850 - 6s - loss: 0.2902 - accuracy: 0.8965 - val_loss: 0.1002 - val_accuracy: 0.9750 - 6s/epoch - 2ms/step\n",
            "Epoch 205/500\n",
            "3850/3850 - 6s - loss: 0.2888 - accuracy: 0.8967 - val_loss: 0.2192 - val_accuracy: 0.9374 - 6s/epoch - 2ms/step\n",
            "Epoch 206/500\n",
            "3850/3850 - 6s - loss: 0.2881 - accuracy: 0.8965 - val_loss: 0.1699 - val_accuracy: 0.9565 - 6s/epoch - 1ms/step\n",
            "Epoch 207/500\n",
            "3850/3850 - 6s - loss: 0.2867 - accuracy: 0.8982 - val_loss: 0.1345 - val_accuracy: 0.9652 - 6s/epoch - 1ms/step\n",
            "Epoch 208/500\n",
            "3850/3850 - 6s - loss: 0.2844 - accuracy: 0.8981 - val_loss: 0.1867 - val_accuracy: 0.9441 - 6s/epoch - 1ms/step\n",
            "Epoch 209/500\n",
            "3850/3850 - 6s - loss: 0.2848 - accuracy: 0.8974 - val_loss: 0.1506 - val_accuracy: 0.9605 - 6s/epoch - 1ms/step\n",
            "Epoch 210/500\n",
            "3850/3850 - 6s - loss: 0.2838 - accuracy: 0.8980 - val_loss: 0.2568 - val_accuracy: 0.9163 - 6s/epoch - 2ms/step\n",
            "Epoch 211/500\n",
            "3850/3850 - 6s - loss: 0.2809 - accuracy: 0.8989 - val_loss: 0.1524 - val_accuracy: 0.9638 - 6s/epoch - 1ms/step\n",
            "Epoch 212/500\n",
            "3850/3850 - 6s - loss: 0.2819 - accuracy: 0.8996 - val_loss: 0.2137 - val_accuracy: 0.9392 - 6s/epoch - 1ms/step\n",
            "Epoch 213/500\n",
            "3850/3850 - 6s - loss: 0.2812 - accuracy: 0.8991 - val_loss: 0.3801 - val_accuracy: 0.8612 - 6s/epoch - 2ms/step\n",
            "Epoch 214/500\n",
            "3850/3850 - 6s - loss: 0.2806 - accuracy: 0.9010 - val_loss: 0.2034 - val_accuracy: 0.9392 - 6s/epoch - 2ms/step\n",
            "Epoch 215/500\n",
            "3850/3850 - 6s - loss: 0.2794 - accuracy: 0.8995 - val_loss: 0.1391 - val_accuracy: 0.9624 - 6s/epoch - 1ms/step\n",
            "Epoch 216/500\n",
            "3850/3850 - 6s - loss: 0.2785 - accuracy: 0.9010 - val_loss: 0.0986 - val_accuracy: 0.9727 - 6s/epoch - 2ms/step\n",
            "Epoch 217/500\n",
            "3850/3850 - 6s - loss: 0.2775 - accuracy: 0.9017 - val_loss: 0.3839 - val_accuracy: 0.8609 - 6s/epoch - 2ms/step\n",
            "Epoch 218/500\n",
            "3850/3850 - 6s - loss: 0.2767 - accuracy: 0.9005 - val_loss: 0.2442 - val_accuracy: 0.9250 - 6s/epoch - 1ms/step\n",
            "Epoch 219/500\n",
            "3850/3850 - 6s - loss: 0.2774 - accuracy: 0.9016 - val_loss: 0.1628 - val_accuracy: 0.9549 - 6s/epoch - 2ms/step\n",
            "Epoch 220/500\n",
            "3850/3850 - 6s - loss: 0.2744 - accuracy: 0.9025 - val_loss: 0.0804 - val_accuracy: 0.9841 - 6s/epoch - 2ms/step\n",
            "Epoch 221/500\n",
            "3850/3850 - 6s - loss: 0.2743 - accuracy: 0.9016 - val_loss: 0.3741 - val_accuracy: 0.8541 - 6s/epoch - 1ms/step\n",
            "Epoch 222/500\n",
            "3850/3850 - 6s - loss: 0.2733 - accuracy: 0.9029 - val_loss: 0.1748 - val_accuracy: 0.9504 - 6s/epoch - 2ms/step\n",
            "Epoch 223/500\n",
            "3850/3850 - 6s - loss: 0.2730 - accuracy: 0.9029 - val_loss: 0.2668 - val_accuracy: 0.9142 - 6s/epoch - 2ms/step\n",
            "Epoch 224/500\n",
            "3850/3850 - 6s - loss: 0.2721 - accuracy: 0.9027 - val_loss: 0.1584 - val_accuracy: 0.9565 - 6s/epoch - 1ms/step\n",
            "Epoch 225/500\n",
            "3850/3850 - 6s - loss: 0.2716 - accuracy: 0.9031 - val_loss: 0.1776 - val_accuracy: 0.9497 - 6s/epoch - 1ms/step\n",
            "Epoch 226/500\n",
            "3850/3850 - 6s - loss: 0.2715 - accuracy: 0.9020 - val_loss: 0.1928 - val_accuracy: 0.9425 - 6s/epoch - 1ms/step\n",
            "Epoch 227/500\n",
            "3850/3850 - 6s - loss: 0.2688 - accuracy: 0.9059 - val_loss: 0.2677 - val_accuracy: 0.9114 - 6s/epoch - 2ms/step\n",
            "Epoch 228/500\n",
            "3850/3850 - 6s - loss: 0.2688 - accuracy: 0.9048 - val_loss: 0.2495 - val_accuracy: 0.9189 - 6s/epoch - 1ms/step\n",
            "Epoch 229/500\n",
            "3850/3850 - 6s - loss: 0.2678 - accuracy: 0.9051 - val_loss: 0.1330 - val_accuracy: 0.9652 - 6s/epoch - 2ms/step\n",
            "Epoch 230/500\n",
            "3850/3850 - 6s - loss: 0.2676 - accuracy: 0.9033 - val_loss: 0.2816 - val_accuracy: 0.9004 - 6s/epoch - 2ms/step\n",
            "Epoch 231/500\n",
            "3850/3850 - 6s - loss: 0.2672 - accuracy: 0.9060 - val_loss: 0.1581 - val_accuracy: 0.9547 - 6s/epoch - 1ms/step\n",
            "Epoch 232/500\n",
            "3850/3850 - 6s - loss: 0.2655 - accuracy: 0.9053 - val_loss: 0.3763 - val_accuracy: 0.8569 - 6s/epoch - 2ms/step\n",
            "Epoch 233/500\n",
            "3850/3850 - 6s - loss: 0.2656 - accuracy: 0.9052 - val_loss: 0.3050 - val_accuracy: 0.8850 - 6s/epoch - 2ms/step\n",
            "Epoch 234/500\n",
            "3850/3850 - 6s - loss: 0.2644 - accuracy: 0.9067 - val_loss: 0.2709 - val_accuracy: 0.9065 - 6s/epoch - 1ms/step\n",
            "Epoch 235/500\n",
            "3850/3850 - 6s - loss: 0.2632 - accuracy: 0.9067 - val_loss: 0.1026 - val_accuracy: 0.9769 - 6s/epoch - 1ms/step\n",
            "Epoch 236/500\n",
            "3850/3850 - 6s - loss: 0.2633 - accuracy: 0.9064 - val_loss: 0.1702 - val_accuracy: 0.9493 - 6s/epoch - 1ms/step\n",
            "Epoch 237/500\n",
            "3850/3850 - 6s - loss: 0.2629 - accuracy: 0.9062 - val_loss: 0.1688 - val_accuracy: 0.9504 - 6s/epoch - 2ms/step\n",
            "Epoch 238/500\n",
            "3850/3850 - 6s - loss: 0.2625 - accuracy: 0.9070 - val_loss: 0.1751 - val_accuracy: 0.9467 - 6s/epoch - 2ms/step\n",
            "Epoch 239/500\n",
            "3850/3850 - 6s - loss: 0.2610 - accuracy: 0.9074 - val_loss: 0.1890 - val_accuracy: 0.9427 - 6s/epoch - 1ms/step\n",
            "Epoch 240/500\n",
            "3850/3850 - 6s - loss: 0.2603 - accuracy: 0.9080 - val_loss: 0.2271 - val_accuracy: 0.9271 - 6s/epoch - 2ms/step\n",
            "Epoch 241/500\n",
            "3850/3850 - 6s - loss: 0.2600 - accuracy: 0.9073 - val_loss: 0.2226 - val_accuracy: 0.9303 - 6s/epoch - 2ms/step\n",
            "Epoch 242/500\n",
            "3850/3850 - 6s - loss: 0.2602 - accuracy: 0.9098 - val_loss: 0.2569 - val_accuracy: 0.9156 - 6s/epoch - 1ms/step\n",
            "Epoch 243/500\n",
            "3850/3850 - 6s - loss: 0.2569 - accuracy: 0.9098 - val_loss: 0.1727 - val_accuracy: 0.9479 - 6s/epoch - 2ms/step\n",
            "Epoch 244/500\n",
            "3850/3850 - 6s - loss: 0.2578 - accuracy: 0.9077 - val_loss: 0.2526 - val_accuracy: 0.9142 - 6s/epoch - 2ms/step\n",
            "Epoch 245/500\n",
            "3850/3850 - 6s - loss: 0.2582 - accuracy: 0.9090 - val_loss: 0.1746 - val_accuracy: 0.9511 - 6s/epoch - 1ms/step\n",
            "Epoch 246/500\n",
            "3850/3850 - 6s - loss: 0.2571 - accuracy: 0.9082 - val_loss: 0.1314 - val_accuracy: 0.9652 - 6s/epoch - 1ms/step\n",
            "Epoch 247/500\n",
            "3850/3850 - 6s - loss: 0.2567 - accuracy: 0.9080 - val_loss: 0.1522 - val_accuracy: 0.9561 - 6s/epoch - 1ms/step\n",
            "Epoch 248/500\n",
            "3850/3850 - 6s - loss: 0.2547 - accuracy: 0.9100 - val_loss: 0.0879 - val_accuracy: 0.9797 - 6s/epoch - 1ms/step\n",
            "Epoch 249/500\n",
            "3850/3850 - 6s - loss: 0.2548 - accuracy: 0.9095 - val_loss: 0.1923 - val_accuracy: 0.9413 - 6s/epoch - 1ms/step\n",
            "Epoch 250/500\n",
            "3850/3850 - 6s - loss: 0.2545 - accuracy: 0.9095 - val_loss: 0.1857 - val_accuracy: 0.9381 - 6s/epoch - 1ms/step\n",
            "Epoch 251/500\n",
            "3850/3850 - 6s - loss: 0.2551 - accuracy: 0.9085 - val_loss: 0.3319 - val_accuracy: 0.8784 - 6s/epoch - 1ms/step\n",
            "Epoch 252/500\n",
            "3850/3850 - 6s - loss: 0.2531 - accuracy: 0.9105 - val_loss: 0.2276 - val_accuracy: 0.9250 - 6s/epoch - 2ms/step\n",
            "Epoch 253/500\n",
            "3850/3850 - 6s - loss: 0.2529 - accuracy: 0.9107 - val_loss: 0.2394 - val_accuracy: 0.9224 - 6s/epoch - 1ms/step\n",
            "Epoch 254/500\n",
            "3850/3850 - 6s - loss: 0.2518 - accuracy: 0.9111 - val_loss: 0.2525 - val_accuracy: 0.9121 - 6s/epoch - 1ms/step\n",
            "Epoch 255/500\n",
            "3850/3850 - 6s - loss: 0.2518 - accuracy: 0.9113 - val_loss: 0.1228 - val_accuracy: 0.9675 - 6s/epoch - 2ms/step\n",
            "Epoch 256/500\n",
            "3850/3850 - 6s - loss: 0.2513 - accuracy: 0.9114 - val_loss: 0.1327 - val_accuracy: 0.9656 - 6s/epoch - 2ms/step\n",
            "Epoch 257/500\n",
            "3850/3850 - 6s - loss: 0.2504 - accuracy: 0.9126 - val_loss: 0.1859 - val_accuracy: 0.9437 - 6s/epoch - 1ms/step\n",
            "Epoch 258/500\n",
            "3850/3850 - 6s - loss: 0.2504 - accuracy: 0.9123 - val_loss: 0.2122 - val_accuracy: 0.9294 - 6s/epoch - 2ms/step\n",
            "Epoch 259/500\n",
            "3850/3850 - 6s - loss: 0.2490 - accuracy: 0.9125 - val_loss: 0.2299 - val_accuracy: 0.9243 - 6s/epoch - 2ms/step\n",
            "Epoch 260/500\n",
            "3850/3850 - 6s - loss: 0.2494 - accuracy: 0.9121 - val_loss: 0.2212 - val_accuracy: 0.9296 - 6s/epoch - 1ms/step\n",
            "Epoch 261/500\n",
            "3850/3850 - 6s - loss: 0.2481 - accuracy: 0.9124 - val_loss: 0.3553 - val_accuracy: 0.8488 - 6s/epoch - 2ms/step\n",
            "Epoch 262/500\n",
            "3850/3850 - 6s - loss: 0.2487 - accuracy: 0.9114 - val_loss: 0.2027 - val_accuracy: 0.9306 - 6s/epoch - 2ms/step\n",
            "Epoch 263/500\n",
            "3850/3850 - 6s - loss: 0.2479 - accuracy: 0.9126 - val_loss: 0.1379 - val_accuracy: 0.9600 - 6s/epoch - 1ms/step\n",
            "Epoch 264/500\n",
            "3850/3850 - 6s - loss: 0.2469 - accuracy: 0.9125 - val_loss: 0.1841 - val_accuracy: 0.9423 - 6s/epoch - 1ms/step\n",
            "Epoch 265/500\n",
            "3850/3850 - 6s - loss: 0.2472 - accuracy: 0.9123 - val_loss: 0.2239 - val_accuracy: 0.9238 - 6s/epoch - 1ms/step\n",
            "Epoch 266/500\n",
            "3850/3850 - 6s - loss: 0.2464 - accuracy: 0.9128 - val_loss: 0.2410 - val_accuracy: 0.9161 - 6s/epoch - 2ms/step\n",
            "Epoch 267/500\n",
            "3850/3850 - 6s - loss: 0.2456 - accuracy: 0.9133 - val_loss: 0.2373 - val_accuracy: 0.9177 - 6s/epoch - 1ms/step\n",
            "Epoch 268/500\n",
            "3850/3850 - 6s - loss: 0.2459 - accuracy: 0.9137 - val_loss: 0.1537 - val_accuracy: 0.9565 - 6s/epoch - 2ms/step\n",
            "Epoch 269/500\n",
            "3850/3850 - 6s - loss: 0.2450 - accuracy: 0.9140 - val_loss: 0.1905 - val_accuracy: 0.9341 - 6s/epoch - 2ms/step\n",
            "Epoch 270/500\n",
            "3850/3850 - 6s - loss: 0.2443 - accuracy: 0.9141 - val_loss: 0.1327 - val_accuracy: 0.9596 - 6s/epoch - 1ms/step\n",
            "Epoch 271/500\n",
            "3850/3850 - 6s - loss: 0.2443 - accuracy: 0.9142 - val_loss: 0.1617 - val_accuracy: 0.9521 - 6s/epoch - 1ms/step\n",
            "Epoch 272/500\n",
            "3850/3850 - 6s - loss: 0.2440 - accuracy: 0.9134 - val_loss: 0.2181 - val_accuracy: 0.9238 - 6s/epoch - 1ms/step\n",
            "Epoch 273/500\n",
            "3850/3850 - 6s - loss: 0.2441 - accuracy: 0.9132 - val_loss: 0.1202 - val_accuracy: 0.9682 - 6s/epoch - 1ms/step\n",
            "Epoch 274/500\n",
            "3850/3850 - 6s - loss: 0.2429 - accuracy: 0.9137 - val_loss: 0.2380 - val_accuracy: 0.9212 - 6s/epoch - 1ms/step\n",
            "Epoch 275/500\n",
            "3850/3850 - 6s - loss: 0.2429 - accuracy: 0.9157 - val_loss: 0.1314 - val_accuracy: 0.9640 - 6s/epoch - 1ms/step\n",
            "Epoch 276/500\n",
            "3850/3850 - 6s - loss: 0.2421 - accuracy: 0.9142 - val_loss: 0.2559 - val_accuracy: 0.9088 - 6s/epoch - 1ms/step\n",
            "Epoch 277/500\n",
            "3850/3850 - 6s - loss: 0.2410 - accuracy: 0.9148 - val_loss: 0.3134 - val_accuracy: 0.8829 - 6s/epoch - 2ms/step\n",
            "Epoch 278/500\n",
            "3850/3850 - 6s - loss: 0.2410 - accuracy: 0.9164 - val_loss: 0.1728 - val_accuracy: 0.9493 - 6s/epoch - 1ms/step\n",
            "Epoch 279/500\n",
            "3850/3850 - 6s - loss: 0.2410 - accuracy: 0.9151 - val_loss: 0.1417 - val_accuracy: 0.9593 - 6s/epoch - 1ms/step\n",
            "Epoch 280/500\n",
            "3850/3850 - 6s - loss: 0.2409 - accuracy: 0.9150 - val_loss: 0.1815 - val_accuracy: 0.9409 - 6s/epoch - 2ms/step\n",
            "Epoch 281/500\n",
            "3850/3850 - 6s - loss: 0.2401 - accuracy: 0.9150 - val_loss: 0.2849 - val_accuracy: 0.8838 - 6s/epoch - 2ms/step\n",
            "Epoch 282/500\n",
            "3850/3850 - 6s - loss: 0.2386 - accuracy: 0.9162 - val_loss: 0.2259 - val_accuracy: 0.9226 - 6s/epoch - 1ms/step\n",
            "Epoch 283/500\n",
            "3850/3850 - 6s - loss: 0.2374 - accuracy: 0.9171 - val_loss: 0.2399 - val_accuracy: 0.9187 - 6s/epoch - 2ms/step\n",
            "Epoch 284/500\n",
            "3850/3850 - 6s - loss: 0.2381 - accuracy: 0.9163 - val_loss: 0.1512 - val_accuracy: 0.9525 - 6s/epoch - 2ms/step\n",
            "Epoch 285/500\n",
            "3850/3850 - 6s - loss: 0.2376 - accuracy: 0.9172 - val_loss: 0.1516 - val_accuracy: 0.9532 - 6s/epoch - 1ms/step\n",
            "Epoch 286/500\n",
            "3850/3850 - 6s - loss: 0.2384 - accuracy: 0.9159 - val_loss: 0.2295 - val_accuracy: 0.9184 - 6s/epoch - 2ms/step\n",
            "Epoch 287/500\n",
            "3850/3850 - 6s - loss: 0.2384 - accuracy: 0.9158 - val_loss: 0.1913 - val_accuracy: 0.9409 - 6s/epoch - 2ms/step\n",
            "Epoch 288/500\n",
            "3850/3850 - 6s - loss: 0.2366 - accuracy: 0.9164 - val_loss: 0.2292 - val_accuracy: 0.9165 - 6s/epoch - 1ms/step\n",
            "Epoch 289/500\n",
            "3850/3850 - 6s - loss: 0.2364 - accuracy: 0.9167 - val_loss: 0.1532 - val_accuracy: 0.9523 - 6s/epoch - 1ms/step\n",
            "Epoch 290/500\n",
            "3850/3850 - 6s - loss: 0.2370 - accuracy: 0.9151 - val_loss: 0.2309 - val_accuracy: 0.9189 - 6s/epoch - 2ms/step\n",
            "Epoch 291/500\n",
            "3850/3850 - 6s - loss: 0.2360 - accuracy: 0.9172 - val_loss: 0.3134 - val_accuracy: 0.8759 - 6s/epoch - 2ms/step\n",
            "Epoch 292/500\n",
            "3850/3850 - 6s - loss: 0.2350 - accuracy: 0.9185 - val_loss: 0.2397 - val_accuracy: 0.9140 - 6s/epoch - 1ms/step\n",
            "Epoch 293/500\n",
            "3850/3850 - 6s - loss: 0.2347 - accuracy: 0.9167 - val_loss: 0.1969 - val_accuracy: 0.9350 - 6s/epoch - 2ms/step\n",
            "Epoch 294/500\n",
            "3850/3850 - 6s - loss: 0.2328 - accuracy: 0.9187 - val_loss: 0.2560 - val_accuracy: 0.9074 - 6s/epoch - 1ms/step\n",
            "Epoch 295/500\n",
            "3850/3850 - 6s - loss: 0.2337 - accuracy: 0.9178 - val_loss: 0.1298 - val_accuracy: 0.9600 - 6s/epoch - 1ms/step\n",
            "Epoch 296/500\n",
            "3850/3850 - 6s - loss: 0.2339 - accuracy: 0.9170 - val_loss: 0.3294 - val_accuracy: 0.8682 - 6s/epoch - 2ms/step\n",
            "Epoch 297/500\n",
            "3850/3850 - 6s - loss: 0.2341 - accuracy: 0.9172 - val_loss: 0.2641 - val_accuracy: 0.9025 - 6s/epoch - 2ms/step\n",
            "Epoch 298/500\n",
            "3850/3850 - 6s - loss: 0.2333 - accuracy: 0.9165 - val_loss: 0.1861 - val_accuracy: 0.9395 - 6s/epoch - 1ms/step\n",
            "Epoch 299/500\n",
            "3850/3850 - 6s - loss: 0.2319 - accuracy: 0.9192 - val_loss: 0.1646 - val_accuracy: 0.9462 - 6s/epoch - 2ms/step\n",
            "Epoch 300/500\n",
            "3850/3850 - 6s - loss: 0.2335 - accuracy: 0.9189 - val_loss: 0.3343 - val_accuracy: 0.8670 - 6s/epoch - 1ms/step\n",
            "Epoch 301/500\n",
            "3850/3850 - 6s - loss: 0.2321 - accuracy: 0.9177 - val_loss: 0.1893 - val_accuracy: 0.9371 - 6s/epoch - 2ms/step\n",
            "Epoch 302/500\n",
            "3850/3850 - 6s - loss: 0.2321 - accuracy: 0.9184 - val_loss: 0.1743 - val_accuracy: 0.9446 - 6s/epoch - 1ms/step\n",
            "Epoch 303/500\n",
            "3850/3850 - 6s - loss: 0.2328 - accuracy: 0.9187 - val_loss: 0.1293 - val_accuracy: 0.9619 - 6s/epoch - 2ms/step\n",
            "Epoch 304/500\n",
            "3850/3850 - 6s - loss: 0.2319 - accuracy: 0.9174 - val_loss: 0.1884 - val_accuracy: 0.9378 - 6s/epoch - 2ms/step\n",
            "Epoch 305/500\n",
            "3850/3850 - 6s - loss: 0.2317 - accuracy: 0.9186 - val_loss: 0.1574 - val_accuracy: 0.9511 - 6s/epoch - 1ms/step\n",
            "Epoch 306/500\n",
            "3850/3850 - 6s - loss: 0.2300 - accuracy: 0.9183 - val_loss: 0.1839 - val_accuracy: 0.9385 - 6s/epoch - 2ms/step\n",
            "Epoch 307/500\n",
            "3850/3850 - 6s - loss: 0.2307 - accuracy: 0.9197 - val_loss: 0.2922 - val_accuracy: 0.8894 - 6s/epoch - 1ms/step\n",
            "Epoch 308/500\n",
            "3850/3850 - 6s - loss: 0.2301 - accuracy: 0.9200 - val_loss: 0.1898 - val_accuracy: 0.9416 - 6s/epoch - 2ms/step\n",
            "Epoch 309/500\n",
            "3850/3850 - 6s - loss: 0.2301 - accuracy: 0.9187 - val_loss: 0.0737 - val_accuracy: 0.9857 - 6s/epoch - 2ms/step\n",
            "Epoch 310/500\n",
            "3850/3850 - 6s - loss: 0.2293 - accuracy: 0.9189 - val_loss: 0.2325 - val_accuracy: 0.9116 - 6s/epoch - 1ms/step\n",
            "Epoch 311/500\n",
            "3850/3850 - 6s - loss: 0.2300 - accuracy: 0.9183 - val_loss: 0.1274 - val_accuracy: 0.9631 - 6s/epoch - 1ms/step\n",
            "Epoch 312/500\n",
            "3850/3850 - 6s - loss: 0.2285 - accuracy: 0.9195 - val_loss: 0.2387 - val_accuracy: 0.9177 - 6s/epoch - 1ms/step\n",
            "Epoch 313/500\n",
            "3850/3850 - 6s - loss: 0.2281 - accuracy: 0.9207 - val_loss: 0.1944 - val_accuracy: 0.9331 - 6s/epoch - 1ms/step\n",
            "Epoch 314/500\n",
            "3850/3850 - 6s - loss: 0.2282 - accuracy: 0.9199 - val_loss: 0.1557 - val_accuracy: 0.9547 - 6s/epoch - 2ms/step\n",
            "Epoch 315/500\n",
            "3850/3850 - 6s - loss: 0.2273 - accuracy: 0.9203 - val_loss: 0.2631 - val_accuracy: 0.8995 - 6s/epoch - 2ms/step\n",
            "Epoch 316/500\n",
            "3850/3850 - 6s - loss: 0.2276 - accuracy: 0.9204 - val_loss: 0.3148 - val_accuracy: 0.8693 - 6s/epoch - 2ms/step\n",
            "Epoch 317/500\n",
            "3850/3850 - 6s - loss: 0.2267 - accuracy: 0.9197 - val_loss: 0.2589 - val_accuracy: 0.9074 - 6s/epoch - 1ms/step\n",
            "Epoch 318/500\n",
            "3850/3850 - 6s - loss: 0.2274 - accuracy: 0.9198 - val_loss: 0.1782 - val_accuracy: 0.9353 - 6s/epoch - 2ms/step\n",
            "Epoch 319/500\n",
            "3850/3850 - 6s - loss: 0.2267 - accuracy: 0.9213 - val_loss: 0.2131 - val_accuracy: 0.9229 - 6s/epoch - 1ms/step\n",
            "Epoch 320/500\n",
            "3850/3850 - 6s - loss: 0.2261 - accuracy: 0.9201 - val_loss: 0.2248 - val_accuracy: 0.9191 - 6s/epoch - 2ms/step\n",
            "Epoch 321/500\n",
            "3850/3850 - 6s - loss: 0.2264 - accuracy: 0.9200 - val_loss: 0.1911 - val_accuracy: 0.9343 - 6s/epoch - 2ms/step\n",
            "Epoch 322/500\n",
            "3850/3850 - 6s - loss: 0.2259 - accuracy: 0.9200 - val_loss: 0.3042 - val_accuracy: 0.8831 - 6s/epoch - 2ms/step\n",
            "Epoch 323/500\n",
            "3850/3850 - 6s - loss: 0.2248 - accuracy: 0.9212 - val_loss: 0.2118 - val_accuracy: 0.9259 - 6s/epoch - 2ms/step\n",
            "Epoch 324/500\n",
            "3850/3850 - 6s - loss: 0.2262 - accuracy: 0.9192 - val_loss: 0.1800 - val_accuracy: 0.9420 - 6s/epoch - 1ms/step\n",
            "Epoch 325/500\n",
            "3850/3850 - 6s - loss: 0.2258 - accuracy: 0.9196 - val_loss: 0.2189 - val_accuracy: 0.9245 - 6s/epoch - 2ms/step\n",
            "Epoch 326/500\n",
            "3850/3850 - 6s - loss: 0.2247 - accuracy: 0.9204 - val_loss: 0.2286 - val_accuracy: 0.9191 - 6s/epoch - 1ms/step\n",
            "Epoch 327/500\n",
            "3850/3850 - 6s - loss: 0.2248 - accuracy: 0.9198 - val_loss: 0.1456 - val_accuracy: 0.9568 - 6s/epoch - 2ms/step\n",
            "Epoch 328/500\n",
            "3850/3850 - 6s - loss: 0.2253 - accuracy: 0.9205 - val_loss: 0.1321 - val_accuracy: 0.9638 - 6s/epoch - 1ms/step\n",
            "Epoch 329/500\n",
            "3850/3850 - 6s - loss: 0.2245 - accuracy: 0.9213 - val_loss: 0.1728 - val_accuracy: 0.9441 - 6s/epoch - 1ms/step\n",
            "Epoch 330/500\n",
            "3850/3850 - 6s - loss: 0.2237 - accuracy: 0.9212 - val_loss: 0.1259 - val_accuracy: 0.9610 - 6s/epoch - 1ms/step\n",
            "Epoch 331/500\n",
            "3850/3850 - 6s - loss: 0.2238 - accuracy: 0.9206 - val_loss: 0.1746 - val_accuracy: 0.9446 - 6s/epoch - 1ms/step\n",
            "Epoch 332/500\n",
            "3850/3850 - 6s - loss: 0.2241 - accuracy: 0.9196 - val_loss: 0.1504 - val_accuracy: 0.9537 - 6s/epoch - 1ms/step\n",
            "Epoch 333/500\n",
            "3850/3850 - 6s - loss: 0.2233 - accuracy: 0.9205 - val_loss: 0.1211 - val_accuracy: 0.9663 - 6s/epoch - 2ms/step\n",
            "Epoch 334/500\n",
            "3850/3850 - 6s - loss: 0.2225 - accuracy: 0.9215 - val_loss: 0.2815 - val_accuracy: 0.8908 - 6s/epoch - 2ms/step\n",
            "Epoch 335/500\n",
            "3850/3850 - 6s - loss: 0.2229 - accuracy: 0.9204 - val_loss: 0.2558 - val_accuracy: 0.8990 - 6s/epoch - 1ms/step\n",
            "Epoch 336/500\n",
            "3850/3850 - 6s - loss: 0.2231 - accuracy: 0.9198 - val_loss: 0.2042 - val_accuracy: 0.9301 - 6s/epoch - 1ms/step\n",
            "Epoch 337/500\n",
            "3850/3850 - 6s - loss: 0.2226 - accuracy: 0.9209 - val_loss: 0.1674 - val_accuracy: 0.9481 - 6s/epoch - 1ms/step\n",
            "Epoch 338/500\n",
            "3850/3850 - 6s - loss: 0.2219 - accuracy: 0.9211 - val_loss: 0.1737 - val_accuracy: 0.9427 - 6s/epoch - 1ms/step\n",
            "Epoch 339/500\n",
            "3850/3850 - 6s - loss: 0.2220 - accuracy: 0.9215 - val_loss: 0.2551 - val_accuracy: 0.9039 - 6s/epoch - 2ms/step\n",
            "Epoch 340/500\n",
            "3850/3850 - 6s - loss: 0.2215 - accuracy: 0.9205 - val_loss: 0.2804 - val_accuracy: 0.8873 - 6s/epoch - 2ms/step\n",
            "Epoch 341/500\n",
            "3850/3850 - 6s - loss: 0.2202 - accuracy: 0.9225 - val_loss: 0.2869 - val_accuracy: 0.8850 - 6s/epoch - 2ms/step\n",
            "Epoch 342/500\n",
            "3850/3850 - 6s - loss: 0.2221 - accuracy: 0.9220 - val_loss: 0.1333 - val_accuracy: 0.9621 - 6s/epoch - 1ms/step\n",
            "Epoch 343/500\n",
            "3850/3850 - 6s - loss: 0.2216 - accuracy: 0.9218 - val_loss: 0.3194 - val_accuracy: 0.8679 - 6s/epoch - 1ms/step\n",
            "Epoch 344/500\n",
            "3850/3850 - 6s - loss: 0.2207 - accuracy: 0.9221 - val_loss: 0.2125 - val_accuracy: 0.9236 - 6s/epoch - 1ms/step\n",
            "Epoch 345/500\n",
            "3850/3850 - 6s - loss: 0.2209 - accuracy: 0.9219 - val_loss: 0.2923 - val_accuracy: 0.8712 - 6s/epoch - 2ms/step\n",
            "Epoch 346/500\n",
            "3850/3850 - 6s - loss: 0.2208 - accuracy: 0.9214 - val_loss: 0.2631 - val_accuracy: 0.8845 - 6s/epoch - 2ms/step\n",
            "Epoch 347/500\n",
            "3850/3850 - 6s - loss: 0.2209 - accuracy: 0.9217 - val_loss: 0.1729 - val_accuracy: 0.9404 - 6s/epoch - 1ms/step\n",
            "Epoch 348/500\n",
            "3850/3850 - 6s - loss: 0.2195 - accuracy: 0.9235 - val_loss: 0.2284 - val_accuracy: 0.9144 - 6s/epoch - 1ms/step\n",
            "Epoch 349/500\n",
            "3850/3850 - 6s - loss: 0.2195 - accuracy: 0.9228 - val_loss: 0.2368 - val_accuracy: 0.9119 - 6s/epoch - 1ms/step\n",
            "Epoch 350/500\n",
            "3850/3850 - 6s - loss: 0.2191 - accuracy: 0.9229 - val_loss: 0.1639 - val_accuracy: 0.9462 - 6s/epoch - 1ms/step\n",
            "Epoch 351/500\n",
            "3850/3850 - 6s - loss: 0.2196 - accuracy: 0.9225 - val_loss: 0.2392 - val_accuracy: 0.9081 - 6s/epoch - 2ms/step\n",
            "Epoch 352/500\n",
            "3850/3850 - 6s - loss: 0.2199 - accuracy: 0.9228 - val_loss: 0.2579 - val_accuracy: 0.9000 - 6s/epoch - 2ms/step\n",
            "Epoch 353/500\n",
            "3850/3850 - 6s - loss: 0.2193 - accuracy: 0.9219 - val_loss: 0.2830 - val_accuracy: 0.8866 - 6s/epoch - 1ms/step\n",
            "Epoch 354/500\n",
            "3850/3850 - 6s - loss: 0.2184 - accuracy: 0.9230 - val_loss: 0.1340 - val_accuracy: 0.9596 - 6s/epoch - 2ms/step\n",
            "Epoch 355/500\n",
            "3850/3850 - 6s - loss: 0.2193 - accuracy: 0.9222 - val_loss: 0.1692 - val_accuracy: 0.9430 - 6s/epoch - 1ms/step\n",
            "Epoch 356/500\n",
            "3850/3850 - 6s - loss: 0.2188 - accuracy: 0.9218 - val_loss: 0.1482 - val_accuracy: 0.9518 - 6s/epoch - 1ms/step\n",
            "Epoch 357/500\n",
            "3850/3850 - 6s - loss: 0.2187 - accuracy: 0.9231 - val_loss: 0.2391 - val_accuracy: 0.9107 - 6s/epoch - 2ms/step\n",
            "Epoch 358/500\n",
            "3850/3850 - 6s - loss: 0.2185 - accuracy: 0.9225 - val_loss: 0.1750 - val_accuracy: 0.9420 - 6s/epoch - 2ms/step\n",
            "Epoch 359/500\n",
            "3850/3850 - 6s - loss: 0.2188 - accuracy: 0.9223 - val_loss: 0.1843 - val_accuracy: 0.9392 - 6s/epoch - 2ms/step\n",
            "Epoch 360/500\n",
            "3850/3850 - 6s - loss: 0.2172 - accuracy: 0.9236 - val_loss: 0.2424 - val_accuracy: 0.9109 - 6s/epoch - 1ms/step\n",
            "Epoch 361/500\n",
            "3850/3850 - 6s - loss: 0.2193 - accuracy: 0.9222 - val_loss: 0.2269 - val_accuracy: 0.9165 - 6s/epoch - 2ms/step\n",
            "Epoch 362/500\n",
            "3850/3850 - 6s - loss: 0.2189 - accuracy: 0.9229 - val_loss: 0.1531 - val_accuracy: 0.9516 - 6s/epoch - 2ms/step\n",
            "Epoch 363/500\n",
            "3850/3850 - 6s - loss: 0.2181 - accuracy: 0.9217 - val_loss: 0.1834 - val_accuracy: 0.9376 - 6s/epoch - 2ms/step\n",
            "Epoch 364/500\n",
            "3850/3850 - 6s - loss: 0.2174 - accuracy: 0.9242 - val_loss: 0.1675 - val_accuracy: 0.9427 - 6s/epoch - 2ms/step\n",
            "Epoch 365/500\n",
            "3850/3850 - 6s - loss: 0.2163 - accuracy: 0.9236 - val_loss: 0.2394 - val_accuracy: 0.9058 - 6s/epoch - 1ms/step\n",
            "Epoch 366/500\n",
            "3850/3850 - 6s - loss: 0.2164 - accuracy: 0.9232 - val_loss: 0.2733 - val_accuracy: 0.8927 - 6s/epoch - 1ms/step\n",
            "Epoch 367/500\n",
            "3850/3850 - 6s - loss: 0.2181 - accuracy: 0.9232 - val_loss: 0.2461 - val_accuracy: 0.9032 - 6s/epoch - 1ms/step\n",
            "Epoch 368/500\n",
            "3850/3850 - 6s - loss: 0.2160 - accuracy: 0.9244 - val_loss: 0.1713 - val_accuracy: 0.9441 - 6s/epoch - 2ms/step\n",
            "Epoch 369/500\n",
            "3850/3850 - 6s - loss: 0.2155 - accuracy: 0.9229 - val_loss: 0.1970 - val_accuracy: 0.9301 - 6s/epoch - 2ms/step\n",
            "Epoch 370/500\n",
            "3850/3850 - 6s - loss: 0.2168 - accuracy: 0.9227 - val_loss: 0.2381 - val_accuracy: 0.9116 - 6s/epoch - 2ms/step\n",
            "Epoch 371/500\n",
            "3850/3850 - 6s - loss: 0.2172 - accuracy: 0.9236 - val_loss: 0.2231 - val_accuracy: 0.9170 - 6s/epoch - 1ms/step\n",
            "Epoch 372/500\n",
            "3850/3850 - 6s - loss: 0.2162 - accuracy: 0.9233 - val_loss: 0.1603 - val_accuracy: 0.9476 - 6s/epoch - 1ms/step\n",
            "Epoch 373/500\n",
            "3850/3850 - 6s - loss: 0.2160 - accuracy: 0.9235 - val_loss: 0.1290 - val_accuracy: 0.9619 - 6s/epoch - 1ms/step\n",
            "Epoch 374/500\n",
            "3850/3850 - 6s - loss: 0.2160 - accuracy: 0.9246 - val_loss: 0.1819 - val_accuracy: 0.9413 - 6s/epoch - 2ms/step\n",
            "Epoch 375/500\n",
            "3850/3850 - 6s - loss: 0.2157 - accuracy: 0.9221 - val_loss: 0.3261 - val_accuracy: 0.8649 - 6s/epoch - 2ms/step\n",
            "Epoch 376/500\n",
            "3850/3850 - 6s - loss: 0.2141 - accuracy: 0.9248 - val_loss: 0.1474 - val_accuracy: 0.9556 - 6s/epoch - 2ms/step\n",
            "Epoch 377/500\n",
            "3850/3850 - 6s - loss: 0.2156 - accuracy: 0.9236 - val_loss: 0.1683 - val_accuracy: 0.9418 - 6s/epoch - 2ms/step\n",
            "Epoch 378/500\n",
            "3850/3850 - 6s - loss: 0.2144 - accuracy: 0.9250 - val_loss: 0.3510 - val_accuracy: 0.8518 - 6s/epoch - 1ms/step\n",
            "Epoch 379/500\n",
            "3850/3850 - 6s - loss: 0.2149 - accuracy: 0.9237 - val_loss: 0.1636 - val_accuracy: 0.9479 - 6s/epoch - 1ms/step\n",
            "Epoch 380/500\n",
            "3850/3850 - 6s - loss: 0.2160 - accuracy: 0.9227 - val_loss: 0.1716 - val_accuracy: 0.9460 - 6s/epoch - 2ms/step\n",
            "Epoch 381/500\n",
            "3850/3850 - 6s - loss: 0.2137 - accuracy: 0.9244 - val_loss: 0.2631 - val_accuracy: 0.8953 - 6s/epoch - 1ms/step\n",
            "Epoch 382/500\n",
            "3850/3850 - 6s - loss: 0.2151 - accuracy: 0.9236 - val_loss: 0.2888 - val_accuracy: 0.8820 - 6s/epoch - 2ms/step\n",
            "Epoch 383/500\n",
            "3850/3850 - 6s - loss: 0.2137 - accuracy: 0.9253 - val_loss: 0.1489 - val_accuracy: 0.9542 - 6s/epoch - 1ms/step\n",
            "Epoch 384/500\n",
            "3850/3850 - 6s - loss: 0.2135 - accuracy: 0.9246 - val_loss: 0.1215 - val_accuracy: 0.9659 - 6s/epoch - 1ms/step\n",
            "Epoch 385/500\n",
            "3850/3850 - 6s - loss: 0.2137 - accuracy: 0.9241 - val_loss: 0.2249 - val_accuracy: 0.9147 - 6s/epoch - 1ms/step\n",
            "Epoch 386/500\n",
            "3850/3850 - 6s - loss: 0.2137 - accuracy: 0.9240 - val_loss: 0.1166 - val_accuracy: 0.9675 - 6s/epoch - 1ms/step\n",
            "Epoch 387/500\n",
            "3850/3850 - 6s - loss: 0.2137 - accuracy: 0.9234 - val_loss: 0.2073 - val_accuracy: 0.9294 - 6s/epoch - 1ms/step\n",
            "Epoch 388/500\n",
            "3850/3850 - 6s - loss: 0.2126 - accuracy: 0.9252 - val_loss: 0.1693 - val_accuracy: 0.9437 - 6s/epoch - 2ms/step\n",
            "Epoch 389/500\n",
            "3850/3850 - 6s - loss: 0.2134 - accuracy: 0.9241 - val_loss: 0.1625 - val_accuracy: 0.9465 - 6s/epoch - 1ms/step\n",
            "Epoch 390/500\n",
            "3850/3850 - 6s - loss: 0.2133 - accuracy: 0.9236 - val_loss: 0.2261 - val_accuracy: 0.9086 - 6s/epoch - 1ms/step\n",
            "Epoch 391/500\n",
            "3850/3850 - 6s - loss: 0.2135 - accuracy: 0.9232 - val_loss: 0.1631 - val_accuracy: 0.9451 - 6s/epoch - 1ms/step\n",
            "Epoch 392/500\n",
            "3850/3850 - 6s - loss: 0.2135 - accuracy: 0.9236 - val_loss: 0.2490 - val_accuracy: 0.9051 - 6s/epoch - 1ms/step\n",
            "Epoch 393/500\n",
            "3850/3850 - 6s - loss: 0.2123 - accuracy: 0.9247 - val_loss: 0.2177 - val_accuracy: 0.9231 - 6s/epoch - 2ms/step\n",
            "Epoch 394/500\n",
            "3850/3850 - 6s - loss: 0.2131 - accuracy: 0.9244 - val_loss: 0.3344 - val_accuracy: 0.8616 - 6s/epoch - 1ms/step\n",
            "Epoch 395/500\n",
            "3850/3850 - 6s - loss: 0.2118 - accuracy: 0.9249 - val_loss: 0.1688 - val_accuracy: 0.9458 - 6s/epoch - 1ms/step\n",
            "Epoch 396/500\n",
            "3850/3850 - 6s - loss: 0.2124 - accuracy: 0.9250 - val_loss: 0.1715 - val_accuracy: 0.9343 - 6s/epoch - 1ms/step\n",
            "Epoch 397/500\n",
            "3850/3850 - 6s - loss: 0.2101 - accuracy: 0.9257 - val_loss: 0.1793 - val_accuracy: 0.9385 - 6s/epoch - 2ms/step\n",
            "Epoch 398/500\n",
            "3850/3850 - 6s - loss: 0.2119 - accuracy: 0.9259 - val_loss: 0.1140 - val_accuracy: 0.9677 - 6s/epoch - 1ms/step\n",
            "Epoch 399/500\n",
            "3850/3850 - 6s - loss: 0.2122 - accuracy: 0.9249 - val_loss: 0.1850 - val_accuracy: 0.9343 - 6s/epoch - 2ms/step\n",
            "Epoch 400/500\n",
            "3850/3850 - 6s - loss: 0.2123 - accuracy: 0.9244 - val_loss: 0.1748 - val_accuracy: 0.9383 - 6s/epoch - 2ms/step\n",
            "Epoch 401/500\n",
            "3850/3850 - 6s - loss: 0.2115 - accuracy: 0.9238 - val_loss: 0.1779 - val_accuracy: 0.9409 - 6s/epoch - 2ms/step\n",
            "Epoch 402/500\n",
            "3850/3850 - 6s - loss: 0.2111 - accuracy: 0.9251 - val_loss: 0.1328 - val_accuracy: 0.9605 - 6s/epoch - 1ms/step\n",
            "Epoch 403/500\n",
            "3850/3850 - 6s - loss: 0.2112 - accuracy: 0.9249 - val_loss: 0.2111 - val_accuracy: 0.9217 - 6s/epoch - 2ms/step\n",
            "Epoch 404/500\n",
            "3850/3850 - 6s - loss: 0.2114 - accuracy: 0.9249 - val_loss: 0.2929 - val_accuracy: 0.8857 - 6s/epoch - 1ms/step\n",
            "Epoch 405/500\n",
            "3850/3850 - 6s - loss: 0.2103 - accuracy: 0.9252 - val_loss: 0.1613 - val_accuracy: 0.9481 - 6s/epoch - 1ms/step\n",
            "Epoch 406/500\n",
            "3850/3850 - 6s - loss: 0.2111 - accuracy: 0.9247 - val_loss: 0.3411 - val_accuracy: 0.8553 - 6s/epoch - 1ms/step\n",
            "Epoch 407/500\n",
            "3850/3850 - 6s - loss: 0.2104 - accuracy: 0.9255 - val_loss: 0.2674 - val_accuracy: 0.8990 - 6s/epoch - 1ms/step\n",
            "Epoch 408/500\n",
            "3850/3850 - 6s - loss: 0.2099 - accuracy: 0.9253 - val_loss: 0.2765 - val_accuracy: 0.8887 - 6s/epoch - 2ms/step\n",
            "Epoch 409/500\n",
            "3850/3850 - 6s - loss: 0.2102 - accuracy: 0.9247 - val_loss: 0.1490 - val_accuracy: 0.9563 - 6s/epoch - 2ms/step\n",
            "Epoch 410/500\n",
            "3850/3850 - 6s - loss: 0.2104 - accuracy: 0.9253 - val_loss: 0.2201 - val_accuracy: 0.9175 - 6s/epoch - 1ms/step\n",
            "Epoch 411/500\n",
            "3850/3850 - 6s - loss: 0.2096 - accuracy: 0.9254 - val_loss: 0.2547 - val_accuracy: 0.8974 - 6s/epoch - 2ms/step\n",
            "Epoch 412/500\n",
            "3850/3850 - 6s - loss: 0.2094 - accuracy: 0.9254 - val_loss: 0.1216 - val_accuracy: 0.9635 - 6s/epoch - 2ms/step\n",
            "Epoch 413/500\n",
            "3850/3850 - 6s - loss: 0.2105 - accuracy: 0.9252 - val_loss: 0.1573 - val_accuracy: 0.9495 - 6s/epoch - 2ms/step\n",
            "Epoch 414/500\n",
            "3850/3850 - 6s - loss: 0.2098 - accuracy: 0.9242 - val_loss: 0.3109 - val_accuracy: 0.8759 - 6s/epoch - 2ms/step\n",
            "Epoch 415/500\n",
            "3850/3850 - 6s - loss: 0.2108 - accuracy: 0.9247 - val_loss: 0.1159 - val_accuracy: 0.9649 - 6s/epoch - 1ms/step\n",
            "Epoch 416/500\n",
            "3850/3850 - 6s - loss: 0.2109 - accuracy: 0.9259 - val_loss: 0.1576 - val_accuracy: 0.9483 - 6s/epoch - 2ms/step\n",
            "Epoch 417/500\n",
            "3850/3850 - 6s - loss: 0.2092 - accuracy: 0.9255 - val_loss: 0.1138 - val_accuracy: 0.9677 - 6s/epoch - 1ms/step\n",
            "Epoch 418/500\n",
            "3850/3850 - 6s - loss: 0.2102 - accuracy: 0.9256 - val_loss: 0.1371 - val_accuracy: 0.9575 - 6s/epoch - 2ms/step\n",
            "Epoch 419/500\n",
            "3850/3850 - 6s - loss: 0.2096 - accuracy: 0.9253 - val_loss: 0.2708 - val_accuracy: 0.8953 - 6s/epoch - 1ms/step\n",
            "Epoch 420/500\n",
            "3850/3850 - 6s - loss: 0.2082 - accuracy: 0.9261 - val_loss: 0.2527 - val_accuracy: 0.8960 - 6s/epoch - 2ms/step\n",
            "Epoch 421/500\n",
            "3850/3850 - 6s - loss: 0.2085 - accuracy: 0.9251 - val_loss: 0.1038 - val_accuracy: 0.9722 - 6s/epoch - 1ms/step\n",
            "Epoch 422/500\n",
            "3850/3850 - 6s - loss: 0.2100 - accuracy: 0.9246 - val_loss: 0.3702 - val_accuracy: 0.8457 - 6s/epoch - 2ms/step\n",
            "Epoch 423/500\n",
            "3850/3850 - 6s - loss: 0.2087 - accuracy: 0.9258 - val_loss: 0.1930 - val_accuracy: 0.9285 - 6s/epoch - 1ms/step\n",
            "Epoch 424/500\n",
            "3850/3850 - 6s - loss: 0.2078 - accuracy: 0.9261 - val_loss: 0.2739 - val_accuracy: 0.8864 - 6s/epoch - 1ms/step\n",
            "Epoch 425/500\n",
            "3850/3850 - 6s - loss: 0.2078 - accuracy: 0.9249 - val_loss: 0.2631 - val_accuracy: 0.8932 - 6s/epoch - 1ms/step\n",
            "Epoch 426/500\n",
            "3850/3850 - 6s - loss: 0.2090 - accuracy: 0.9257 - val_loss: 0.2300 - val_accuracy: 0.9088 - 6s/epoch - 2ms/step\n",
            "Epoch 427/500\n",
            "3850/3850 - 6s - loss: 0.2074 - accuracy: 0.9267 - val_loss: 0.2008 - val_accuracy: 0.9254 - 6s/epoch - 1ms/step\n",
            "Epoch 428/500\n",
            "3850/3850 - 6s - loss: 0.2083 - accuracy: 0.9249 - val_loss: 0.3713 - val_accuracy: 0.8455 - 6s/epoch - 2ms/step\n",
            "Epoch 429/500\n",
            "3850/3850 - 6s - loss: 0.2076 - accuracy: 0.9256 - val_loss: 0.1919 - val_accuracy: 0.9280 - 6s/epoch - 2ms/step\n",
            "Epoch 430/500\n",
            "3850/3850 - 6s - loss: 0.2074 - accuracy: 0.9264 - val_loss: 0.3216 - val_accuracy: 0.8642 - 6s/epoch - 2ms/step\n",
            "Epoch 431/500\n",
            "3850/3850 - 6s - loss: 0.2078 - accuracy: 0.9262 - val_loss: 0.2787 - val_accuracy: 0.8852 - 6s/epoch - 1ms/step\n",
            "Epoch 432/500\n",
            "3850/3850 - 6s - loss: 0.2063 - accuracy: 0.9269 - val_loss: 0.1719 - val_accuracy: 0.9467 - 6s/epoch - 2ms/step\n",
            "Epoch 433/500\n",
            "3850/3850 - 6s - loss: 0.2092 - accuracy: 0.9250 - val_loss: 0.1999 - val_accuracy: 0.9212 - 6s/epoch - 2ms/step\n",
            "Epoch 434/500\n",
            "3850/3850 - 6s - loss: 0.2067 - accuracy: 0.9253 - val_loss: 0.1572 - val_accuracy: 0.9427 - 6s/epoch - 1ms/step\n",
            "Epoch 435/500\n",
            "3850/3850 - 6s - loss: 0.2073 - accuracy: 0.9258 - val_loss: 0.3714 - val_accuracy: 0.8422 - 6s/epoch - 2ms/step\n",
            "Epoch 436/500\n",
            "3850/3850 - 6s - loss: 0.2080 - accuracy: 0.9255 - val_loss: 0.4345 - val_accuracy: 0.8263 - 6s/epoch - 2ms/step\n",
            "Epoch 437/500\n",
            "3850/3850 - 6s - loss: 0.2068 - accuracy: 0.9261 - val_loss: 0.3506 - val_accuracy: 0.8534 - 6s/epoch - 1ms/step\n",
            "Epoch 438/500\n",
            "3850/3850 - 6s - loss: 0.2073 - accuracy: 0.9263 - val_loss: 0.2219 - val_accuracy: 0.9107 - 6s/epoch - 1ms/step\n",
            "Epoch 439/500\n",
            "3850/3850 - 6s - loss: 0.2073 - accuracy: 0.9260 - val_loss: 0.2308 - val_accuracy: 0.9084 - 6s/epoch - 1ms/step\n",
            "Epoch 440/500\n",
            "3850/3850 - 6s - loss: 0.2071 - accuracy: 0.9266 - val_loss: 0.2686 - val_accuracy: 0.8927 - 6s/epoch - 1ms/step\n",
            "Epoch 441/500\n",
            "3850/3850 - 6s - loss: 0.2063 - accuracy: 0.9263 - val_loss: 0.3352 - val_accuracy: 0.8630 - 6s/epoch - 1ms/step\n",
            "Epoch 442/500\n",
            "3850/3850 - 6s - loss: 0.2059 - accuracy: 0.9269 - val_loss: 0.2897 - val_accuracy: 0.8824 - 6s/epoch - 1ms/step\n",
            "Epoch 443/500\n",
            "3850/3850 - 6s - loss: 0.2056 - accuracy: 0.9260 - val_loss: 0.3002 - val_accuracy: 0.8808 - 6s/epoch - 1ms/step\n",
            "Epoch 444/500\n",
            "3850/3850 - 6s - loss: 0.2052 - accuracy: 0.9269 - val_loss: 0.2929 - val_accuracy: 0.8829 - 6s/epoch - 2ms/step\n",
            "Epoch 445/500\n",
            "3850/3850 - 6s - loss: 0.2065 - accuracy: 0.9273 - val_loss: 0.2187 - val_accuracy: 0.9163 - 6s/epoch - 1ms/step\n",
            "Epoch 446/500\n",
            "3850/3850 - 6s - loss: 0.2060 - accuracy: 0.9272 - val_loss: 0.3962 - val_accuracy: 0.8375 - 6s/epoch - 1ms/step\n",
            "Epoch 447/500\n",
            "3850/3850 - 6s - loss: 0.2062 - accuracy: 0.9261 - val_loss: 0.1968 - val_accuracy: 0.9313 - 6s/epoch - 2ms/step\n",
            "Epoch 448/500\n",
            "3850/3850 - 6s - loss: 0.2050 - accuracy: 0.9257 - val_loss: 0.3330 - val_accuracy: 0.8707 - 6s/epoch - 2ms/step\n",
            "Epoch 449/500\n",
            "3850/3850 - 6s - loss: 0.2042 - accuracy: 0.9272 - val_loss: 0.2434 - val_accuracy: 0.9037 - 6s/epoch - 2ms/step\n",
            "Epoch 450/500\n",
            "3850/3850 - 6s - loss: 0.2048 - accuracy: 0.9264 - val_loss: 0.1131 - val_accuracy: 0.9649 - 6s/epoch - 2ms/step\n",
            "Epoch 451/500\n",
            "3850/3850 - 6s - loss: 0.2051 - accuracy: 0.9273 - val_loss: 0.2127 - val_accuracy: 0.9175 - 6s/epoch - 1ms/step\n",
            "Epoch 452/500\n",
            "3850/3850 - 6s - loss: 0.2043 - accuracy: 0.9277 - val_loss: 0.2325 - val_accuracy: 0.9058 - 6s/epoch - 1ms/step\n",
            "Epoch 453/500\n",
            "3850/3850 - 6s - loss: 0.2052 - accuracy: 0.9264 - val_loss: 0.1780 - val_accuracy: 0.9469 - 6s/epoch - 1ms/step\n",
            "Epoch 454/500\n",
            "3850/3850 - 6s - loss: 0.2043 - accuracy: 0.9271 - val_loss: 0.2032 - val_accuracy: 0.9243 - 6s/epoch - 1ms/step\n",
            "Epoch 455/500\n",
            "3850/3850 - 6s - loss: 0.2051 - accuracy: 0.9267 - val_loss: 0.2864 - val_accuracy: 0.8890 - 6s/epoch - 2ms/step\n",
            "Epoch 456/500\n",
            "3850/3850 - 6s - loss: 0.2057 - accuracy: 0.9263 - val_loss: 0.2583 - val_accuracy: 0.8953 - 6s/epoch - 2ms/step\n",
            "Epoch 457/500\n",
            "3850/3850 - 6s - loss: 0.2052 - accuracy: 0.9262 - val_loss: 0.1993 - val_accuracy: 0.9343 - 6s/epoch - 2ms/step\n",
            "Epoch 458/500\n",
            "3850/3850 - 6s - loss: 0.2043 - accuracy: 0.9259 - val_loss: 0.2521 - val_accuracy: 0.9007 - 6s/epoch - 2ms/step\n",
            "Epoch 459/500\n",
            "3850/3850 - 6s - loss: 0.2051 - accuracy: 0.9259 - val_loss: 0.2437 - val_accuracy: 0.9060 - 6s/epoch - 1ms/step\n",
            "Epoch 460/500\n",
            "3850/3850 - 6s - loss: 0.2055 - accuracy: 0.9258 - val_loss: 0.1958 - val_accuracy: 0.9331 - 6s/epoch - 1ms/step\n",
            "Epoch 461/500\n",
            "3850/3850 - 6s - loss: 0.2034 - accuracy: 0.9278 - val_loss: 0.1569 - val_accuracy: 0.9507 - 6s/epoch - 1ms/step\n",
            "Epoch 462/500\n",
            "3850/3850 - 6s - loss: 0.2039 - accuracy: 0.9266 - val_loss: 0.4012 - val_accuracy: 0.8380 - 6s/epoch - 1ms/step\n",
            "Epoch 463/500\n",
            "3850/3850 - 6s - loss: 0.2036 - accuracy: 0.9265 - val_loss: 0.2669 - val_accuracy: 0.8939 - 6s/epoch - 1ms/step\n",
            "Epoch 464/500\n",
            "3850/3850 - 6s - loss: 0.2033 - accuracy: 0.9276 - val_loss: 0.1891 - val_accuracy: 0.9292 - 6s/epoch - 2ms/step\n",
            "Epoch 465/500\n",
            "3850/3850 - 6s - loss: 0.2033 - accuracy: 0.9267 - val_loss: 0.2793 - val_accuracy: 0.8894 - 6s/epoch - 2ms/step\n",
            "Epoch 466/500\n",
            "3850/3850 - 6s - loss: 0.2046 - accuracy: 0.9266 - val_loss: 0.2689 - val_accuracy: 0.8976 - 6s/epoch - 2ms/step\n",
            "Epoch 467/500\n",
            "3850/3850 - 6s - loss: 0.2023 - accuracy: 0.9286 - val_loss: 0.1468 - val_accuracy: 0.9488 - 6s/epoch - 2ms/step\n",
            "Epoch 468/500\n",
            "3850/3850 - 6s - loss: 0.2030 - accuracy: 0.9275 - val_loss: 0.2273 - val_accuracy: 0.9217 - 6s/epoch - 2ms/step\n",
            "Epoch 469/500\n",
            "3850/3850 - 6s - loss: 0.2031 - accuracy: 0.9274 - val_loss: 0.2003 - val_accuracy: 0.9205 - 6s/epoch - 2ms/step\n",
            "Epoch 470/500\n",
            "3850/3850 - 6s - loss: 0.2036 - accuracy: 0.9278 - val_loss: 0.1357 - val_accuracy: 0.9598 - 6s/epoch - 2ms/step\n",
            "Epoch 471/500\n",
            "3850/3850 - 6s - loss: 0.2022 - accuracy: 0.9266 - val_loss: 0.1659 - val_accuracy: 0.9458 - 6s/epoch - 2ms/step\n",
            "Epoch 472/500\n",
            "3850/3850 - 6s - loss: 0.2035 - accuracy: 0.9270 - val_loss: 0.3016 - val_accuracy: 0.8749 - 6s/epoch - 2ms/step\n",
            "Epoch 473/500\n",
            "3850/3850 - 6s - loss: 0.2027 - accuracy: 0.9274 - val_loss: 0.1785 - val_accuracy: 0.9362 - 6s/epoch - 2ms/step\n",
            "Epoch 474/500\n",
            "3850/3850 - 6s - loss: 0.2031 - accuracy: 0.9274 - val_loss: 0.2173 - val_accuracy: 0.9231 - 6s/epoch - 2ms/step\n",
            "Epoch 475/500\n",
            "3850/3850 - 6s - loss: 0.2019 - accuracy: 0.9262 - val_loss: 0.2481 - val_accuracy: 0.9032 - 6s/epoch - 2ms/step\n",
            "Epoch 476/500\n",
            "3850/3850 - 6s - loss: 0.2012 - accuracy: 0.9279 - val_loss: 0.2204 - val_accuracy: 0.9135 - 6s/epoch - 2ms/step\n",
            "Epoch 477/500\n",
            "3850/3850 - 6s - loss: 0.2025 - accuracy: 0.9275 - val_loss: 0.1944 - val_accuracy: 0.9261 - 6s/epoch - 2ms/step\n",
            "Epoch 478/500\n",
            "3850/3850 - 12s - loss: 0.2025 - accuracy: 0.9275 - val_loss: 0.1679 - val_accuracy: 0.9460 - 12s/epoch - 3ms/step\n",
            "Epoch 479/500\n",
            "3850/3850 - 9s - loss: 0.2028 - accuracy: 0.9276 - val_loss: 0.1950 - val_accuracy: 0.9254 - 9s/epoch - 2ms/step\n",
            "Epoch 480/500\n",
            "3850/3850 - 6s - loss: 0.2022 - accuracy: 0.9282 - val_loss: 0.2263 - val_accuracy: 0.9109 - 6s/epoch - 2ms/step\n",
            "Epoch 481/500\n",
            "3850/3850 - 6s - loss: 0.2013 - accuracy: 0.9269 - val_loss: 0.2115 - val_accuracy: 0.9196 - 6s/epoch - 2ms/step\n",
            "Epoch 482/500\n",
            "3850/3850 - 6s - loss: 0.2023 - accuracy: 0.9276 - val_loss: 0.2585 - val_accuracy: 0.8964 - 6s/epoch - 2ms/step\n",
            "Epoch 483/500\n",
            "3850/3850 - 6s - loss: 0.2024 - accuracy: 0.9280 - val_loss: 0.3339 - val_accuracy: 0.8614 - 6s/epoch - 2ms/step\n",
            "Epoch 484/500\n",
            "3850/3850 - 6s - loss: 0.2010 - accuracy: 0.9287 - val_loss: 0.2366 - val_accuracy: 0.9102 - 6s/epoch - 1ms/step\n",
            "Epoch 485/500\n",
            "3850/3850 - 6s - loss: 0.2018 - accuracy: 0.9275 - val_loss: 0.1714 - val_accuracy: 0.9376 - 6s/epoch - 2ms/step\n",
            "Epoch 486/500\n",
            "3850/3850 - 6s - loss: 0.2015 - accuracy: 0.9276 - val_loss: 0.2190 - val_accuracy: 0.9091 - 6s/epoch - 2ms/step\n",
            "Epoch 487/500\n",
            "3850/3850 - 6s - loss: 0.2016 - accuracy: 0.9265 - val_loss: 0.2512 - val_accuracy: 0.8990 - 6s/epoch - 2ms/step\n",
            "Epoch 488/500\n"
          ]
        }
      ],
      "source": [
        "#for single \n",
        "\n",
        "model.fit(\n",
        "   \n",
        "      x= scaled_samples_withoutzero\n",
        "    , y=label_withoutzero \n",
        "    , validation_split=0.1\n",
        "    , batch_size=10\n",
        "    , epochs=500\n",
        "    , verbose=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "summary \n",
        "at 500 acc 92\n",
        "at 200 acc\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LCXAUjeqqiVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zl6Dz4Zfqfee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IjhunYcy4fK"
      },
      "source": [
        "# saving model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oanoAdL8yxqg",
        "outputId": "b2ce970f-e50b-4ab7-9e44-03663cd9c71c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ANN_MY_spsp_withoutblank_PU_reduced7_splited/assets\n"
          ]
        }
      ],
      "source": [
        "# Save the entire model as a SavedModel.\n",
        "!mkdir -p saved_model\n",
        "model.save('ANN_MY_spsp_withoutblank_PU_reduced7_splited')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vo63m6SOz5bY"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngJKT8mwz-w5"
      },
      "outputs": [],
      "source": [
        "model=keras.models.load_model('/content/drive/MyDrive/ANN_MY_spsp_withoutblank_PU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKVZeCAJg1Z-"
      },
      "outputs": [],
      "source": [
        "#reduced\n",
        "model=keras.models.load_model('/content/drive/MyDrive/ANN_MY_spsp_withoutblank_PU_reduced7_splited')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to7Va4o10G5i",
        "outputId": "d23770f8-4504-4452-a926-8543cebab3f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spectral in /usr/local/lib/python3.7/dist-packages (0.22.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from spectral) (1.21.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install spectral "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jI8hxJHI0Irv"
      },
      "outputs": [],
      "source": [
        "import spectral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9phR9X9i0Ksg",
        "outputId": "b7c556a8-aacd-490e-ce20-406c91ed4232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(610, 340)\n"
          ]
        }
      ],
      "source": [
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "mGT0Mn0v0M9O",
        "outputId": "49c17839-7130-4091-ea45-fab44a171590"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "ground_truth = spectral.imshow(classes = y,figsize =(7,7))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Qtj-zT40PYM"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(\n",
        "      #x=scaled_samples_withoutzero\n",
        "      x=X_test      \n",
        "    , batch_size=10 # what is the defualt\n",
        "    , verbose=0\n",
        ")  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKU6Q2cL0WKj"
      },
      "outputs": [],
      "source": [
        "rounded_predictions = np.argmax(predictions, axis=-1) #review the axis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_lVYDou0WyV",
        "outputId": "00d9fe55-c5ff-4f87-a091-e305369d0636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      precision    recall  f1-score   support\n",
            "\n",
            "             Asphalt       0.97      0.97      0.97      1326\n",
            "             Meadows       0.98      0.99      0.98      3730\n",
            "              Gravel       0.90      0.85      0.87       420\n",
            "               Trees       0.98      0.97      0.97       613\n",
            "Painted metal sheets       1.00      1.00      1.00       269\n",
            "           Bare Soil       0.97      0.94      0.95      1006\n",
            "             Bitumen       0.97      0.94      0.96       266\n",
            "Self-Blocking Bricks       0.89      0.94      0.91       737\n",
            "             Shadows       1.00      1.00      1.00       189\n",
            "\n",
            "            accuracy                           0.97      8556\n",
            "           macro avg       0.96      0.95      0.96      8556\n",
            "        weighted avg       0.97      0.97      0.97      8556\n",
            "\n"
          ]
        }
      ],
      "source": [
        "target_names = ['Asphalt', 'Meadows', 'Gravel', 'Trees'  ## you should change this ####\n",
        "                        ,'Painted metal sheets', 'Bare Soil', 'Bitumen', \n",
        "                        'Self-Blocking Bricks', 'Shadows']\n",
        "#print( classification_report( label_withoutzero-1, rounded_predictions,target_names=target_names ) ) ## this should be made on testing data not training\n",
        "print( classification_report( y_test, rounded_predictions,target_names=target_names ) )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test for all pixels\n",
        "predictions = model.predict(\n",
        "      x=scaled_samples_withoutzero\n",
        "      #x=X_test      \n",
        "    , batch_size=10 # what is the defualt\n",
        "    , verbose=0\n",
        ")  \n",
        "rounded_predictions = np.argmax(predictions, axis=-1) #review the axis"
      ],
      "metadata": {
        "id": "F6wQGHZeJioO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WuEiL8e0aJw",
        "outputId": "4ab02d7a-bd55-4fea-91c5-02ac6db88688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(207400,)\n"
          ]
        }
      ],
      "source": [
        "zeros_arr=np.zeros(y.shape[0]*y.shape[1])\n",
        "print(zeros_arr.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5bUf2VU0cnQ",
        "outputId": "a52bc4be-1cb2-4383-986d-bfa7a7959ae7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(42776,)\n"
          ]
        }
      ],
      "source": [
        "result2 = np. where(label != 0)\n",
        "print(result2[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLXyjXFK0fLf",
        "outputId": "ef2b9167-34fb-4313-dceb-219dda12d59f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(207400,)\n",
            "[0. 0. 0. ... 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "zeros_arr[result2[0]]=rounded_predictions + 1\n",
        "print(zeros_arr.shape)\n",
        "print(zeros_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLBBZgdo0hun"
      },
      "outputs": [],
      "source": [
        "outputs=zeros_arr.reshape(y.shape[0],y.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "_VJfmT7K0lW2",
        "outputId": "2ecc0225-5db5-42ef-9a87-e06ec0ccf660"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "predict_image = spectral.imshow(classes = outputs.astype(int),figsize =(7,7))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOThmyFfS-uV"
      },
      "source": [
        "# throughput"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK_DsG4ZTAvZ",
        "outputId": "b463c051-9df4-4d2c-af3b-e7e07f1d1c79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 45)\n"
          ]
        }
      ],
      "source": [
        "N_batch=1000\n",
        "batched_input=scaled_samples_duplicate[0:N_batch]\n",
        "print(batched_input.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ihkqbdETGTf",
        "outputId": "bc722722-6a5f-4266-ddb6-62cbdc43fe29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dense_7': TensorSpec(shape=(None, 9), dtype=tf.float32, name='dense_7')}\n"
          ]
        }
      ],
      "source": [
        "#load optimized model with FP32 precision \n",
        "#import tensorflow.contrib.tensorrt \n",
        "loaded_spsp = tf.saved_model.load('/content/drive/MyDrive/ANN_MY_spsp_withoutblank_PU_reduced6')\n",
        "\n",
        "#they return dictionary as signiture (what are signatures) \n",
        "infer_spsp=loaded_spsp.signatures['serving_default']\n",
        "print(infer_spsp.structured_outputs) #structure output "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JpcRMYbzTRxh"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "def predict_and_benchmark_throughput(batched_input, infer, N_warmup_run=10, N_run=100):\n",
        "\n",
        "  elapsed_time = []\n",
        "  all_preds = []\n",
        "  batch_size = batched_input.shape[0] \n",
        "\n",
        "  tensor_list = tf.convert_to_tensor(batched_input) # change to tensor\n",
        "  tensor_list = tf.cast(tensor_list, tf.float32)  # change to float32\n",
        "\n",
        "  for i in range(N_warmup_run):\n",
        "    labeling = infer(tensor_list)\n",
        "    preds = labeling['dense_7'].numpy()\n",
        "\n",
        "  for i in range(N_run):\n",
        "    start_time = time.time()\n",
        "\n",
        "    labeling = infer(tensor_list)\n",
        "\n",
        "    preds = labeling['dense_7'].numpy()\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    elapsed_time = np.append(elapsed_time, end_time - start_time)\n",
        "    \n",
        "    all_preds.append(preds)\n",
        "\n",
        "    if i % 50 == 0:\n",
        "      print('Steps {}-{} average: {:4.1f}ms'.format(i, i+50, (elapsed_time[-50:].mean()) * 1000))\n",
        "\n",
        "  print('Throughput: {:.0f} pixels/s'.format(N_run * batch_size / elapsed_time.sum()))\n",
        "  return all_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htPeeiqiTotB",
        "outputId": "ce0d68a5-5182-4a90-cac7-51767f8a57a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps 0-50 average:  1.0ms\n",
            "Steps 50-100 average:  0.8ms\n",
            "Steps 100-150 average:  0.9ms\n",
            "Steps 150-200 average:  0.8ms\n",
            "Steps 200-250 average:  0.8ms\n",
            "Steps 250-300 average:  0.9ms\n",
            "Steps 300-350 average:  0.9ms\n",
            "Steps 350-400 average:  0.8ms\n",
            "Steps 400-450 average:  0.8ms\n",
            "Steps 450-500 average:  0.8ms\n",
            "Throughput: 1187057 pixels/s\n"
          ]
        }
      ],
      "source": [
        "pred=predict_and_benchmark_throughput(batched_input, infer_spsp, N_warmup_run=10, N_run=500)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ANN_withpout_alldatasets.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nrft-tiCqd5l",
        "UGfa4p5Y5ZSQ",
        "JMO9p1vSqjcg",
        "1IjhunYcy4fK",
        "Vo63m6SOz5bY"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}